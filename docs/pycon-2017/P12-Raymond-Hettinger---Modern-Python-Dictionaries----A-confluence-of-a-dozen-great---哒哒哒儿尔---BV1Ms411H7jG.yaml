- en: P12：Raymond Hettinger   Modern Python Dictionaries    A confluence of a dozen
    great - 哒哒哒儿尔 - BV1Ms411H7jG
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: P12：雷蒙德·海丁格 现代Python字典 十几个伟大思想的汇聚 - 哒哒哒儿尔 - BV1Ms411H7jG
- en: And now， welcome Raymond Heddinga。
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，欢迎雷蒙德·海丁加。
- en: '![](img/c15e81bfa56cedacdd05349ba2e93c1b_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c15e81bfa56cedacdd05349ba2e93c1b_1.png)'
- en: All right。 Welcome to my talk， A Brief History of Time。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧。欢迎参加我的演讲，《时间简史》。
- en: '![](img/c15e81bfa56cedacdd05349ba2e93c1b_3.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c15e81bfa56cedacdd05349ba2e93c1b_3.png)'
- en: By Stephen， I mean， Raymond Heddinga。 In the beginning， the dinosaurs roamed
    the earth。 They died in the cave extinct because of their inadequate capabilities。
    In the void that they left behind， the mammals arose。 And intelligent life came
    to this planet。 And we invented Python dictionaries。 Any questions？ Would you
    like a few more details？ All right。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的“Stephen”指的是**雷蒙德·海丁加**。一开始，恐龙在地球上漫游。由于能力不足，它们在洞穴中灭绝。在它们留下的空白中，哺乳动物兴起。智能生命来到这个星球。然后我们发明了Python字典。有任何问题吗？你想要更多细节吗？好吧。
- en: So my name is Raymond Heddinga。 The theme of my talk is lots of smart people
    over time。 Thought about the dictionary problem very， very deeply。 Came up with
    some ideas。 Presented their ideas， the world accepted them and thought we had
    good dictionaries。 Then someone else came along， thought about it very deeply，
    and had another innovation。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我叫雷蒙德·海丁加。我演讲的主题是很多聪明的人在一段时间内，深入思考字典问题，提出了一些想法，世界接受了这些想法，并认为我们有了很好的字典。然后其他人也深入思考，并有了另一个创新。
- en: and another innovation。 And I think what we have today is a confluence of about
    a dozen great ideas。 that span the course of about 50 years。 And so I'd like to
    take you from the dinosaur era up to the present。 and then slightly into the future。
    There are those of you who know nothing about hash tables。 You will know everything
    about hash tables shortly。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 还有另一个创新。我认为我们今天拥有的是大约十几个伟大思想的汇聚，跨越了大约50年的时间。因此，我想带你们从恐龙时代走到现在，稍微展望一下未来。你们中有些人对哈希表一无所知。不久后你们将了解哈希表的一切。
- en: There are those of you who learned about hash tables in school。 Now you'll learn
    how they're done in real industrial strength production。 There are those of you
    who already knew that。 But don't know what the latest innovations are in Python。
    We have propelled the future quite a bit forward in the last few years。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你们中有些人在学校学习过哈希表。现在你们将学习它们在真实工业强度生产中的实现。你们中有些人已经知道这一点，但不知道Python的最新创新。我们在过去几年中推动了未来的进程。
- en: And I'd like to take you on this journey to where I think is a somewhat magnificent。
    I'd call it an ending point， but evolution never ceases。 Shall we begin？ All right。
    So one little thing about me。 What is my mission in life is to train thousands
    of Python programmers。 I personally trained about 5，000 programmers。 My company，
    Mutable Minds， Inc。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我想带你们走上一段旅程，那里我认为是相当宏伟的。我会称之为一个结束点，但进化永远不会停止。我们开始吧？好吧。关于我，有一件小事。我的人生使命是培养成千上万的Python程序员。我个人培训了大约5，000名程序员。我的公司是Mutable
    Minds，Inc。
- en: I have a team of trainers and we have trained， about 13，000 people accumulatively。
    So if you have an interest in such things， call me。 And let's begin。 All right。
    Our journey。 The beginning and the end。 Let's do the overview first， which is。
    We do not reprogram your keys just prior to a presentation。 There you go。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我有一个培训团队，我们累计培训了大约13，000人。因此，如果你对这些感兴趣，请联系我。让我们开始吧。好吧。我们的旅程。开始和结束。我们先做个概述，就是在演示前不会重新编程你的密钥。好了。
- en: So the importance of Python is built around dictionaries。 Globals are dictionaries。
    Locals were at one time actually dictionaries。 Modules have dictionaries。 Classes
    have dictionaries。 Instances have dictionaries。 They are central to the language。
    which means that they're used everywhere， and they're pretty darn important。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Python的重要性建立在字典之上。全局变量是字典。局部变量曾经实际上是字典。模块有字典。类有字典。实例有字典。它们是语言的核心，意味着它们无处不在，而且非常重要。
- en: One example is we have instances。 So we have a class and we have several instance
    variables。 And I've chosen Quito， Sarah， Barry， Rachel and Tim， all important
    people， in my life。 And a repper to show them。 We've made a three instances， a
    color set of cities， a set of fruits。 so that we know Quito's favorite color is
    blue。 His favorite city is Austin and his favorite fruit is Apple。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 一个例子是我们有实例。所以我们有一个类，还有几个实例变量。我选择了 Quito、Sarah、Barry、Rachel 和 Tim，这些都是我生活中重要的人。并且有一个方法来展示它们。我们创建了三个实例，一个是城市的颜色集合，一个是水果的集合。因此我们知道
    Quito 最喜欢的颜色是蓝色。他最喜欢的城市是奥斯丁，他最喜欢的水果是苹果。
- en: I just made all of it up and we can loop over the instances and print them out。
    Common place。 everyday Python code。 What I'd like to do is look what's behind
    it and look what it looks like。 So behind each of these three instances is addiction
    instance dictionary。 Where is the make big button？ That is my favorite button。
    There we go。 Okay。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我刚刚编造了这一切，我们可以遍历这些实例并打印出来。这是常见的、日常的 Python 代码。我想做的是看看它背后的内容以及它的样子。所以在这三个实例的背后是一个添加实例字典。哪里有“大按钮”？那是我最喜欢的按钮。好了，我们开始吧。
- en: So we've got three dictionaries， Quito， blue。 And then the next one， Quito。
    is Austin and the next one， Quito is Apple。 And so that's a consequence of how
    Python is designed。 Instances have dictionaries behind them。 So what we'd like
    to do is see how these dictionaries are implemented over various。 versions of
    Python。 Jumping right to the end to see where we ended up after all the evolution。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们有三个字典，Quito 和蓝色。接下来是，Quito 是奥斯丁，再接下来是，Quito 是苹果。这是 Python 设计的结果。实例背后有字典。因此我们想看看这些字典在不同的
    Python 版本中是如何实现的。直接跳到最后，看看我们在所有演变之后最终得到了什么。
- en: And Python 2。7， each one of these dictionaries took 280 bytes each。 And the
    ordering of the dictionary was Sarah would go first and Quito would go last。 And
    that is deterministic。 It is repeatable in Python 2。7。 And the keys are scrambled。
    We actually say arbitrary because they're not res scrambled every time。 And Python
    3。5， some things。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 2.7 中，这些字典每个占用 280 字节。字典的顺序是 Sarah 会优先，Quito 最后。这是确定性的。在 Python 2.7
    中是可重复的。而且键是杂乱的。我们实际上说是任意的，因为它们每次不会重新洗牌。而在 Python 3.5 中，有一些变化。
- en: had changed。 By 3。5， the size of the dictionary had gotten down to 196 bytes，
    which is very。 nice a compaction。 And this time， the keys are actually randomized
    so that every time you rerun it。 you get a different key order。 So they were no
    longer deterministic。 Then Python 3。6 came out。 Is the size a little bit smaller？
    112 bytes， which is pretty darn amazing。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 到了 3.5，字典的大小降到了 196 字节，压缩效果非常不错。这一次，键实际上是随机化的，所以每次重新运行时，你会得到不同的键顺序。因此它们不再是确定性的。然后
    Python 3.6 发布了。大小稍微小一点？112 字节，这真是太惊人了。
- en: And the key order is now deterministic。 And it's the order that you added the
    keys because after all。 in the beginning， there was Quito and from Quito came
    everything that you see around you。 Okay。 So Quito goes first， always the ruler
    of the kingdom in the order dictionaries。 And the Python 3。5 universe， he was
    just another schmo。 Once in a while， he'd get to be benevolent dictator。
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 现在键的顺序是确定性的。它是你添加键的顺序，因为毕竟，一开始是 Quito，从 Quito 开始，一切你看到的都围绕着它。因此，Quito 总是第一个，永远是有序字典的统治者。在
    Python 3.5 的宇宙中，他只是另一个普通人。偶尔，他会成为仁慈的独裁者。
- en: Once in a while， the rest of us would get to tell him what to do。 And Python
    2。7。 he was always on the bottom of the list， and not called Timmy took， priority。
    But now he always gets to be a king。 And so that's where we're going to end up。
    At the end of our journey is with smaller dictionaries that are ordered。 By the
    way。
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 偶尔，我们其他人会告诉他该做什么。在 Python 2.7 中，他总是在列表的底部，而且不叫 Timmy 的优先级。可是现在他总是能够成为国王。所以我们的旅程结束时会是更小的、有序的字典。顺便提一句。
- en: how many of you like small and ordered dictionaries？ This is a fine thing。 It's
    one of your reasons to want to upgrade to Python 3。6 straight away。 I'm not going
    to say that I was a Python 3 holdout because I've been working on。 making it better
    for about eight years。 That said， I believe Python 3。6。
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 你们中有多少人喜欢小而有序的字典？这是一件好事。这是你们想要立即升级到 Python 3.6 的原因之一。我并不是说我曾经是 Python 3 的保留者，因为我已经为此工作了大约八年。话虽如此，我相信
    Python 3.6。
- en: 1 is the first of the Python 3 series that's， actually better in many， many，
    many respects。 It is very， very， very good。 It is now time to really push hard
    on other people to go ahead and just switch。 over。 When I step back to 2。7， which
    was a nearly perfect Python， it feels like a， dinosaur to me。 And you'll see part
    of the reason why coming up。 So let's start back in time with the dinosaurs。
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 1 是 Python 3 系列中的第一个版本，在许多方面实际上更优秀。它非常非常好。现在是时候真正推动其他人转向它。当我回到 2.7 时，这几乎是一个完美的
    Python，我感觉它像是一只恐龙。你将会看到原因之一即将出现。所以让我们从恐龙时代开始回顾。
- en: Okay。 So the dinosaurs were parents and our grandparents who had this bright。
    idea of using databases。 And in a database， we had rows and columns。 And the columns
    were each field。 So name the color of the city and the fruit。 Now。 our forefathers
    weren't entirely clueless。 They came up the bright idea of indexing into this
    database so that you could do。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 好的。所以恐龙是父母和我们的祖父母，他们有这个聪明的想法使用数据库。在数据库中，我们有行和列。每一列都是一个字段。所以包括城市的名称、颜色和水果。现在，我们的祖先并非完全无知。他们想出了一个聪明的主意，为这个数据库建立索引，以便你可以进行查询。
- en: quick lookups for a berry。 But clearly， our ancestors。 our parents and grandparents
    had no idea what they。 were doing back in the 1960s when they made databases like
    this。 Or I should actually say early 70s。 This design was from E。F。 Cod in 1970
    who announced onto the world all at once relational database theory。
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 快速查找浆果。但显然，我们的祖先，我们的父母和祖父母在1960年代创建这样的数据库时根本不知道他们在做什么。或者我应该说是70年代初。这种设计是由 E.
    F. Codd 于1970年提出的，他一举向世界宣布了关系数据库理论。
- en: So this is the state of the art in 1970， the dinosaurs who died and became stink。
    because their skills were inadequate in comparison to our awesome skills of today。
    Their parents were unequal to us。 They would shiver to see our modern code。 Just
    saying。 This we all know is true。 Programming has advanced dramatically over 50
    years。 Do you believe me？
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是1970年的前沿技术，恐龙们因技能不足而消亡，变得不堪一击。与我们今天的超强技能相比，他们的父母与我们不相称。他们看到我们现代的代码会感到颤抖。只是说说。这我们都知道是真的。编程在50年间显著进步。你相信我吗？
- en: It was a trick question。 Do you believe me？ Do you believe me？ It's a trick
    question。 No。 OK。 so I've got a little set up here。 I've got some keys， some values，
    three sets of values。 I create a list of hashes， a list of entries and combined
    entries that have， the keys。 hashes and values。 These will be the data structures
    that I use through the rest of the top。
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个技巧性问题。你相信我吗？你相信我吗？这是一个技巧性问题。不。好的，所以我这里有一点准备。我有一些键，一些值，三组值。我创建了一个哈希列表，一个条目列表，以及包含键的组合条目。这些将是我在整个主题中使用的数据结构。
- en: So what is the database way of solving a problem？ In Python we would represent
    it as a list of tuples。 The problem with this is we have to do a linear search。
    And so as it starts to scale。 the performance is really bad。 Interestingly， compared
    to modern dictionaries。 once you get to a list of size two， you are not as good
    as a dictionary。
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 那么数据库解决问题的方式是什么？在 Python 中，我们将其表示为一个元组列表。这样做的问题是我们必须进行线性搜索。因此，当它开始扩展时，性能真的很糟糕。有趣的是，与现代字典相比，一旦列表的大小达到两个，你就不如字典了。
- en: So we tend to think of scaling is falling by。 Oh， if you've got a million entries。
    dictionaries would be better。 But typically it's about two or three when dictionaries
    start to win。 which is， pretty amazing。 I know what you're thinking。 Oh， that
    was a trick too。 There must be a worse way than this。 There is。 Unto them was
    born a crazy group of people known as list programmers。
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们往往认为扩展是落后的。哦，如果你有一百万个条目，字典会更好。但通常是在两个或三个条目时字典才开始占优，这真是令人惊讶。我知道你在想什么。哦，那也是个技巧。肯定还有比这更糟糕的方法。确实有。于是，一群疯狂的人被称为列表程序员诞生了。
- en: And the saying was a list programmer knows the value of everything in the price
    of nothing。 So a list programmer would store what we're called association list，
    the key value pairs。 So in this case， we have a list of tuples。 Each one of them
    needs to be searched independently。 but you can see there's a linear， search for
    each of these。
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 有句话说，列表程序员知道一切的价值却不知道价格。所以列表程序员会存储我们称之为关联列表的键值对。在这种情况下，我们有一个元组列表。每一个都需要独立搜索。但你可以看到这些的线性搜索。
- en: And we have multiple lists and there's redundancy inside wasting space like
    crazy。 like list programmers are want to do。 Just saying。 Remember， the dinosaurs。
    our parents and grandparents were crazy people and didn't。 know all of the things
    that we know today。 That was a trick。 All right。
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有多个列表，里面存在冗余，疯狂地浪费空间。程序员们就是这样。记住，恐龙。我们的父母和祖父母是疯狂的人，不知道我们今天所知道的所有事情。这是一个圈套。好的。
- en: So what was the first innovation after the dinosaurs died off？ It was called
    separate training。 And the idea is instead of doing a linear search of a big list，
    how about do smaller。 linear searches of smaller list？ So the idea is take that
    one big list we had before and divided into two。 This is list number one and list
    number two。 Now， if you search list number one。
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 所以恐龙灭绝后第一个创新是什么？它叫做分离训练。想法是与其对一个大列表进行线性搜索，不如对更小的列表进行更小的线性搜索？所以想法是将之前的一个大列表分成两个。这是列表一和列表二。现在，如果你搜索列表一。
- en: you either get one probe to find quito or two probes， to find Tim， one for Sarah。
    two for Barry and three for Rachel。 This doubles the performance of the lookups
    as long as you know which bucket to look in。 and you know which bucket to look
    in by hashing。 If somebody asks you for a simple summary of what hashing is。 it
    is reducing the size， of the search space。 So if I was doing a linear search of
    this room。
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 你要么用一个探针找到基托，要么用两个探针找到蒂姆，一个探针给莎拉，两个给巴里，三个给瑞秋。只要你知道在哪个桶里查找，这将使查找性能翻倍。你知道在哪个桶里查找是通过哈希。如果有人问你哈希的简单总结是什么，那就是减少搜索空间的大小。所以如果我在这个房间进行线性搜索。
- en: I would have to go through 600 people。 But if I know which cluster you're in，
    cluster one。 cluster two or cluster three， I could， search cut the search space
    by a factor of three。 Easy enough。 That's a one or two sentence elevator pitch
    for hash tables。 What is a hash table？
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我必须经过600人。但如果我知道你在哪个聚类中，聚类一、聚类二或聚类三，我可以将搜索空间缩小三倍。足够简单。这是对哈希表的一两句电梯推销。哈希表是什么？
- en: Something that reduces the search space by cutting it into smaller clusters。
    which are traditionally， named buckets when talking about separate a chain。 [
    Laughter ]。 This time it's better way。 Okay。 There is a better way。 If two buckets
    is good。 four buckets would be even better。 So now I have four buckets and what's
    cool about that is the more buckets you have。
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 一种通过将搜索空间划分成更小的聚类来减少搜索空间的方法，传统上称为桶。 [笑声]。这次是更好的方法。好的。有更好的方法。如果两个桶不错，四个桶会更好。所以现在我有四个桶，最酷的是，你拥有的桶越多。
- en: the more you produce the search。 So we have now four people who are found with
    one probe and Barry is a hash collision。 and it takes a second probe to find him。
    So that means that on average。 the weighted number of probes across these five
    people is 1。2， probes。 That's pretty darn good。 It's like most of the time you
    look for something， it's always in the first place you look rather。
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 你越多地生产搜索结果。现在我们有四个人通过一个探针找到了，而巴里是一个哈希碰撞。找到他需要第二个探针。所以这意味着平均来说，这五个人的加权探针数是1.2个探针。这相当不错。大多数时候，你寻找的东西总是在你第一眼看到的地方。
- en: than in the last place。 Pretty awesome。 [ Laughter ]， If four buckets would
    be good。 what would be better？ Eight buckets。 Now eight buckets is kind of interesting。
    We actually still end up with a collision。 Quito and Rachel are in the same bucket
    for these。 By the way， I've run actual code behind this。 So these are literally
    where the collisions are and using Python 2。
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 比最后一个地方更好。太棒了。 [笑声]，如果四个桶不错，那什么会更好？八个桶。现在八个桶有点有趣。我们实际上仍然会有碰撞。基托和瑞秋在同一个桶里。顺便说一下，我在这方面运行了实际代码。这些地方就是碰撞的地方，使用的是Python
    2。
- en: 7 hashing。 But if I get the buckets big enough， eventually everybody will be
    in their own bucket。 which means I will find them right away。 The number of lookups
    is exactly one。 This is dramatically better than linear searching。 So does this
    sound like a really great idea？
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 哈希处理。但如果我把桶做得足够大，最终每个人都会在自己的桶里。这意味着我会立刻找到他们。查找的次数正好是一次。这比线性搜索要好得多。这听起来像个好主意吗？
- en: I think so too， but you'll notice little bits of wasted space in there。 But
    in exchange for wasted space， you get very fast lookups。 This is the advantage
    of sparsity。 The problem is is this dictionary gets bigger and bigger， even with
    size 8。 With 8 buckets in 2000 entries， see if I can drive this computer， here
    we go。 With 8 buckets。
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我也这样认为，但你会注意到里面有一些浪费的空间。但以浪费的空间换取的是非常快速的查找。这就是稀疏性的优势。问题是，随着字典变得越来越大，即使是8的大小。用2000个条目和8个桶，看看我能否驱动这台电脑，开始吧。用8个桶。
- en: if I put 2000 entries in it， the average chain would be about of length 250。
    And so as the dictionary gets slows down or as it gets bigger， it slows down。
    In fact。 there is a better way。 The solution is to periodically resize the dictionary
    so that it's never more than 2/3 full。 Essentially， we copy out all the key value
    pairs， then we loop back and set up a bigger number。
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我放入2000个条目，平均链的长度大约是250。因此，随着字典的增大，它会变慢。实际上，有一个更好的方法。解决方案是定期调整字典的大小，使其从不超过2/3满。基本上，我们复制所有的键值对，然后循环回来设置一个更大的数字。
- en: of buckets than we had before and then we reinsert it。 So whenever 8 buckets
    is not enough。 go and make 16 buckets。 After 16 buckets， 32。 And that way， no
    matter how big the dictionary gets。 it retains its performance。 Pretty awesome。
    These people in the beginning were thinkers。 And this is the way they teach it
    to you in school。
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 比我们之前有的桶要多，然后我们重新插入。所以无论什么时候8个桶不够，去做16个桶。16个桶之后，32个。这样，无论字典变得多大，它都能保持性能。真是太棒了。最开始这些人都是思考者。这就是他们在学校教给你的方式。
- en: But they leave a lot of important things out in school。 Like here's an important
    thing that you typically don't find in the textbooks。 Which is that we cache the
    hash value。 The idea is instead of this narrow table up above。 we're going to
    add an additional column to it。 And that is to actually store the full hash value
    inside。
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 但他们在学校省略了很多重要的东西。比如这是一个你通常在教科书中找不到的重要内容。那就是我们缓存哈希值。这个想法是，除了上面的狭窄表格外，我们要添加一个额外的列。那就是实际上将完整的哈希值存储在里面。
- en: At first， this appears crazy。 Why do you need a hash value when you're inside
    the hash table？ Well。 the problem is when you resize， you have to go rehash every
    key。 And potentially hashing is very expensive for a key。 And you don't want to
    do it again。 The solution to the problem is cache it so we save it inside。 At
    that point。
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 一开始，这看起来很疯狂。为什么在哈希表内需要哈希值？好吧，问题是当你调整大小时，你必须重新哈希每个键。而哈希可能对某个键来说是非常昂贵的。你不想再做一次。解决问题的办法是缓存它，以便我们将其保存。到那时。
- en: the resize code becomes a little simpler。 It says loop over our keys and values
    and the known hash value。 And then reinsert it back into the new bucket in a larger，
    bigger table。 So this is by the way。 this stuff is not pseudo code。 It all runs
    and I'll give you links to it。 Although in the end。 I'll combine it together into
    one big recipe and hand it to everybody。
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 调整大小的代码变得简单一些。它说遍历我们的键和值以及已知的哈希值。然后将其重新插入到一个更大表中的新桶中。顺便说一下，这些东西不是伪代码。它们都能运行，我会给你链接。尽管最后，我会将它们结合成一个大的配方，交给每个人。
- en: so that you can play with all of these things。 And the idea is in textbooks。
    you don't see this because it isn't essential to the algorithm， and it makes it
    use up extra space。 Do you see this third column here？ Okay， so extra space。 But
    it makes sizes very， very cheap。 I'm astonished by this even though I'm one of
    the maintainers of this code。 When I timed it。
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这样你就可以玩这些东西。这个想法在教科书中，你看不到，因为它对算法并不是必需的，并且会占用额外空间。你看到这第三列了吗？好的，所以是额外空间。但这使得大小非常、非常便宜。尽管我是这段代码的维护者之一，我对此感到震惊。当我计时的时候。
- en: I found that resizing a dictionary is about one fifth as fast as a list copy。
    It is essentially running at the speed of copy。 It makes no calls to equality。
    It makes no calls to hash。 It essentially just says， what is my current hash？
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我发现调整字典的大小大约是列表复制的五分之一快。它基本上运行的速度和复制一样。它不调用相等。它不调用哈希。它基本上只是问，我当前的哈希是什么？
- en: Take it modulo some power of two and reinsert it into a new table and loops
    over the existing keys。 It's incredibly fast。 Almost as fast as copying a list
    of keys。 Who thinks that's kind of cool？
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 取模某个二次幂，然后将其重新插入到新表中，并遍历现有键。这非常快。几乎和复制键的列表一样快。谁觉得这有点酷？
- en: Which is why we use this extra column。 All right， so the next step up is faster
    matching。 This is something that they don't teach in school as well。 In school。
    they say loop over the keys until you find a match。 If you don't find a match，
    raise a key here。 The problem is how do you know whether a key is matched？ You
    do an equality test。
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们使用额外列的原因。好的，下一步是更快的匹配。这是学校里也不教的内容。在学校里，他们说循环遍历键直到找到匹配。如果没有找到匹配，抛出键错误。问题是，你怎么知道一个键是否匹配？你进行相等性测试。
- en: Does the key equal the target key？ That makes a lot of sense in textbooks because
    the thing that they're looking for is typically a number。 Or something like that。
    So a quality test are very cheap。 But in object-oriented languages。 any object
    can define a dunder EQ that's very expensive。 For instance。 comparing two decimal
    objects involves a lot of steps because we have to line up the number of decimal
    places first。
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这个键是否等于目标键？在教科书中这很有意义，因为他们所寻找的通常是一个数字。或者类似的东西。因此，相等性测试是非常便宜的。但在面向对象的语言中，任何对象都可以定义一个非常昂贵的dunder
    EQ。例如，比较两个十进制对象涉及很多步骤，因为我们必须首先对齐小数位数。
- en: There's not just a direct comparison of values。 And so a lot of work can be
    done there。 Potentially。 if you have a database record， you have to compare every
    one of the fields in order to determine the three quality。 The moral is， in an
    object-oriented programming language， you can't assume that equality is fast。
    It can be very， very， very slow。 And if it's slow， you want to do it all the time。
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅仅是直接比较值。因此在这里可以做很多工作。潜在地，如果你有一个数据库记录，你必须比较每一个字段来确定相等性。关键是，在面向对象的编程语言中，你不能假设相等是快速的。它可能非常非常慢。如果它慢，你就想要时常进行这种比较。
- en: or do you want to avoid it？ I would avoid it。 And so there's two fast， early
    outs。 One of them is this notion that identity implies equality。 If we have two
    pointers to the same object， two variable names pointing to identically the same
    object。 we don't even have to look at the object to know that they're equal。 You
    are equal to a you。
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 还是你想避免它？我会避免。因此有两个快速的、早期的解决方案。其中一个是身份意味着相等的概念。如果我们有两个指针指向同一个对象，两个变量名指向完全相同的对象，我们甚至不需要查看对象就知道它们是相等的。你等于你自己。
- en: Doesn't that seem obvious to you？ If there's two pointers to the same object，
    it's the same object？
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这对你来说难道不明显吗？如果有两个指针指向同一个对象，那就是同一个对象？
- en: Sir， what's your name？ Oh， question。 A person on the front row on the far right
    side。 What's your name？ Ooh， I had two references to the same object。 Did I have
    to ask in both time？
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 先生，你叫什么名字？哦，问题。前排右侧的一个人。你叫什么名字？哦，我有两个引用指向同一个对象。我是否在两次都要问？
- en: Or if I knew the references were the same， did I even have to ask to know it
    was the same guy？
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 或者如果我知道引用是相同的，我是否甚至不需要问就知道是同一个人？
- en: Identity implies equality。 That person sitting in that chair is the person who's
    sitting in that chair。 regardless of how I refer to the chair。 Does that seem
    logical and obvious to you？ It does。 interestingly， everything in the Python world
    is the subject of contentious debate。 In the world of floating point numbers，
    there's the concept of a nan， not a number。
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 身份意味着相等。坐在那把椅子上的人就是坐在那把椅子上的人，无论我如何称呼这把椅子。对你来说，这似乎合乎逻辑和明显吗？确实有趣的是，Python世界中的一切都是争议的主题。在浮点数的世界中，有nan的概念，非数字。
- en: And the IEEE 754 specification of nans defines nans as not being equal to themselves。
    Are you equal to yourself？ Of course you are because you're not a nan。 But if
    you were a nan。 it would say no。 And so there's this thought that dictionaries
    break nans because if you use one as a key。 then we go back and we say， oh， I
    found that key and says， I'm not really me。 At which point。
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: IEEE 754规范中的nans定义为不等于自身。你是否等于自己？当然，因为你不是nan。如果你是nan，那它会说不。因此有这种想法，字典会打破nans，因为如果你用一个作为键，然后我们回过头来说，哦，我找到了那个键，它说，我并不是真正的我。在这种情况下。
- en: a person who is a die-hard for nans would say a nans should not be look-upable。
    You should be able to put it in a dictionary， but you should never be able to
    find it later。 And then they hold up the specification， IEEE 754 arithmetic。 What
    do I have that can trump an IEEE 754 specification？ Something of greater weight
    than that。
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 一个坚定支持nans的人会说，nans不应该可查找。你应该能将其放入字典中，但你永远不能再找到它。然后他们举起IEEE 754算术规范。我有什么能够超越IEEE
    754规范的？更重要的东西。
- en: Something we care about more。 The Zen of Python。 I hold up the Zen of Python。
    but I'm not going to tell me。 I say practicality beats purity。 If you put something
    in a dictionary and can't get it back out， that's very impractical。 It's generally
    a bad thing。 It makes it impossible to reason about the container。
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们更关心的事情。Python的禅。我举起Python的禅，但我不打算告诉你。我说实用性胜于纯粹性。如果你把东西放进字典却无法拿出来，那是非常不实用的。这通常是一件坏事。这使得推理容器变得不可能。
- en: And if I make identity implies equality， I can make dictionaries very fast。
    Do you want dictionaries that are fast and practical or do you want one that makes
    it so you can put nans in and show your mama cute trick？
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我让同一性意味着平等，我可以使字典变得非常快速。你想要快速实用的字典，还是想要一个可以放入nans并展示给你妈妈看的可爱把戏的字典？
- en: OK， so I fight it with practicality beats purity periodically though。 Once a
    year。 somebody comes back up and posts， I put a nan in a dictionary and later
    I was able to find it。 This is terrible。 And I have to fight the battle once again。
    I'm afraid if I ever retire from Python core development， this will disappear。
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，我时常与实用性与纯粹性作斗争。每年总会有人回来发帖，说我在字典中放了一个nan，后来能找到它。这太糟糕了。我不得不再次进行这场战斗。我担心如果我从Python核心开发中退休，这种情况就会消失。
- en: People will be able to put things in dictionaries and not get them back out
    and say， "I。 triple E 754。"， And Uncle Timmy would come back and haunt them from
    his grave at that time。 All right， there is a， the way hash tables work is I group
    all of you into clusters and I only have to search that cluster for you。 But if
    I'm mistaken about which cluster you're in， I'm never going to find you。 This
    is cluster one。
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 人们将能够把东西放进字典，却找不到它们，并说，“我。三重E 754。”，然后蒂米叔叔会从他的坟墓里回来缠着他们。好吧，哈希表的工作方式是我将你们分成多个簇，我只需在那个簇中搜索你。但是如果我对你所在的簇判断错误，我将永远找不到你。这是簇一。
- en: cluster two and cluster three。 If I go to look for you and cluster one， I'm
    not going to find you。 So we have a， what is known as a hash invariant。 All hash
    tables require this。 If two objects are equal to each other， then they have to
    have the same hash。 They have to be in the same cluster so that we can go find
    an object equal to that object。
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 簇二和簇三。如果我去簇一寻找你，我将找不到你。所以我们有一个被称为哈希不变式的东西。所有哈希表都需要这个。如果两个对象彼此相等，那么它们必须具有相同的哈希。它们必须在同一个簇中，以便我们可以找到与该对象相等的对象。
- en: Does that make sense？ Now I'm going to get mathematical and logical on you like
    Dr。 Sheldon Cooper from the Big Bang Theory。 We will use modus-tolens logic and
    I will express the contra positive of this statement。 That's where you switch
    the if and the then and the gate the then。 It's called denying the antecedents。
    The contra-positive says if two objects have caches that are unequal。
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这有道理吗？现在我将像《生活大爆炸》中的谢尔顿·库珀博士那样进行数学和逻辑分析。我们将使用模态否定逻辑，我将表达这个陈述的对立命题。就是将“如果”和“那么”互换，并否定“那么”。这叫做否定前提。对立命题表示如果两个对象的缓存不相等。
- en: if you were in two different clusters， then it means that you're not the same
    person。 You're not equal to each other。 So we flip it around to the contra positive
    and it gives us a fast match algorithm。 Internally dictionaries and sets use a
    fast match。 First of all， they check for identity。 Are the two objects sitting
    in the same chair？ If the answer is yes， we assume that they're equal。
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在两个不同的簇中，这意味着你不是同一个人。你们不相等。因此，我们把它翻转到对立命题，这给我们提供了一个快速匹配算法。内部字典和集合使用快速匹配。首先，他们检查身份。这两个对象是否坐在同一把椅子上？如果答案是肯定的，我们假设它们相等。
- en: Identity implies equality。 This is extremely fast。 It's just a pointer comparison。
    The next thing is we already know the hash of the object and we already know。
    the hash stored in the hash table。 As a result of that， if the hashes aren't equal。
    we don't even have to test them for equality。 We know that they are not equal
    to each other。
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 同一性意味着平等。这是非常快速的。只需进行指针比较。接下来，我们已经知道对象的哈希值，也知道哈希表中存储的哈希值。因此，如果哈希值不相等，我们甚至不需要测试它们是否相等。我们知道它们彼此不相等。
- en: And then finally， we have the slow test。 If these two early outs don't work。
    we finally have to do an equality test。 Too fast early outs in front of a slow
    test。 If you knock these two lines out of Python， it cuts its speed by more than
    half。 Are these lines kind of important？ So you like identity implies equality
    and you're not going to file a bug report about。
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们有缓慢的测试。如果这两个早期退出都不奏效，我们最终必须进行相等性测试。在缓慢测试前有两个快速的早期退出。如果你将这两行从Python中删除，它的速度将减少一半以上。这两行重要吗？所以你认为身份意味着相等，而你不会为此提交bug报告。
- en: IEEE 754 and say， "The world's not safe for nans！"， I see how it is。 That is
    an interesting test。 This one though， I've known about for a very long time the
    full impact of it though。 didn't hit me until we started to go to the 64-bit world。
    What are the odds that two hashes are going to be equal to each other and the。
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: IEEE 754说，“这个世界对nans来说并不安全！”我明白了。这是一个有趣的测试。不过，我对此的全部影响早在很久之前就知道了。直到我们开始进入64位世界时，我才真正意识到。两个哈希相等的几率是多少？
- en: objects are not going to be equal to each other？ The answer is one and two to
    the 64。 That means that with this test in place， we never， well， almost never，
    like never。 in your lifetime or in the lifetime of the universe， we will never
    have a case。 where the key is equal to the target key。 We never do an unnecessary
    equality check。
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 对象之间不会相等吗？答案是一和二的64次方。这意味着有了这个测试，我们几乎永远不会，在你的一生或宇宙的生命周期中，我们永远不会出现这样的情况：键等于目标键。我们从不进行不必要的相等性检查。
- en: So every dictionary and set look up if it finds a match does exactly one equality
    test。 even if there are collisions。 That's kind of cool。 These odds are so great
    that I conducted an interesting and funky experiment。 I replaced this line in
    Python with return true， which said， "If the hashes are equal。
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，每个字典和集合查找如果找到匹配项，则只进行一次相等性测试。即使存在碰撞，这也很酷。这些几率如此之大，以至于我进行了一个有趣且古怪的实验。我在Python中将这行替换为返回真，即“如果哈希相等”。
- en: just assume they're the same object。"， Interestingly， the entire test suite
    pass。 Django's test suite pass， NumPy's test suite pass。 In other words， this
    is a very， very。 very good assumption。 How many of you think it would be safe
    if I just took out the equality test and said。 "You don't think it'd be safe？
    How many of you think it would be unsafe if I were to just take this slow equality
    test out entirely？
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 假设它们是同一个对象。值得注意的是，整个测试套件都通过了。Django的测试套件通过了，NumPy的测试套件也通过了。换句话说，这是一个非常、非常、非常好的假设。你们中有多少人认为如果我去掉相等性测试，会安全？你们认为这样不安全吗？有多少人认为如果我完全去掉这个缓慢的相等性测试，会不安全？
- en: '"， Really？ A lot of you think it would be unsafe。 Now I''ve got another poll
    question。 How many of you use Git？ Git does exactly this。 When it compares files。
    it doesn''t look at the files。 If the hashes are equal， it believes that they
    are the same。 This was a really good idea until SHA-1 started to look kind of
    weak of late。'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: “真的吗？你们中有很多人认为这不安全。”现在我有另一个投票问题。你们中有多少人使用Git？Git正是这样做的。当它比较文件时，它并不查看文件。如果哈希相等，它就认为它们是相同的。这在SHA-1最近开始显得有点脆弱之前是个好主意。
- en: so they're actively working on switching from SHA-1 to a different hash。 where
    a person can't produce a collision easily on purpose。 All right， so all of this
    was great。 but there's a problem。 Separate chaining takes a great deal of space。
    by having all the pointers to many separate lists。 So what's the solution？
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 所以他们正在积极地从SHA-1切换到其他哈希算法。在这种情况下，一个人不能故意产生碰撞。好吧，所有这些都很好，但有一个问题。分离链表需要大量空间，因为要有许多指向各个独立列表的指针。那么解决方案是什么呢？
- en: The solution is make the table more dense， get rid of all the pointers。 and
    put all the buckets in one table。 The downside of this is you introduce a risk
    of collisions。 and the solution to it is using a linear probing。 So this is a
    pure Python code for doing linear probing。 It says look in position I and check
    to see if you found the value that you needed。 If not。
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案是让表格更密集，去掉所有指针，将所有桶放在一个表中。这种做法的缺点是引入了碰撞的风险，而解决方法是使用线性探测。这是一个纯Python代码，用于执行线性探测。它说检查位置I，看看是否找到了所需的值。如果没有。
- en: go switch to the next location and look there and look in the next place， and
    the next place。 and the next place。 So with open addressing， here's what the table
    looks like。 Interestingly。 Tim was supposed to go in Sarah's slot， but because
    it was already occupied。 he went to the next slot， wrapping it around。 This greatly
    improves the density of the table。
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 切换到下一个位置，查看那里，接着查看下一个地方，然后是下一个地方，接着是下一个地方。因此，在开放寻址中，表格看起来是这样的。有趣的是，蒂姆本该放在莎拉的槽中，但因为已被占用，他去了下一个槽，循环回去。这大大提高了表格的密度。
- en: Pretty good idea？ It is， except for one problem。 Later， if we delete Sarah from
    the list。 Tim becomes unvindable。 By the way， is Tim Peters here？ That's because
    Sarah got deleted。 In fact。 there is a better way。 The problem is removing a key
    leaves a hole。 The solution is to mark that with a dummy entry。 And the dummy
    entry says this space was used by some key。
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 不错的主意？是的，只是有一个问题。稍后，如果我们从列表中删除莎拉，蒂姆就变得无法访问。顺便问一下，蒂姆·彼得斯在这里吗？这正是因为莎拉被删除。事实上，还有更好的办法。问题是删除一个键会留下一个空位。解决方案是用一个虚位条目来标记它。这个虚位条目表明这个空间曾被某个键使用。
- en: When you're searching， go ahead and skip pass this and keep on looking until
    you find Uncle Timmy。 And here's the pure Python code for that。 You can see the
    idea is， wow， I'm going to speed up。 Is it 15 minutes to questions？ How many people
    walk out the door？ 20。 All right， good enough。 So our free slot is we track to
    see if we found any dummies。 As we do the search。
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在搜索时，可以跳过这个，继续寻找直到找到蒂米叔叔。这是纯Python代码。你可以看到，想法是，哇，我要加速了。到问题的时间是15分钟？有多少人走出门？20。好吧，足够好了。因此我们的空槽是，我们跟踪是否找到任何虚位。在搜索时。
- en: if we find a dummy， we remember where it is。 Later， if we find a hole in the
    table。 we'll go back instead of using the hole。 We'll use the original free slot，
    the dummy that we found。 And that lets us reuse the slots。 On the other hand，
    if we find a key。 we can use that fast match that we just discussed。
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们找到一个虚位，我们会记住它的位置。稍后，如果我们在表中发现一个空位，我们会回去而不是使用这个空位。我们将使用找到的原始空槽，即虚位。这使我们能够重复使用槽。另一方面，如果我们找到一个键，我们可以使用刚才讨论的快速匹配。
- en: with identity equal equality in the hash table check in order to do a quick
    check。 And this is the core logic for dictionaries。 This is known as Nuth Algorithm
    D。 And it was known right at the end of the 1960s。 It appears in the art of computer
    programming。 Turns out our grandparents knew a thing or two after all。 Multiple
    hashing。
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在哈希表中检查身份等于等式，以便快速检查。这是字典的核心逻辑。这被称为Nuth算法D。它在1960年代末时被知晓。它出现在《计算机程序设计艺术》中。结果我们的祖父母其实懂一些东西。多重哈希。
- en: The problem with linear probing is that we end up with a catastrophic linear
    pile up。 The solution is do every time you get a collision， do a rehash so that
    they don't。 pile up in the same place。 So they split off in different directions。
    And so there's two tricks there。 One is we use all the bits of a hash。
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 线性探测的问题是，我们最终会遇到灾难性的线性堆积。解决方案是每次发生冲突时，进行重新哈希，以避免它们堆积在同一个地方。因此它们朝不同的方向分散。因此有两个技巧。一个是我们使用哈希的所有位。
- en: We've got a 64-bit hash and perhaps a table with only eight entries。 So we only
    need three bits at a time。 So we gradually shift in five at a time and that's
    called perturbing。 In addition， there's a linear， cringruential random number
    generator that says。 take the current slot times five， add， one， modulo the number
    of slots to find the next one。
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一个64位的哈希，也许还有一个只有八个条目的表。因此我们每次只需要三位。于是我们逐渐每次移动五位，这称为扰动。此外，还有一个线性同余随机数生成器，它会说：将当前槽乘以五，加上一个，取模槽的数量以找到下一个槽。
- en: What's cool about this is it provably eventually visits every slot。 It means
    that hash tables don't get caught in a loop when there's collisions。 I believe
    Uncle Timmy came up with these ideas。 And so this code is Uncle Timmy's code。
    Whenever you get a collision， we print out we， perturb the bits shifting in additional
    bits。
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，这种方法能够证明最终会访问每个槽。这意味着哈希表在发生冲突时不会陷入循环。我相信蒂米叔叔想出了这些想法。因此这段代码是蒂米叔叔的代码。每当发生冲突时，我们打印出内容，扰动位并移入额外的位。
- en: multiply by five， add one， take， him modulo and update the perturb。 So in this
    structure。 we end up with no， call or all of the here's the collisions that came
    out for this as it's probing all。 of our round。 I made this a fairly dense table
    and I picked these names on purpose to create a。 lot of collisions。 So that is
    an improvement on News Algorithm D。 Are you trying to say that Tim。
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 乘以五，加一，取模并更新扰动。在这个结构中，我们没有呼叫，或者所有这些都是冲突，随着它对我们所有的轮次进行探测。我把这个表做得相当密集，并故意选择这些名字以制造大量冲突。因此，这是对新闻算法D的改进。你是在说蒂姆吗？
- en: Uncle Timmy was able to come up with something that Donald News didn't know？
    Pretty cool。 Now an early out for a look up says Victor， Stinner here。 So Victor
    Stinner is an awesome Python core developer who's been working very。 hard on improving
    the speed of Python。 One of his ideas is that internally in Python。
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 小蒂米能够想出一些唐纳德·新闻不知道的东西？挺酷的。现在，维克托·斯廷纳在这里说早期查找的情况。因此，维克托·斯廷纳是一个了不起的Python核心开发者，他一直在努力提高Python的速度。他的一个想法是Python内部。
- en: we use dictionaries a lot and， we're often looking up method names and it's
    the same method name over and over。 again and we have to repeat the dictionary
    look up every time because。 potentially the dictionary could mutate。 The better
    way is in pet 509。 which appeared in Python three six， he added a， private version
    number to the dictionary。
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经常使用字典，通常在查找方法名称，而且是同样的方法名称一遍又一遍。我们每次都必须重复字典查找，因为字典可能会改变。更好的方法是在Python 3.6中引入的PEP
    509，它为字典添加了一个私有版本号。
- en: So every time we update the dictionary， we update the version number。 That means
    that anything that wants to do a avoid repeated lookups can just keep。 track of
    the version number and say if the version number is same， I don't need。 to do
    the look up again。 And this sped up the internals quite a bit。
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 每次我们更新字典时，我们都会更新版本号。这意味着任何想要避免重复查找的东西只需跟踪版本号，并且如果版本号相同，就不需要再进行查找。这使得内部处理速度大大提高。
- en: Are you trying to tell me that Victor Stinner came up with something that uncle。
    Timmy couldn't who came up with something that Donald News couldn't come up with。
    which was better than the dinosaurs who used databases？ In fact， that's the case。
    There was a problem though with that design。 If you look at this table。
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 你是想告诉我，维克托·斯廷纳想出了一些小蒂米无法做到的事情，而小蒂米想出的事情比唐纳德·新闻更好？实际上，确实是这样。不过，这个设计存在一个问题。如果你看看这个表。
- en: it's got these holes in it and the holes are quite， wide。 It is all three fields。
    And so there's an enormous amount of wasted space inside。 This is my big idea。
    My big idea was the compact deck and essentially what I did was compress。 these
    down and got rid of all the holes。 So all of the hash values。
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 它有这些孔，孔相当宽。包含了三个字段。因此，里面浪费了大量空间。这是我的大想法。我的大想法是紧凑的字典，基本上我所做的就是压缩这些并消除所有孔。因此，所有的哈希值。
- en: the keys and the values are stored in a dense fashion。 and there's a separate
    table of indexes that's a very narrow。 Interestingly。 because we only have to
    have eight possible slots， the indexes can， be stored in one byte each。 So this
    index table is only eight bytes。 It's actually smaller than the space it takes
    to store。
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 键和值以密集的方式存储，并且有一个单独的索引表，这个索引表非常窄。有趣的是，因为我们只需要八个可能的槽，索引可以每个占用一个字节。因此，这个索引表只有八个字节。实际上，它比存储的空间要小。
- en: Quito's name， which I think is pretty awesome。 It probably doesn't seem like
    that to you because Quito's got five characters。 but string objects are bigger
    than that。 They have some overhead。 So the index table is essentially free in
    comparison to this。 No wasted space。 Dictionaries are compact。 You got the idea
    of how they got smaller and later versions of Python？
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 基多的名字，我觉得这很酷。你可能觉得这没什么，因为基多有五个字符，但字符串对象比这要大。它们有一些开销。因此，与此相比，索引表几乎是免费的。没有浪费空间。字典是紧凑的。你了解它们是如何变小的，以及后来的Python版本吗？
- en: We got rid of all the wasted space。 Are you telling me that I thought of an
    idea that Victor Sinner didn't think of。 that Tim Peterson didn't think of， that
    Nutha didn't think of。 that the dinosaurs didn't think of in their databases？
    That is in fact true。 That said。 there was a terrible problem。 The problem is
    with my dictionaries， by the way。
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们摆脱了所有浪费的空间。你是在告诉我我想出的这个主意是**维克多·辛纳**没想到的，是**蒂姆·彼得森**没想到的，是**纳萨**没想到的，是恐龙在他们的数据库里没想到的？这实际上是对的。不过，有一个可怕的问题。问题出在我的字典上，顺便说一句。
- en: I'm getting the history slightly out of order here to make it easier to explain。
    These things happen in a different order than I'm saying here。 But the problem
    is we had a dictionary for colors， a dictionary for cities。 and a dictionary for
    fruits。 Notice that all of these have exactly the same hash values。
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我有点把历史顺序搞乱了，以便更容易解释。这些事情发生的顺序和我在这里说的不一样。但是问题是我们有一个颜色字典，一个城市字典和一个水果字典。注意所有这些字典的哈希值完全相同。
- en: exactly the same， keys over and over again， repeated。 If you have a thousand
    instances。 you have a thousand dictionaries， where two thirds of the space is
    completely redundant。 This can't be solved by people like me or Victor。 We're
    not smart enough。 No， it came from a PhD。 Mark Shannon and PEP of 412， a key sharing
    dictionary。 The idea is we share the first two columns。
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 完全相同的键，一遍又一遍地重复。如果你有一千个实例，你就有一千个字典，其中三分之二的空间是完全冗余的。这无法由像我或维克多这样的人解决。我们不够聪明。不，这个想法来自一位博士，**马克·香农**和PEP
    412，一个键共享字典。这个想法是我们共享前两列。
- en: So all of that compacts down to this， which means we've got four dictionaries。
    In one little space here with no gaps in between。 Do you see all these ideas dove
    together really well？
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 所以所有这些都压缩成这个，这意味着我们有四个字典。在这里的一小块空间里，没有间隙。你看到这些想法融合得很好吗？
- en: So let me take you into the present。 Let me take you into the future。 The future
    is something I'm working on right now with sets。 Because this part is so cheap。
    it's only eight bytes。 Would it cost me very much to make it bigger and to double
    the size of it and make it less sparse？
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 所以让我带你进入现在。让我带你进入未来。未来是我正在用集合工作的一件事。因为这一部分非常便宜，只有八个字节。把它变得更大，双倍其大小并减少稀疏性会花费我很多吗？
- en: The answer is no。 I hear people clapping in the other room。 That's a bad sign。
    OK。 And so the only difference here is not this data。 It is this index table is
    twice as big as it was before。 It's got 16 entries， which means it went from eight
    bytes to 16 bytes。 And it's still smaller than Quito's name。 It's the size of
    two of these hash values。
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 答案是否定的。我听到旁边房间里有人在鼓掌。这是个坏兆头。好的。因此，这里唯一的区别不是这些数据，而是这个索引表的大小是之前的两倍。它有16个条目，这意味着它从八个字节变成了16个字节。它的大小仍然小于基多的名字。它是这两个哈希值的大小。
- en: It's nothing in comparison to the total table。 But I've doubled the sparsity。
    What's cool about this is。 One second。 What's really nice about this structure
    is we've completely eliminated all of the collisions。 If you make the table sparse
    enough， there's no collisions at all。 And it turns out we can now make them sparse
    essentially for free。 Who learned something new？
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这与整个表相比算不了什么。但我把稀疏性翻倍了。这个结构的好处在于，我们完全消除了所有的冲突。如果你让表足够稀疏，就完全没有冲突。而且我们现在基本上可以免费让它们变得稀疏。谁学到了新的东西？
- en: So that's going to be in the future。 And the first generation will do even fewer
    steps to look up and the same is with sets。 By the way， have you seen anything
    that looks like this before？ Really？ Yes。 it was up at the top of the of the page。
    Do you remember what those dinosaurs did a long time ago？
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这将会在未来。第一代将进行更少的查找步骤，集合也是如此。顺便问一下，你之前见过像这样的东西吗？真的？是的，它在页面的顶部。你还记得那些恐龙很久以前做了什么吗？
- en: '[ Laughter and Applause ]， Here in the third millennium， we''ve reindented
    databases with indexes。 [ Laughter ]， That said， they''re pretty badass。 They''re
    compact。 They iterate faster。 And as a side effect of how we build them， they
    preserve order。 So in Python 3。6， dicks are smaller。 And faster。 Space efficient。
    Beautiful。 And key sharing。'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[笑声和掌声]，在第三个千年里，我们重新设计了带索引的数据库。[笑声]，话虽如此，它们相当厉害。它们紧凑，迭代更快。作为我们构建它们的副产品，它们保持顺序。因此在Python
    3.6中，字典更小，更快，空间效率高，美观，并且实现了键共享。'
- en: And if you get a million instances with a million dictionaries， none of this
    data over here。 these two columns are repeated at all。 In fact， the incremental
    space is just a space that stores the values for that individual one。 Who learned
    something new？ All right。 I had some odds and ends at the end。 Let me just say
    a couple of them real quickly。 We still need a hit， sit， passion Python。
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你得到一百万个实例和一百万个字典，这里没有任何数据。这两列在任何情况下都是重复的。实际上，增量空间只是存储那个特定值的空间。谁学到了新东西？好吧。我最后有一些琐事。让我快速说几句。我们仍然需要一次成功、坐着、热情的Python。
- en: The purpose of that is it turns out some people are diabolical and try and create
    keys。 that intentionally collide。 We fought back against them by putting a cryptographic
    cache that's receded everything。 Time Python starts up so it's very difficult
    to come up with keys that collide。 Also。 sets use a different strategy。 They use
    multiple chaining and linear probing because sets are about something different。
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做的目的是，有些人非常阴险，试图创建故意碰撞的键。我们通过放置一个加密缓存来抵御他们，这个缓存会回避一切。Python启动时，产生碰撞的键非常难以构造。此外，集合使用不同的策略。它们使用多重链和线性探测，因为集合关注的是不同的事情。
- en: dictionaries。 Dictionaries are about looking something up。 Sets are about determining
    whether something is actually there or not。 Dictionaries。 you typically know the
    thing is there。 You just don't know what the value is。 Different use cases。 a
    different balance of strategies。 A popular thing to talk about on Hacker News
    now is Cuckoo Hashing。
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 字典。字典是用来查找某些东西的。集合是用来确定某些东西是否确实存在。字典中，你通常知道某物存在。你只是不知道它的值是什么。不同的用例，不同的策略平衡。现在在Hacker
    News上讨论的一个热门话题是布谷鸟哈希。
- en: And a number of languages are using it。 How well does that mesh with this？
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 一些语言正在使用它。这与此的契合度如何？
- en: And the answer is nothing I've described conflicts with Cuckoo Hashing。 Cuckoo
    Hashing is simply a different arrangement at the index table。 but the rest of
    this could survive。 We could still do it。 I don't think we should because we have
    no need for densification at this point given。
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这些我所描述的内容与布谷鸟哈希（Cuckoo Hashing）并不冲突。布谷鸟哈希只是索引表的不同排列方式，但其余部分仍然可以生存。我们仍然可以做到。我认为我们不应该这样做，因为在目前的情况下，我们并不需要密集化。
- en: that we've already reached a maximum density。 And Cuckoo Hashing is all about
    increasing the number of collisions。 Whereas making it sparse is all about decreasing
    it。 And I think that would be a step in the wrong direction。 Additionally。 there's
    one other piece of logic inside。 In a safe world。
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经达到了最大密度。而布谷鸟哈希完全是为了增加碰撞的数量。而稀疏化则是为了减少碰撞。我认为这将是一个错误的方向。此外，还有另一部分逻辑。在一个安全的世界里。
- en: someone loops over a dictionary and they don't change it while they're looping
    over it。 The analogy is you put a ladder up on the side of a house。 you take out
    a saw and you cut out the ladder underneath you。 That's what happens when you
    mutate a structure while you're iterating。
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 有人遍历一个字典，并且在遍历时不对其进行更改。这个比喻就像你把梯子放在房子的侧面，然后拿出锯子把梯子从你下面锯掉。当你在迭代时修改结构时，就会发生这种情况。
- en: And so we have logic to guard against that so that the dictionaries and sets
    won't seg fall。 If you're interested when I post all these slides。 all of this
    combined together is in a single piece of code。 This was something that I posted
    about four years ago。 It is pure Python code。
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们有逻辑来防止字典和集合出现段错误。如果你感兴趣的话，当我发布所有这些幻灯片时，所有这些内容合在一起是一个代码块。这是我大约四年前发布的。这是纯Python代码。
- en: It is a complete implementation of compact dictionaries from scratch。 And everything
    I showed you is in here somewhere。 The generation of the probes with Tim Peters
    sequence。 the dummy entries， the compact indices， the resizing logic， the fast
    matching。 All of that is in here。 And so I will post this shortly and in the end，
    here's what we get。
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这是从头开始实现的紧凑字典的完整实现。我展示给你的一切都在这里某处。探测器的生成使用了Tim Peters的序列，虚拟条目、紧凑索引、调整大小的逻辑、快速匹配。这一切都在这里。所以我将很快发布这个，最后，我们得到的就是这些。
- en: The output of this is this beautiful little dictionary。 which is what I posted
    to Python Dev back in 2012。 Congratulations。 Welcome to the third millennium。
    [Applause]， Hey。 So it looks like a bunch of you are going to lunch。 That's fine。
    Just be quiet while you're leaving the room。 There are plenty of people who are
    sticking around and probably want to ask some questions。
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这个输出就是这个漂亮的小字典。这是我在2012年发给Python开发者的。恭喜你们。欢迎来到第三个千年。[掌声]，嘿。所以看起来你们中有很多人要去午餐。这没问题。离开房间时请保持安静。还有很多人留在这里，可能想问一些问题。
- en: If you do have a question， there are microphones in the in the aisles here。
    Sure。 Thank you。 All right。 Let's call it a day and go eat。 Yeah， everybody， please
    thank Raymond Hadinger。
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有问题，这里走道上有麦克风。好的，谢谢。好吧。今天就到这里，大家去吃饭吧。是的，请大家感谢雷蒙德·哈丁格。
- en: '![](img/c15e81bfa56cedacdd05349ba2e93c1b_5.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c15e81bfa56cedacdd05349ba2e93c1b_5.png)'
- en: '[Applause]。'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[掌声]。'
- en: '![](img/c15e81bfa56cedacdd05349ba2e93c1b_7.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c15e81bfa56cedacdd05349ba2e93c1b_7.png)'
- en: Oh， I remember。
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 哦，我记得了。
