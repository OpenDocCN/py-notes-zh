- en: P1：¡Escuincla babosa! - Creating a telenovela script in three Python deep learning
    - leosan - BV1qt411g7JH
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It's opportunities。 So let's please welcome Lorraine Amesa。 She'll be giving
    the talk Esquincla Babosa， creating a telenovela， script， and three deep learning。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_1.png)'
  prefs: []
  type: TYPE_IMG
- en: frameworks。 [APPLAUSE]， Excellent。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_3.png)'
  prefs: []
  type: TYPE_IMG
- en: OK， can you all hear me all right？ Very cool。 I naturally am a loud person and
    use a lot of hand motion。 So this will be great because I think it， goes with
    a topic pretty well。 So yes。 if you were staring at the name of this talk， and
    you're like， I don't think there's English。 in some of this。 You are correct。
    You're in the right place。 Esquincla Babosa。
  prefs: []
  type: TYPE_NORMAL
- en: creating a telenovela script， and three Python deep learning frameworks。 Side
    note。 I will be actually on some of the slides。 There is a URL that you can actually。
    follow along with the slides。 And I do actually have all my content linked。 to
    the GitHub repository that has this code。 And there's a surprise of another GitHub
    repository。
  prefs: []
  type: TYPE_NORMAL
- en: at the tail end。 So who am I？ Ola， soy， la rena mesa， with our learning， glets
    or espanol。 But I will obviously be talking in English for this talk。 It is not
    pike， charlas。 So the topic。 I personally am just really， interested in deep learning。
    I hear the term deep learning。 And I'm like， what's so deep about this learning？
    So I'm really just kind of curious about this topic。
  prefs: []
  type: TYPE_NORMAL
- en: And I also really love telenovelas。 So when I was thinking about a topic。 it
    felt like a very big win-win for me。 So why not？ Why not？ But actually， more practically。
    I actually， work as a data engineer at GitHub。 And I sit between two teams in
    the data org。 My team's name is Software Intelligence Systems， which， is a little
    bit of a mouthful。
  prefs: []
  type: TYPE_NORMAL
- en: S-I-S for short。 And the teams that I work with are our semantic code team。
    and our machine learning team。 Our machine learning engineers are increasingly。
    talking about different deep learning techniques， and using GPUs。 And a lot of
    these kind of techniques I hadn't used before。
  prefs: []
  type: TYPE_NORMAL
- en: So why not marry my interest and try a little toy session。 and see what I can
    learn about deep learning， and share with you all in a Python talk？
  prefs: []
  type: TYPE_NORMAL
- en: I do some other work in the Python space as well。 I'm in Chicago。 I help run
    Pi Lady Chicago。 And I'm also on the Python Software Foundation board， of directors。
    Yay。 [LAUGHTER]。 If you do have any questions about those things， again， you can
    find me later。 So I'm a bit curious how many of you。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_5.png)'
  prefs: []
  type: TYPE_IMG
- en: may have seen some of these headlines floating around。 Oops。 Sorry about that。
    Let me go to the next slide。 OK， excellent。 Did anyone see this headline floating
    around about this AI。 generated script starring David Hasselhoff？ No？ OK， you
    should watch it。 It's this really interesting and absurdist eight minute short。
    And the creator of this。
  prefs: []
  type: TYPE_NORMAL
- en: Ross Goodwin， who is a creative technologist in Google's Artist， and Machine
    Learning program。 actually used a RNN， a recurring， neural network to actually
    generate all the lines that。 were in the short for David Hasselhoff script。 The
    short is quite interesting。 It's very ephemeral。 It's not quite clear what's happening。
    But when I first saw this headline。
  prefs: []
  type: TYPE_NORMAL
- en: it actually got me thinking about the intersection of art， and technology。 And
    this was something I never really， have thought about before。 What happens if
    we can maybe automate the idea， the creativity process？
  prefs: []
  type: TYPE_NORMAL
- en: What does that actually look like？ Another place that I kind of started seeing
    this floating。 around， as one does， lots of conversations on Twitter。 Specifically。
    this is from a screenshot from a chat that， was March 2018， wherein someone alleged。
    that they took all of the scripts of the various saw movies， and no。
  prefs: []
  type: TYPE_NORMAL
- en: I do not know how many there are。 And apparently developed a neural network。
    and allegedly trained it for 1，000 hours， whatever that means， to generate this
    script。 And this script is supposed to be a horror script。 And in the script，
    that first line， it says。 a sexy woman， Becky， sex woman， is covered by a bed。
    She's in a whale。
  prefs: []
  type: TYPE_NORMAL
- en: but doesn't know she's in a whale。 And it's a very confusing piece of text。
    The part on the right-hand side that kind of continues， to go into this a little
    bit starts。 talking about how this is a really interesting application。 of neural
    networks to try to create an on-meath idea， with text generation of movie scripts。
  prefs: []
  type: TYPE_NORMAL
- en: However， they do start asking questions， about why are the words in the vocabulary。
    used in this script， including such language as Trump and Whale。 The person then
    goes on to critique to say， actually。 nowhere in the saw movies are these two
    words appearing。
  prefs: []
  type: TYPE_NORMAL
- en: And if you know anything about neural networks， and by the end of this talk，
    you will， a little bit。 that can be a little problematic because as a neural network，
    is learning。 it learns from the corpus of text， that you provide it。 So if you're
    allegedly providing it the saw scripts。
  prefs: []
  type: TYPE_NORMAL
- en: and it's coming up with words it had not ever seen before。 can we say this is
    actually an AI-generated script？ I don't know。 Either way。 I think this thread
    is very interesting， and it started poking a lot of questions。 and maybe you want
    to actually try my own example。 The Whale did that。 It became a meme。
  prefs: []
  type: TYPE_NORMAL
- en: You can go find out more about this script。 But there's a lot of people that
    are starting。 to think about what is the intersectionality of creativity， and
    technology。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_7.png)'
  prefs: []
  type: TYPE_IMG
- en: So you might be asking， why tel noveles？ Also， what in the world is a telenovela？
    Well。 you came to the right place。 I'm here to inform you about one of the most
    epic meltdowns。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_9.png)'
  prefs: []
  type: TYPE_IMG
- en: in a telenovela that has ever happened。 So do I have any telenovela fans in
    here？ Yes。 OK。 that's exciting for me。 So maybe some of you remember this one，
    Maria La Del Barrio。 which is a beloved Mexican telenovela， from the 1990s。 I
    believe specifically 1995 to 1996 with like 195 episodes。
  prefs: []
  type: TYPE_NORMAL
- en: But this scene-- and the images might be a little hard to see。 but this scene
    includes some of the characters， of where we get the beloved phrase。 Esquinga
    La Babosa， which is in the title of this talk。 So we have on the top two。 we've
    got a love-struck couple。 We have Alithia to the left， and we have Nambito to
    the right。
  prefs: []
  type: TYPE_NORMAL
- en: And the main character who's shown on the right-hand side， and also that third
    panel at the bottom。 that is Soraya。 So she is our main character of this telenovela。
    And Soraya。 she's got some complex history going on。 So she is the-- she's a stepmother
    of Alithia。 And then Nambito is her ex-husband's son。 Right。 And the thing here
    is Soraya is still desperately。
  prefs: []
  type: TYPE_NORMAL
- en: desperately in love with Nandito's father。 Like to the point of maybe there
    was like a restraining order。 So she's desperately-- she's desperately in love，
    with Nandito's father。 And she's stuck in a marriage， though， where she's， got
    this daughter， Alithia。 So she happens to walk into the room， where Alithia and
    Nandito are starting。
  prefs: []
  type: TYPE_NORMAL
- en: to express their love for one another。 Nandito very tenderly says， may Alithia
    please have a kiss。 And as they're leaning into this moment， in comes Soraya。
    And Soraya is like， what is going on？
  prefs: []
  type: TYPE_NORMAL
- en: I don't understand， because for her， this shatters， I guess。 her master plan
    to get back with Nandito's father。 Essentially。 she then screams and calls Alithia
    Esquincalababoso。 which kind of means use world rotten bread in nice speak。 And
    what then ensues is the most epic fight。 I guess we can call it。 There's a lot
    of kind of air slaps。 You can very， very specifically tell。 that there's not any
    contact happening。 There's people like diving over beds to protect one another。
    some random gentleman in a suit walks in， and is like trying to break up the fight。
  prefs: []
  type: TYPE_NORMAL
- en: His character is in no way， shape or form， explained， as to why he's there。
    And then the nanny。 the nanny here， she walks in。 And what that says in Spanish
    here is， this woman is， this woman is。 she's got problems。 She is possessed by
    the devil。 So this scene and all the kind of trope of love。 and complex family
    relationships。 And the idea that we all have this trauma。
  prefs: []
  type: TYPE_NORMAL
- en: that's near and dear to our heart， that leads us into what Eta de novella is。
    And so Jorge Gonzales in talking about tell novella， he's a sociologist kind of
    commenting。 on the impact and social phenomena of tell novella。 Basically says
    they are melodramas。 And these are serial melodramas。 You get increments of 25，
    30 minutes， maybe five times a week。
  prefs: []
  type: TYPE_NORMAL
- en: But what happens here， because it is a stable relationship， that you're making
    with the audience。 people become very passionate and very connected， with these
    narratives。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_11.png)'
  prefs: []
  type: TYPE_IMG
- en: To the extent that when we talk about tell novella， there's about two billion
    people worldwide。 who consume tell novella that are from Latin America。 That's
    about like a third of the world population。 So that's a pretty sizable number。
    And if you want to know more about why tell novella， is our big deal。
  prefs: []
  type: TYPE_NORMAL
- en: here's some stats of some of the viewing， and patterns of viewing of Latin American
    tell novella。 So Latin American tell novella have been viewed， in over 100 countries。
    They have generated over $800 million， in marketing on various tell novella in
    a five year period。 I believe that stat is 2010 to 2015。 And just generally speaking，
    this is a global phenomenon。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_13.png)'
  prefs: []
  type: TYPE_IMG
- en: So in breaking down the arc of a tell novella， because if we want to try to
    emulate。 and create a tell novella with a neural network， we need to understand
    what it is we're trying to create。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_15.png)'
  prefs: []
  type: TYPE_IMG
- en: So back to kind of thinking about that kind of relationship， and things that
    pop up。 One of the things that's interesting about tell novella。 is this idea
    that there's not really any cliffhangers， or kind of open ended stories。 Dr。 Rios
    who talks about tell novella， and kind of understanding their social impact。
  prefs: []
  type: TYPE_NORMAL
- en: specifically says that at the end of the tell novella， things have to be cleared
    up。 So in our Maria de la Barrio， for example， if we have the character Maria
    and we want to know。 what's happening， she would hypothesize and say， our audience
    doesn't want to worry about Maria。 We don't want to know if she didn't find her
    true love。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_17.png)'
  prefs: []
  type: TYPE_IMG
- en: her true mother， her true father， we like want all those answers。 So unlike
    English soap operas。 which I think some have been going for more than like 15，
    20 years。 what happens with that on novella， is you have a fixed melodramatic
    plot line。 And yes。 it's going to be lost loves。 It's going to be mothers and
    daughters fighting。
  prefs: []
  type: TYPE_NORMAL
- en: It's going to be long lost relatives。 It's going to be love found。 It may be
    as quickly as you found that love。 Something happens where that person is shipped
    away。 and we don't know what happened to them。 Maybe the guy in the suit， he's
    from an ela de la novella。 I don't know。 But our telenovelas have a finite beginning
    and end， and they're generally tied up。
  prefs: []
  type: TYPE_NORMAL
- en: with a very big happy element at the end。 So for example， like the world's largest
    wedding。 If you watch Casa de las velores， like there's kind of some of that。
    maybe there's being built up to。 But yes， there's always this idea。 We've got
    a fixed arc。 a lot of intricate kind of heart wrenching moments， but it's going
    to wrap up with something happy。
  prefs: []
  type: TYPE_NORMAL
- en: that we can all feel good about and move on， with our lives and not wonder what
    happens to these characters。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_19.png)'
  prefs: []
  type: TYPE_IMG
- en: So for thinking about examples of telenovelas， let's take a look at some of
    the ones。 that are available to us in Spanish。 So this is Kate Del Castillo， who
    I swear。 I think she's like my role model in life。 She's fantastic。 If any of
    you like watch that documentary， about talking with Chapo， who's an article， Troficante。
  prefs: []
  type: TYPE_NORMAL
- en: she was doing that with Sean Penn， because that's what she does in her free
    time。 But she's very famous。 She's been in many telenovelas。 And one of the ones
    that is most known is La Reyna del Sor。 So that's an example of one that is really，
    really popular， in Mexico， and then many of us may know。
  prefs: []
  type: TYPE_NORMAL
- en: Jose Betelafeja。 Because actually， some of these telenovelas， have crossovers
    in English。 So the ones that I looked at， because again， we're predominantly，
    an English speaking population。 I looked at popular telenovelas in Spanish， looked
    for their English crossovers。 and then worked with that text。 So Queen of the
    South， which is actually on USA。
  prefs: []
  type: TYPE_NORMAL
- en: talks to us a little bit about that narrative， with Kate Del Castillo。 In this
    one。 in the Queen of the South， essentially what we have is the character who。
    we have a character who becomes the most prominent drug， lord trafficker in South
    Spain after she。 has to flee Mexico because her beloved is actually captured。
  prefs: []
  type: TYPE_NORMAL
- en: by the cartel that's poaching drugs in that area。 So of course， as one does。
    you relocate to another country， and then you start your vast drug empire。 So
    that one's going to have love lost。 It's going to be a thriller。 It's going to
    be a drama。 And it's going to be high emotional action impact。 And then with ugly
    Betty， what we have。
  prefs: []
  type: TYPE_NORMAL
- en: is more or less a rom-com。 This actually started in Colombia， and it's had，
    I think。 three or four crossovers， to different Spanish speaking markets starting
    in 1999， in Colombia。 But essentially， what we have is， what we have is a character，
    a Beatriz， who works in the fashion。 industry and is considered ugly because stereotypical
    things。
  prefs: []
  type: TYPE_NORMAL
- en: like she has braces and she has glasses and things， that I have all worn in
    my life。 But anyways。 it's all about the story， about her struggles working in
    the fashion industry。 and trying to find love。 And then Jane the Virgin actually--。
    now I said I looked for popular crossovers， from Spanish to English， but for this
    one。
  prefs: []
  type: TYPE_NORMAL
- en: because I think there's enough comfort and knowledge， for people of what this
    one is--。 Jane the Virgin is actually a satirical melodrama， but it's fantastic
    because essentially， we。 follow Jane， who is a virgin， who， after visiting a doctor's，
    office， somehow becomes artificially。 and seminated and becomes pregnant。 So she's
    a pregnant virgin， and then various things。
  prefs: []
  type: TYPE_NORMAL
- en: that unfold afterwards， and how she finds love， or how she doesn't find love
    leads us。 into this complex story that is Jane the Virgin。 So in thinking about
    telenovelas。 we understand a little bit of the arc。 We understand that it's a
    melodrama。 We understand that it has finite end。 We understand it's going to wrap
    up with something happy。
  prefs: []
  type: TYPE_NORMAL
- en: and we understand some of the trips that may be employed。 So now。 how can we
    start applying this to deep learning？ When we think about machine learning。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_21.png)'
  prefs: []
  type: TYPE_IMG
- en: and I'm not sure if many of us in here do machine learning。 some of the things
    that you may think of are some of the language。 that's provided to us by the founders
    of this discipline。 So Arthur Samuel。 who actually coined the term machine learning，
    actually provides us with this language。
  prefs: []
  type: TYPE_NORMAL
- en: saying that machine learning is a field of study， where computers have the ability
    to learn without being。 explicitly programmed。 So there's this idea that there's
    something that's not requiring。 us to actually have some intent or some purpose。
    So that is where we can start with machine learning。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_23.png)'
  prefs: []
  type: TYPE_IMG
- en: Now， as we see here at PyCon， there's， many various talks that may talk about
    data science。 or machine learning， and this is a very， very， very， very vast space。
    So if we were looking at。 for example， technology and tools， we may see things
    like Python。 We may be talking about things like Spark or Julia， or other scientific
    programming languages。
  prefs: []
  type: TYPE_NORMAL
- en: If we're talking about the kind of problems we can solve， with machine learning。
    we'll see the problem categories， on the bottom left-hand side。 We might be doing
    classification。 clustering， optimization， kind of problems。 However。 what we want
    to focus on is this idea of a subfield。 So when we talk about deep learning。
  prefs: []
  type: TYPE_NORMAL
- en: deep learning is a subfield。 It's a type of machine learning and is alongside
    other categories。 such as maybe ones you may have heard of， supervised。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_25.png)'
  prefs: []
  type: TYPE_IMG
- en: unsupervised， semi-supervised。 So to broaden on that definition of machine learning。
    and challenging us to think about how we can actually。 have a deep learning model
    that can actually generate an ML， script。 we probably need to reconceptualize，
    what machine learning means。
  prefs: []
  type: TYPE_NORMAL
- en: So this is a great definition given to us by Tom Mitchell。 And Tom Mitchell。
    the former chair of the computer science， department at Carnegie Mellon， who。
    wrote the quintessential book on machine learning published， in 1997。 It stands
    up really well。 I highly recommend reading it。 Basically says， when we think about
    machine learning。
  prefs: []
  type: TYPE_NORMAL
- en: it's not so much that it's a program that， isn't explicitly programmed。 But
    instead。 there's something that we want to accomplish。 So if we're thinking about
    a computer program that's。 said to learn， let's think about it in this framework。
    We have some objectives。 So we have a task that we want to accomplish。 And in
    order to accomplish that task。
  prefs: []
  type: TYPE_NORMAL
- en: we need to be able to provide it with some ability， to understand what that
    task is。 So we have a task， and then we provided some understanding。 to understand
    what some ability to understand what， that task is， which is the experience。 And
    then as that program continues， to attempt to do that task， we can develop a performance。
  prefs: []
  type: TYPE_NORMAL
- en: measurement to understand how it's improving over time。 So this language gets
    us a little bit closer， to thinking about what machine learning is when。 it applied
    to deep learning。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_27.png)'
  prefs: []
  type: TYPE_IMG
- en: But it doesn't get us out the way。 So the trend with machine learning over time--。
    and it's kind of wild to think that in the 1950s， and some of these algorithms
    that we're talking about today--。 naive base， for example-- this is not new math。
    This is not new algorithms。 These are things that have been out there for 20 plus
    years。
  prefs: []
  type: TYPE_NORMAL
- en: But what we're seeing in the trend of the world， of machine learning and what
    does it mean for a machine。 to learn， we start with this realm of artificial intelligence，
    to move into machine learning， which。 is， again， that idea of a program not having，
    to be explicitly programmed to do that task。 And then we move into this world
    of deep learning。 And we start hearing about these things。
  prefs: []
  type: TYPE_NORMAL
- en: called neural networks， which sounds very sci-fi and very， unclear what that
    is。 Frame it a little bit more simply， if we， were to think about what it means。
    that this evolution from AI to deep learning， we can say that an example of an
    artificial intelligence。 program is a door sensor because it's， able to adapt
    to its environment around it。
  prefs: []
  type: TYPE_NORMAL
- en: With a machine learning， we can say， an example of a machine learning program
    is our spam filters。 We all know it。 We see it in our various email inboxes。 The
    idea that we know spam when we see it。 can we teach an algorithm how to do that？
    Yes， we can。 And we've done that with machine learning。 Now， from moving into
    the realm of deep learning， what we start getting into is this idea of using。
  prefs: []
  type: TYPE_NORMAL
- en: these neural networks that drives its own learning。 That is the engine by which
    the learning is empowered。 And if you see on this right-hand side here。 this project
    is called the Deep Dream， which， came from Google Research， wherein they。 are
    providing an image of an object to an algorithm。 And with the desired intent and
    output to say。
  prefs: []
  type: TYPE_NORMAL
- en: tell us what you see in this image。 So what we start seeing on the other side，
    is if we provide it。 let's say， an image of an apple， it's like， OK， I understand
    that this is an apple。 But what other images do I see in it， and what can I infer
    from this image that I'm seeing？
  prefs: []
  type: TYPE_NORMAL
- en: So kind of flipping it a little bit on its head， and getting into the realm，
    maybe。 to Android's dream of electric sheep， that's where we start saying， OK，
    we're。 going to give you some ideas， some definition。 But using this neural network，
    we。 want you to drive your own learning。 So if we were thinking about an example
    of applying deep。
  prefs: []
  type: TYPE_NORMAL
- en: learning to， let's say， a classification problem， if I had something like a
    flashlight。 and I wanted it to respond and learn from audio cues， to turn on，
    we could say， let's say。 I want to have a flashlight that if I say the word dark，
    it turns on。 Well。 with a deep learning implementation， it wouldn't just have
    that fixed understanding of saying， OK。
  prefs: []
  type: TYPE_NORMAL
- en: dark maps to turn on because this， is the task of bringing light to the world。
    But instead。 it might understand other cues， other verbal cues that I might be
    able to supply to this model。 So I might say something like， I can't see， or the
    light switch won't work。 With a deep learning kind of implementation， the neural
    network would be able to learn and infer。
  prefs: []
  type: TYPE_NORMAL
- en: these other kinds of words that may fill in， to suggest that there's an absence
    of light。 to suggest that the area around you is dark。 So this learning， again，
    that happens， the brain。 which is that neural network， happens with an activation
    method。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_29.png)'
  prefs: []
  type: TYPE_IMG
- en: So moving now back to telenovelas， there's a type of problem called text generation。
    that we're going to be looking at。 So text generation is sequence processing。
    and sequence processing has a lot of applications， in the world of deep learning。
    We can use it for video processing， price modeling， and yes， text generation。
    Essentially。
  prefs: []
  type: TYPE_NORMAL
- en: what we want to do is there's， two approaches that we can have。 Using language。
    so actually using a body of text， we can say we want you to look at the individual
    words。 that are in this text to actually generate， some text on the other side，
    or we can actually develop。 the deep learning model to actually look at the individual。
  prefs: []
  type: TYPE_NORMAL
- en: characters that are provided in the corpus， that we're working with。 Either
    way。 given the text that we， provided to the sequence processing model that we
    use。 what it's going to start trying to do， is approximate the relationship of
    what words mean。 what the relationship between one word is to another。
  prefs: []
  type: TYPE_NORMAL
- en: and then as it tries to understand the relationship， between words。 try to think
    about how it is that it can build， its own patterns and generate its own vocabulary
    that。 kind of models the relationships it sees in this corpus of words， that we
    provide it。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_31.png)'
  prefs: []
  type: TYPE_IMG
- en: So I've been using the words neural networks， and deep learning a little bit
    interchangeably。 And while I want you to understand that there， are these artificial
    neural networks。 what essentially deep learning is it actually。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_33.png)'
  prefs: []
  type: TYPE_IMG
- en: makes use of several neural networks。 And when we talk about neural networks。
    the power that drives a neural network is the neuron。 So the neuron here is it's
    got three parts。 We have the inputs， we have the weights， and then we have the
    activation function。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_35.png)'
  prefs: []
  type: TYPE_IMG
- en: So essentially what's happening is our words， are going to be the inputs， and
    we're。 going to represent those as either words or as either characters。 We then
    apply an arbitrary weight to it， and then as it runs through each layer in our
    neural network。 it's going to start trying to approximate that relationship。
  prefs: []
  type: TYPE_NORMAL
- en: to understand relationships either from word to word， or character to character。
    And then it's going to go through this activation function。 whereas it's learning
    these relationships， it starts adjusting those weights。 to try to find the optimal
    weight to use， to actually start generating a thing， or in our case。
  prefs: []
  type: TYPE_NORMAL
- en: generating text。 So the activation function， you can think， of something like
    a sigmoid function。 So essentially what we have is some kind of function。 that
    is a nonlinear function that is going to allow us to actually， start doing some
    math。 So if we have a weight applied to a word， let's say， it starts at 0。5。
  prefs: []
  type: TYPE_NORMAL
- en: but we need to start shifting it either higher， or lower based on the relationship
    between these words。 that the network is learning。 We've got this activation function
    to help us do that。 So when we're training a neuron， essentially what we need
    to do， is these three steps。 The neuron takes an initial guess at classifying
    the sample。
  prefs: []
  type: TYPE_NORMAL
- en: and then updates the guess by adjusting the weights。 and then it goes ahead
    and repeats and tries again。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_37.png)'
  prefs: []
  type: TYPE_IMG
- en: So this process is very iterative。 And with neural networks， there's。 many kinds
    of neural networks that we can use--， feed forward， radial basis function， or
    an RNN。 And RNNs are good for sequential processing problems， like text generation。
    And what's really cool about this， is that it actually allows us to propagate
    data back and forth。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_39.png)'
  prefs: []
  type: TYPE_IMG
- en: So as our neurons are all connected， so a deep neural network would be an example
    of what。 we have on the right-hand side。 Basically， it's a directed graph。 We
    have input going from one node。 but also we can move backwards。 So using an RNN，
    insights learned upstream or downstream。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_41.png)'
  prefs: []
  type: TYPE_IMG
- en: can move back and forth across these neurons。 So if we wanted to make an RNN
    in Python。 how do we do it？
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_43.png)'
  prefs: []
  type: TYPE_IMG
- en: Well， there's more than one way， as we like to do。 So there's three really popular
    frameworks。 Keras， TensorFlow， and PyTorch。 And yes， I'm going to borrow the language
    from the 2017 keynote。 but yes， Python is surprisingly super awesome， or maybe
    unsurprisingly super awesome at scientific programming。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_45.png)'
  prefs: []
  type: TYPE_IMG
- en: So these three frameworks， when you're， thinking about which ones to use。 I
    like to think about questions to help me think about what， tools best for the
    task at hand。 How much technical expertise is needed to start using it？ What are
    your requirements？ For example。 do you have a certain SLO？ Do you have to meet
    what's the size of data you're working on？
  prefs: []
  type: TYPE_NORMAL
- en: Working with。 And also， how easy is it to start using the framework？
  prefs: []
  type: TYPE_NORMAL
- en: So if we're looking at making an RNN in Python using Keras。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_47.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_48.png)'
  prefs: []
  type: TYPE_IMG
- en: we've got these three steps that we're always， going to be emulating。 Basically。
    we have to take that text that text， and we have to transform it either into characters
    or words。 So we tokenize it。 Then once we've tokenized it， we generate these hot
    encodings。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_50.png)'
  prefs: []
  type: TYPE_IMG
- en: which basically gives us-- let's say on the next slide， this actually gives
    us a nice example。 Let's say our corpus is the word bad。 And because we've got
    the letter B。 what we want to do is we've got nine characters in our corpus。 So
    we have other words that introduce these other characters。
  prefs: []
  type: TYPE_NORMAL
- en: What we want to do is basically be able to understand， and predict the likelihood
    for each corpus。 for each character in our corpus， to actually say what's the
    likelihood。 that this character will appear。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_52.png)'
  prefs: []
  type: TYPE_IMG
- en: So as we generate this hot character encoding， we're going to use that as input
    to our neural network。 and we're then going to pass it through our RNN， and basically
    say， hey， start learning the weights。 and start coming up with the optimal weight，
    to represent the likelihood of what。 character you should be generating based
    on these--， again， trying to approximate that relationship。
  prefs: []
  type: TYPE_NORMAL
- en: in the underlying text， and let's see what we get on the other side。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_54.png)'
  prefs: []
  type: TYPE_IMG
- en: And to train this， we're going to run it through some number， of epochs。 So
    with Keras。 what we can notice here， for those of you， who may have used Scikit-Learn，
    we've got a really。 really nice--， we've got a really nice high-level API we can
    use。 Notice how we said sequential processing is a text--， generation is a sequential
    processing problem？
  prefs: []
  type: TYPE_NORMAL
- en: Surprise， we're going to use this in Quenchle Model。 So LSTM， long short-term
    memory。 is a type of RNN， again， propagating that data back and forth。 This is
    pretty straightforward。 because it allows us， to pull in this in Quenchle Model。
    We specifically say we want to use an RNN of this type。 We then basically add
    in our data。
  prefs: []
  type: TYPE_NORMAL
- en: and then we say， OK， let's go ahead and compile that model。 And notice this
    fit。 We're going to have 20 epochs that we're going to train over。 And what we
    want to do is we want to find that optimal weight， that we can generate。 So Keras
    has a very nice and user-friendly interface， that we can start using。
  prefs: []
  type: TYPE_NORMAL
- en: And if you were looking at what it may look like for that process， of running
    through epochs， well。 you can just basically think of a for loop。 It's very iterative。
    If we have 20 loops or we have 1。000， we can start doing things like that。 And
    then when we start wanting to actually use it。 we've got that model。predict functionality。
    So Keras is pretty cool。 Now let's look at TensorFlow。
  prefs: []
  type: TYPE_NORMAL
- en: Mind you， I did some lifting of this data， so there's some logic that's kind
    of not captured。 but it is actually in my GitHub repository。 But again， when we're
    using TensorFlow， again。 we import TensorFlow， and we've actually， got an RNN
    that we can pull in。 Unlike in the last case where we've， got this sequential
    model and we've。
  prefs: []
  type: TYPE_NORMAL
- en: got the LSTM that's kind of baked in， we're going to actually have to start
    making and creating。 our own object to represent the RNN。 We're going to be working
    with Tensors， which， is， again。 a representation of the vector data。 And what
    we need to do then is start。 writing a definition of the RNN that we want。 So
    notice that we've got the basic LSTM here that we can pull in。
  prefs: []
  type: TYPE_NORMAL
- en: But essentially， when we're using TensorFlow， we're going to have to have a
    little bit more knowledge。 about the underlying--， we're not given that high-level
    API interface where it just， says， hey。 here's the thing out of the box。 You actually
    have to go and take the components。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_56.png)'
  prefs: []
  type: TYPE_IMG
- en: and actually start building it yourself。 And likewise。 then when you're actually
    optimizing the weights， what you have to do is you actually。 have to run a session，
    a TensorFlow extension。 And notice， again， we have this epoch loop。 We're going
    to go ahead and do n iterations。 And then when we find the optimal weight。
  prefs: []
  type: TYPE_NORMAL
- en: what happens in both cases is you， can export those optimal weights once you've。
    found them after running so many epoch sessions。 Those weights， then。 let's say
    they're in a flat file， you can then import those for later use。 So TensorFlow。
    we don't have that high-level interface。 We've actually got to kind of meld some
    of those components。
  prefs: []
  type: TYPE_NORMAL
- en: together ourselves。 But we understand what we're doing。 We've got to build the
    model。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_58.png)'
  prefs: []
  type: TYPE_IMG
- en: We've got to fit the model。 We've got to train the model。 And with PyTorch，
    PyTorch actually。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_60.png)'
  prefs: []
  type: TYPE_IMG
- en: gets a lot more interesting。 And you have a lot more flexibility。 to go in there
    and build things as you want。 So notice here， as we're building our RNN with PyTorch。
    notice how we're having to actually build the interface， for actually how forward
    propagation works。 So remember how you said data can move forward and backward？
  prefs: []
  type: TYPE_NORMAL
- en: Now you are able to actually go in and write that logic how。 that happens and
    how you're interacting。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_62.png)'
  prefs: []
  type: TYPE_IMG
- en: with these other neurons。 So the interface actually is much more low level。
    And again。 when we're training， we have that great epoch loop， that we've come
    to know and love。 And also。 when we get our output， we can then export that output。
    We can then export that output to then import to our model， for later use as well。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_64.png)'
  prefs: []
  type: TYPE_IMG
- en: So with those three neural networks examples， what actually can we start generating。
    with an RNN using Python？
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_66.png)'
  prefs: []
  type: TYPE_IMG
- en: This is some of the most coherent texts， I actually started developing， which。
    is to say that it is a work in progress。 So one of the things I noticed is， as
    I。 started asking to make longer pieces of text， it just started getting really，
    really wild。 Remember the whale did that。 So some of the more coherent units of
    text。
  prefs: []
  type: TYPE_NORMAL
- en: I found was actually getting character strings of about 200。 So why is that？
  prefs: []
  type: TYPE_NORMAL
- en: This kind of feels like it's in line， that it could be in a telenovela。 Don't
    threaten me。 Don't do you not understand me？ Whoa， whoa， whoa， whoa。 Right。 Maybe
    we're making that famous fight scene all over。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_68.png)'
  prefs: []
  type: TYPE_IMG
- en: But in thinking about the tooling that we need to build， think about those three
    questions。 How much technical expertise is needed to start with a framework？
  prefs: []
  type: TYPE_NORMAL
- en: I've told you that I'm new to deep learning or relatively new。 So I probably
    want something that's a little bit more， beginner-friendly， something that allows。
    me to build a small toy project quickly。 And something that has， for me， this，
    is super important。 a very， very good， robust user group that， gives lots of documentation
    and lots of examples。
  prefs: []
  type: TYPE_NORMAL
- en: of how to use it。 For my second question， what are my requirements？ Well， actually。
    because I focused on just looking， at those three English telenovelas。 I actually
    did not have that much data。 I had less than 100 megabytes。 And it was actually
    just looking at the raw text spoken word。
  prefs: []
  type: TYPE_NORMAL
- en: data itself that wasn't including things like sometimes。 there's cues and scripts
    that say something like， oh。 15-second pause with the dramatic stare to the side。
    So those weren't actually those kind of nitty-gritty pieces。 of information I
    actually didn't have in my text， that I was working with。 So thinking about that。
    I had a small data set， and something that I wanted to have some ability to debug。
    a little bit more friendly， let's continue， onto my third requirement， which is
    basically how easy。 is it to start using a framework。 And essentially， what I
    wanted was。
  prefs: []
  type: TYPE_NORMAL
- en: to get something that allowed me just to be able to bootstrap， and get going，
    because I just wanted。 to know what it means to actually start working， with text，
    to start processing text。 and actually start doing text generation。 And all that
    to say that the one that won for me--。 notice my priorities？ Caris， Caris， Caris？
    Yes， I opted to work with Caris。
  prefs: []
  type: TYPE_NORMAL
- en: So what's really cool about TensorFlow， is you can actually--， Caris， you can
    plug in。 and you can use with TensorFlow。 And you can use TensorFlow and Caris
    quite nicely。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_70.png)'
  prefs: []
  type: TYPE_IMG
- en: So you can see it's really， really cool。 And you can see it's really cool。 And
    you can see it's really cool。 And you can see it's really cool。 And you can see
    it's really cool。 And you can see it's really cool。 And you can see it's really
    cool。 And you can see it's really cool。
  prefs: []
  type: TYPE_NORMAL
- en: And you can see it's really cool。 And you can see it's really cool。 And you
    can see it's really cool。 And you can see it's really cool。 And you can see it's
    really cool。 And you can see it's really cool。 And you can see it's really cool。
    And you can see it's really cool。
  prefs: []
  type: TYPE_NORMAL
- en: And you can see it's really cool。 And you can see it's really cool。 And you
    can see it's really cool。 And you can see it's really cool。 And you can see it's
    really cool。 And you can see it's really cool。 And you can see it's really cool。
    And you can see it's really cool。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_72.png)'
  prefs: []
  type: TYPE_IMG
- en: And you can see it's really cool。 And you can see it's really cool。 And you
    can see it's really cool。 And you can see it's really cool。 And you can see it's
    really cool。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_74.png)'
  prefs: []
  type: TYPE_IMG
- en: And you can see it's really cool。 And you can see it's really cool。 And you
    can see it's really cool。 And you can see it's really cool。 And you can see it's
    really cool。 And you can see it's really cool。 And you can see it's really cool。
    And you can see it's really cool。
  prefs: []
  type: TYPE_NORMAL
- en: And you can see it's really cool。 And you can see it's really cool。 And you
    can see it's really cool。 And you can see it's really cool。 And you can see it's
    really cool。 And you can see it's really cool。 And you can see it's really cool。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_76.png)'
  prefs: []
  type: TYPE_IMG
- en: And you can see it's really cool。 And you can see it's really cool。 And you
    can see it's really cool。 And you can see it's really cool。 And you can see it's
    really cool。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_78.png)'
  prefs: []
  type: TYPE_IMG
- en: And you can see it's really cool。 And you can see it's really cool。 And you
    can see it's really cool。 And you can see it's really cool。 And you can see it's
    really cool。 And you can see it's really cool。 And you can see it's really cool。
    And you can see it's really cool。
  prefs: []
  type: TYPE_NORMAL
- en: And you can see it's really cool。 And you can see it's really cool。 And you
    can see it's really cool。 And you can see it's really cool。 And you can see it's
    really cool。 And you can see it's really cool。 And you can see it's really cool。
    And you can see it's really cool。
  prefs: []
  type: TYPE_NORMAL
- en: And you can see it's really cool。 And you can see it's really cool。 And you
    can see it's really cool。 And you can see it's really cool。 And you can see it's
    really cool。 And you can see it's really cool。 And you can see it's really cool。
    And you can see it's really cool。
  prefs: []
  type: TYPE_NORMAL
- en: And you can see it's really cool。 And you can see it's really cool。 And you
    can see it's really cool。 And you can see it's really cool。 And you can see it's
    really cool。 And you can see it's really cool。 And you can see it's really cool。
    And you can see it's really cool。
  prefs: []
  type: TYPE_NORMAL
- en: And you can see it's really cool。 And you can see it's really cool。 And you
    can see it's really cool。 And you can see it's really cool。 And you can see it's
    really cool。 And you can see it's really cool。 And you can see it's really cool。
    And you can see it's really cool。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_80.png)'
  prefs: []
  type: TYPE_IMG
- en: And you can see it's really cool。 And you can see it's really cool。 And you
    can see it's really cool。 And you can see it's really cool。 And you can see it's
    really cool。 And you can see it's really cool。 And you can see it's really cool。
    And you can see it's really cool。
  prefs: []
  type: TYPE_NORMAL
- en: And you can see it's really cool。 And you can see it's really cool。 And you
    can see it's really cool。 And you can see it's really cool。 And you can see it's
    really cool。 And you can see it's really cool。 And you can see it's really cool。
    And you can see it's really cool。
  prefs: []
  type: TYPE_NORMAL
- en: And you can see it's really cool。 And you can see it's really cool。 And you
    can see it's really cool。 And you can see it's really cool。 And you can see it's
    really cool。 And you can see it's really cool。 And you can see it's really cool。
    And you can see it's really cool。
  prefs: []
  type: TYPE_NORMAL
- en: And you can see it's really cool。 And you can see it's really cool。 And you
    can see it's really cool。 And you can see it's really cool。 And you can see it's
    really cool。 And you can see it's really cool。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_82.png)'
  prefs: []
  type: TYPE_IMG
- en: And you can see it's really cool。 And you can see it's really cool。 And you
    can see it's really cool。 And you can see it's really cool。 And you can see it's
    really cool。 And you can see it's really cool。 And you can see it's really cool。
    And you can see it's really cool。
  prefs: []
  type: TYPE_NORMAL
- en: And you can see it's really cool。 And you can see it's really cool。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_84.png)'
  prefs: []
  type: TYPE_IMG
- en: And you can see it's really cool。 And you can see it's really cool。 And you
    can see it's really cool。 And you can see it's really cool。 And you can see it's
    really cool。 And you can see it's really cool。 And you can see it's really cool。
    And you can see it's really cool。
  prefs: []
  type: TYPE_NORMAL
- en: And you can see it's really cool。 And you can see it's really cool。 And you
    can see it's really cool。 And you can see it's really cool。 And you can see it's
    really cool。 And you can see it's really cool。 And you can see it's really cool。
    And you can see it's really cool。
  prefs: []
  type: TYPE_NORMAL
- en: And you can see it's really cool。 And you can see it's really cool。 And you
    can see it's really cool。 And you can see it's really cool。 And you can see it's
    really cool。 And you can see it's really cool。 And you can see it's really cool。
    And you can see it's really cool。
  prefs: []
  type: TYPE_NORMAL
- en: And you can see it's really cool。 And you can see it's really cool。 And you
    can see it's really cool。 And you can see it's really cool。 And you can see it's
    really cool。 And you can see it's really cool。 And you can see it's really cool。
    And you can see it's really cool。
  prefs: []
  type: TYPE_NORMAL
- en: And you can see it's really cool。 And you can see it's really cool。 And you
    can see it's really cool。 And you can see it's really cool。 And you can see it's
    really cool。 And you can see it's really cool。 And you can see it's really cool。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86caa82786cf9dc042e1ddb9efafe87d_86.png)'
  prefs: []
  type: TYPE_IMG
- en: And you can see it's really cool。 And you can see it's really cool。 And you
    can see it's really cool。
  prefs: []
  type: TYPE_NORMAL
