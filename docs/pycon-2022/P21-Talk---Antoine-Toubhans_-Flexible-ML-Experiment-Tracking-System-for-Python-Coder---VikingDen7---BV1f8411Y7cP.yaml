- en: P21：Talk - Antoine Toubhans_ Flexible ML Experiment Tracking System for Python
    Coder - VikingDen7 - BV1f8411Y7cP
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: P21：演讲 - Antoine Toubhans_ 灵活的ML实验跟踪系统，适用于Python程序员 - VikingDen7 - BV1f8411Y7cP
- en: Hello and welcome。 So our next presentation and the last one before lunch is
    we have Antoine。
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 你好，欢迎大家。那么我们下一个演讲也是午餐前的最后一个，我们有Antoine。
- en: '![](img/5650230baed0245b16b87a96032fe4fe_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5650230baed0245b16b87a96032fe4fe_1.png)'
- en: '![](img/5650230baed0245b16b87a96032fe4fe_2.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5650230baed0245b16b87a96032fe4fe_2.png)'
- en: Tupong， who is going to be talking about flexible， machine learning experiment
    tracking system。 for Python coders with the VCM Streamlet。 Let's work on Antoine
    with a round of applause。 Hi everybody。 Thank you for being here。 Today I'm going
    to talk about ML experiment tracking。 system。 A few words about me。 My name is
    Antoine Tupong。 I'm French。 I live and work， in Paris。
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Tupong将讨论灵活的机器学习实验跟踪系统，适用于使用VCM Streamlet的Python程序员。让我们用热烈的掌声欢迎Antoine。大家好。感谢你们的到来。今天我将谈论ML实验跟踪系统。关于我几句话。我的名字是Antoine
    Tupong。我是法国人。我在巴黎生活和工作。
- en: I work in a consulting firm called Cicara。 What we do is that we build a telemed。
    solution for our clients， AI solutions mostly。 I am a data scientist for five
    years now and。 I mostly work on computer vision problems。 Today I'm going to talk
    about machine learning。 engineering。 At Cicara the official job title is data
    scientist but actually what we do is。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我在一家叫Cicara的咨询公司工作。我们所做的是为客户构建远程医疗解决方案，主要是AI解决方案。我已经是数据科学家五年了，主要工作于计算机视觉问题。今天我要谈论的是机器学习工程。在Cicara，官方职位是数据科学家，但实际上我们所做的就是。
- en: more machine learning engineer because we do data science。 We read research
    paper。 We。 implement models。 We run experiments but we also build what is around。
    We build APIs。 We integrate models in mobile app or stuff like that。 So it's in
    between data science。 and software engineering。 In software engineering we have
    a lot of tools。 I mean the software。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 更多的机器学习工程师因为我们做数据科学。我们阅读研究论文。我们实现模型。我们进行实验，但我们也构建周围的环境。我们构建API。我们将模型集成到移动应用或类似的东西中。所以它介于数据科学和软件工程之间。在软件工程中，我们有很多工具。我是说软件。
- en: engineering is very mature and you can leverage on existing best tools and best
    practices。 So on the other hand machine learning engineering is more than just
    software engineering。 There。 is a lot of things that you need to do。 You need
    to track the data alongside the code。 It's more an exploratory work。 You have
    to try and test things。 And as you train models。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 工程非常成熟，你可以利用现有的最佳工具和最佳实践。因此，另一方面，机器学习工程不仅仅是软件工程。你需要做很多事情。你需要跟踪数据与代码。更像是一项探索性的工作。你必须尝试和测试东西。当你训练模型时。
- en: you need tools to investigate them， to touch them to see how it works。 So today
    I'm going。 to talk about ML experiment tracking system。 In most machine learning
    projects you have， this loop。 When somehow you have some data and you want to
    try some models， you train， your model。 then you evaluate it and it provides you
    with feedbacks。 So either you modify the。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要工具来调查它们，触摸它们以了解它们的工作原理。所以今天我将谈论ML实验跟踪系统。在大多数机器学习项目中，你会有这个循环。当你有一些数据并想尝试一些模型时，你训练模型。然后你评估它，它会给你反馈。因此，要么你修改。
- en: data or the model you change the power parameters or things like that and you
    do it again。 And。 for these reasons you need an experiment tracking system that
    allows you to track your experiments。 So you want to have a record of which data
    did you use， which code， which parameters。 You want to be able to compare experiments。
    And as the project is going on you are going。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 数据或模型你更改参数或类似的东西，然后再进行。出于这些原因，你需要一个实验跟踪系统，能够让你跟踪实验。因此，你希望有一个记录，显示你使用了哪些数据、哪些代码和哪些参数。你希望能够比较实验。随着项目的进行，你将。
- en: to have more and more experiments。 So you need to organize them so that it's
    easy to search。 And reproducibility is very important because when you have a
    model who proves to be good。 you want to be able to rebuild it in order to be
    able to iterate over it。 And finally。 it's teamwork so you need tools to share
    the knowledge that you have when you run these。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 要进行越来越多的实验。因此，你需要组织它们，以便于搜索。可重复性非常重要，因为当你有一个证明是好的模型时，你希望能够重建它以便能够迭代。最后，这是团队合作，因此你需要工具来分享你在运行这些时所拥有的知识。
- en: experiments。 So today I'm not going to talk about all these solutions which
    are great but。 I call them monolithic because they provide you with all you need
    to do a ML project but。 it's not very easy to customize them。 Instead， I think
    we are a good Python developer so instead。 I propose to build an ML experiment
    tracking system with smaller bricks which are divisients。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 所以今天我不会讨论所有这些很棒的解决方案，但我称它们为单体，因为它们提供了进行ML项目所需的一切，但不容易自定义。相反，我认为我们是优秀的Python开发者，因此我提议用较小的模块构建一个ML实验跟踪系统。
- en: and it will allow you to build a system that is fully customizable。 So let's
    do machine learning。 for the purpose of this talk。 I will use these cats and dogs
    image classification program。 It's adapted from TensorFlow tutorial and basically
    the goal is to build a model that。 given an input image says whether it's a cat
    or a dog。 A few words about the data set。 It's。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这将允许你构建一个完全可自定义的系统。那么让我们进行机器学习。为了这次演讲，我将使用这些猫和狗的图像分类程序。它是根据TensorFlow教程改编的，基本目标是构建一个模型，给定输入图像来判断它是猫还是狗。关于数据集的一些话。
- en: available in TensorFlow data set。 It's 3，000 images and here you can see some
    examples of。 cats and dogs。 So how do we do this？ We are going to build training
    pipelines which are。 the first steps。 The first step is to download the data set。
    Then we have to prepare the data， set。 We need to split the data set in three
    parts。 The train validation and test set。 And。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在TensorFlow数据集中可用。这里有3,000张图像，你可以看到一些猫和狗的示例。那么我们该如何进行呢？我们将构建训练管道，这是第一步。第一步是下载数据集。然后我们需要准备数据集。我们需要将数据集分为三部分：训练集、验证集和测试集。
- en: then I need to train a model over the train and the sets。 And finally I need
    to evaluate。 this model so that I get a metric to know if it's working good。 I'm
    going quickly over， the script。 Basically it's adapted from the TensorFlow tutorial
    you can find online。 So。 the train trick basically what it does is it's in port
    parameters。 It loads the data。 It。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我需要在训练集上训练一个模型。最后，我需要评估这个模型，以便获得一个指标，了解它是否有效。我很快浏览一下脚本。基本上这是根据你可以在线找到的TensorFlow教程改编的。因此，训练的诀窍基本上是它导入参数。它加载数据。
- en: defines a model here。 And then it's trained here。 The training， there is two
    steps during。 the training。 First the backbone is frozen and then it's unfrozen。
    So let's say we want。 to run an experiment。 So what do we need to do？ First we
    need to set up the experiment。 So we need to define which model we want to use
    on which data defines the parameters， and so on。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里定义一个模型。然后在这里进行训练。训练有两个步骤。首先，主干被冻结，然后解冻。那么假设我们想进行一次实验。我们需要做什么？首先，我们需要设置实验。因此我们需要定义我们想要使用哪个模型，在哪些数据上定义参数等等。
- en: And to do that I can track whatever I do with using GitHub because it's code。
    Basically。 it's code or it's configuration files that I can track with so I'm
    happy with this step。 Then I need to run the pipeline。 To do that I need to run
    the script in the right order。 which is I'm not super happy with that because
    it's easy to mix steps。 And then I need to save。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我可以使用GitHub跟踪我所做的任何事情，因为这是代码。基本上，这是我可以跟踪的代码或配置文件，所以我对这一步很满意。然后我需要运行管道。为此，我需要按正确的顺序运行脚本。我对此并不太满意，因为容易混淆步骤。然后我需要保存实验。
- en: the results because when I execute the training pipeline it will produce files。
    For instance。 the model weights， the matrix files and so on。 So I need to put
    it somewhere。 And finally。 I need to keep track of the experiment itself which
    model they use， which parameters， which。 data and so on。 I need tools to do this
    properly。 So it's time to introduce DVC。 DVC stands for。
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是，当我执行训练管道时，它会生成文件。例如，模型权重、矩阵文件等等。所以我需要把这些放在某个地方。最后，我需要跟踪实验本身使用了哪个模型、哪些参数、哪些数据等等。我需要工具来正确完成这件事。因此，是时候介绍DVC了。DVC代表。
- en: Data Version Control。 It's a Python library so you can just pip install it。
    And what it。 does is that it allows you to track huge files that you don't want
    to version with Git because。 it's too heavy。 And it will replace this huge file
    by small metadata files that you can。 track with Git。 So it's very similar to
    Git LFS for instance。 The API is very similar to。
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 数据版本控制。它是一个Python库，所以你可以直接使用pip安装。它的作用是让你跟踪那些你不想用Git版本控制的大文件，因为这些文件太大了。它会用小的元数据文件替代这个大文件，而这些文件可以用Git跟踪。所以它和Git
    LFS非常相似。
- en: Git so if you know how to use Git it's pretty much the same with DVC。 Instead
    of Git add。 your file you just DVC add your file。 And there is also a remote data
    storage mechanism。 so you can DVC push pull to save your results。 What is really
    good with DVC is this reproducible。 pipeline feature。 So in DVC you can track
    the data but you can also track the way you produce， data。
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Git 的使用与 DVC 非常相似。如果你知道如何使用 Git，那么在 DVC 中，你只需使用 DVC add 来添加文件，而不是 Git add。此外，还有远程数据存储机制，因此你可以使用
    DVC push 和 pull 来保存结果。DVC 的一个优点是其可重复的管道功能。因此，在 DVC 中，你不仅可以跟踪数据，还可以跟踪生产数据的方式。
- en: Say for instance here I have a two-stage pipeline that will consume file A，
    B， C and。 in the end will compute a file E。 So all I need to do is to define the
    pipeline in a， YML file。 I just define the two stages to do that。 I give the command
    and I declare the。 dependencies and the output。 And whenever I want to execute
    the pipeline I just want DVC， repro。
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 比如说，这里我有一个两阶段的管道，将消耗文件 A、B、C，最终计算出文件 E。因此，我所需要做的就是在 YML 文件中定义管道。我只需定义两个阶段，给出命令并声明依赖项和输出。每当我想执行管道时，我只需运行
    DVC repro。
- en: And this will resolve the data so that in which order to execute the stage。
    It will。 execute the stages and it will track the input on a put data with DVC。
    There is also a cache。 in mechanism so that whenever a stage the dependencies
    of a stage didn't change it will restore automatically。 the output so that it
    speed up a little bit the pipeline execution。 So let's go back to。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这将解决数据处理的顺序以执行阶段。它将执行阶段，并使用 DVC 跟踪输入数据。此外，还有缓存机制，以便每当某个阶段的依赖项没有变化时，它会自动恢复输出，从而稍微加快管道执行速度。现在，让我们回到。
- en: our training pipeline。 Just as before we have two more files。 No I have a DVC。TML
    file。 that in which I define the fourth stage of my pipelines。 And I have a parameter
    file where。 I define all the parameter from my training pipeline and this parameter
    I directly injected。 in the pipeline definition for instance here。 So let's say
    I want to give a second try to。
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的训练管道。与之前一样，我们还有两个文件。现在我有一个 DVC.TML 文件，在其中定义我的管道的第四个阶段。我还有一个参数文件，在其中定义训练管道的所有参数，并且这些参数我直接注入到管道定义中，比如在这里。因此，假设我想再试一次。
- en: run my experiment。 So the first step is pretty much the same but to modify the
    pipeline of。 parameters I directly modify the DVC。TML and parameters。TML files。
    To run the pipeline。 it's much more easy now。 I just run DVC repro and that's
    it。 And to save the results I have。 nothing to do because DVC will automatically
    track the output data。 Now regarding the experiment。
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 运行我的实验。第一步与之前非常相似，但要修改参数的管道，我直接修改 DVC.TML 和参数.TML 文件。运行管道现在更简单了。我只需运行 DVC repro，就完成了。为了保存结果，我无需做任何事情，因为
    DVC 会自动跟踪输出数据。现在关于实验。
- en: tracking it's not very， I'm still not happy with that because whenever you execute
    a pipeline。 it will create a metadata file that you can track with Git。 So the
    experiment it's track。 you can access it with Git log but what you will get it's
    only the commit names and you。 see all commits in your project you see experiment
    commits together with code commits so it's。
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 跟踪的部分，我对此并不满意，因为每当你执行管道时，它将创建一个可以用 Git 跟踪的元数据文件。因此，实验被跟踪。你可以通过 Git log 访问，但你得到的只是提交名称，你会看到项目中的所有提交，包括实验提交和代码提交。
- en: not very convenient。 The data is tracked but it's not very easy to access。 And
    another。 difference between classical software engineering is that when you do
    machine learning it's not。 a linear work。 When you do classical software engineering
    it's mostly linear。 You have branches。 but when you code in your branch you do
    one commit after the user and it's linear。 In。
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不是很方便。数据被跟踪，但访问起来并不容易。与传统软件工程的另一个区别是，当你进行机器学习时，这并不是一个线性工作。在传统软件工程中，大多数是线性的。你有分支，但在你的分支中编码时，你在用户后进行一次提交，这是一种线性的过程。
- en: data science whenever you train a model usually you train it with a lot of different
    e-par parameters。 So it's not linear。 In DVC there is another feature which is
    called experiment that allows。 you to track experiment in a non-linear way。 I
    will not enter into details but what you。 need to see here is that it will create
    commits whenever you execute a pipeline and it will。
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学中，每当你训练模型时，通常会使用许多不同的超参数。因此，这并不是线性的。在 DVC 中还有一个称为实验的功能，允许你以非线性的方式跟踪实验。我不会详细讲解，但你需要知道的是，每当你执行管道时，它将创建提交。
- en: track them these commits with custom Git references。 And it's not linear。 And
    since you have。 references for your experiment commits you also have commands
    to access them。 So let's。 say I want to see all the experiments from my repository。
    I can run this command， DVC。 Xplist and it will give me something like that。 So
    here you see the parent commits and here。
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 使用自定义 Git 引用跟踪这些提交。并且这不是线性的。由于你有实验提交的引用，你还可以使用命令访问它们。假设我想查看我的仓库中的所有实验。我可以运行这个命令，DVC
    Xplist，它会给我类似这样的结果。在这里你可以看到父提交，这里。
- en: you have all the experiments that arise from it。 So now if I want to access
    the details of。 these experiments I just run DVC Xshow and I can provide the commit
    hash。 Sorry。 So I。 need to compile first。 Here it goes。 And now I have the details
    of all the experiments。 that derive from this Git commit。 So I have the metrics，
    accuracy， I have all the parameters。
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 你有所有从中衍生出的实验。所以现在如果我想访问这些实验的详细信息，我只需运行 DVC Xshow，并提供提交哈希。抱歉，所以我。需要先编译。好了。现在我有所有衍生于这个
    Git 提交的实验的详细信息。所以我有指标、准确度，还有所有参数。
- en: and so on。 So let's get back to running an experiment。 And whenever I want to
    set up an。 experiment I just create a new run of the pipeline by overriding some
    parameters。 So。 instead of running DVC repo I run DVC XPRUN and I use this set
    params option to override。 whatever params parameter I want to override。 And there
    is a queue mechanism so I can flash。
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 等等。所以让我们回到运行实验。当我想设置实验时，我只需通过覆盖一些参数来创建管道的新运行。因此，我不再运行 DVC repo，而是运行 DVC XPRUN，并使用此设置参数选项来覆盖我想要覆盖的任何参数。而且有一个队列机制，所以我可以闪现。
- en: the queue and execute all the experiments in it by running DVC XPRUN RONOL。
    And in the。 end the output data will be automatically tracked by DVC。 And regarding
    the experiment tracking。 I can access all the experiment details by running DVC
    XPRUN。 So it's much better not。 Let's take a step back and let's have a look at
    the main experiment tracking system features。
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 队列中执行所有实验的方法是通过运行 DVC XPRUN RONOL。最后，输出数据将由 DVC 自动跟踪。关于实验跟踪，我可以通过运行 DVC XPRUN
    访问所有实验的详细信息。所以这要好得多。让我们退一步，看看主要的实验跟踪系统功能。
- en: So with DVC we are very good at logging experiment data on tracking the produce
    data。 It's also。 very good for reproducibility because whenever I want to rerun
    an experiment I just have to。 check out the commit and run DVC repo and it will
    re-exitute the experiment the same way。 Regarding the other features comparing
    experiments， organizing experiments and collaboration I。
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 DVC，我们非常擅长记录实验数据以及跟踪产生的数据。这也非常有利于可重复性，因为每当我想重新运行实验时，我只需检出提交并运行 DVC repo，它将以相同的方式重新执行实验。关于其他功能，比如比较实验、组织实验和协作，我。
- en: can do it in common line but it's not very convenient。 I could improve it with
    UI。 So it's time to introduce Streamlet。 Streamlet is the same website。 It's a
    faster way to build。 and share data apps。 So it's a Python library。 You can just
    peep and stall it and use it。 And what it does is that it allows you to build
    an app without knowledge of how to build。
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在命令行中完成，但这并不方便。我可以通过 UI 来改进它。所以是时候介绍 Streamlet。Streamlet 是同一个网站。这是构建和共享数据应用程序的更快方法。它是一个
    Python 库。你只需安装并使用它。它的功能是让你无需了解如何构建就可以构建应用程序。
- en: a web application。 It's only Python and it's very simply simple to understand
    how it works。 So as you may have noticed the slides I'm showing you are dynamic。
    It's because I made。 slides with Streamlet。 So let's have a quick demo。 In Streamlet
    you can display whatever。 you want so you can write text like that。 So here you
    see the rendering。 You can have。
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 一个网络应用程序。它仅使用 Python，非常简单易懂。因此，正如你可能注意到的，我展示给你的幻灯片是动态的。这是因为我用 Streamlet 制作了幻灯片。让我们快速演示一下。在
    Streamlet 中，你可以显示任何你想要的内容，所以你可以像这样写文本。在这里你可以看到渲染效果。你可以拥有。
- en: more complex rendering for instance。 You can run the images like that。 And you
    can run。 the more complex data。 For instance， let's say I have a data frame here。
    You just run。 ST the data frame and it will show you this nice table。 So it's
    very easy to show whatever。 data you want to show in your web app。 And it's also
    easy to make interaction。 For instance。
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 比如说更复杂的渲染。你可以像这样运行图像。你可以运行更复杂的数据。例如，假设我有一个数据框。你只需运行数据框，它会给你展示一个漂亮的表格。所以在你的 web
    应用中显示任何你想要的数据都非常简单。同时也很容易进行交互。例如。
- en: let's say I want a slider。 So here I define a slider between 0 and 100。 And
    whenever I。 change the slider you see here the chosen value gets updated to 35
    and I write the result here。 which is here。 So whenever I change it it gets updated
    here。 So it's very easy to build。 interaction。 And it allows you to build things
    like that。 Let's say I want to investigate。
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我想要一个滑块。我在这里定义一个介于0和100之间的滑块。每当我改变滑块时，你会看到这里选择的值更新为35，我在这里写下结果。每当我更改时，它会在这里更新。所以构建交互非常简单。它允许你创建这样的东西。假设我想进行调查。
- en: my model and I want to see on which images the model is not sure。 So the model
    it puts。 a probability between 0 and 1 of being a cat or a dog。 0 being a cat
    and 1 is a dog。 So。 let's say I want to see images where the model is pretty sure
    it's a cat。 So here I have such。 images and let's say I want to see images where
    the model is not sure。 So close to 50%。
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我想查看我的模型在哪些图像上不确定。所以模型给出了一个介于0和1之间的概率，表示是猫还是狗。0表示猫，1表示狗。所以，假设我想查看模型很确定是猫的图像。这是这样的图像，假设我想查看模型不确定的图像，接近50%。
- en: And here you can see there are three images that correspond to the slider values
    and this。 one is interesting because there is a cat and a dog on the same image。
    So to build this。 template application in the right part it's only a few line
    of codes that are here。 So。 what I do is that I load the predictions from a CSV
    file。 Then I define a slider with a double。
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里你可以看到有三张图像对应滑块的值，其中这一张很有趣，因为同一张图上有一只猫和一只狗。因此，要构建这个模板应用程序，右侧只需要几行代码。所以我做的是从CSV文件加载预测。然后我定义一个带有双重的滑块。
- en: entry here。 And finally I get the two thresholds and I use them to filter the
    prediction and。 I use ST。image to plot the corresponding images。 So very easy
    to use。 And I can do a lot more。 For instance I can directly test the model on
    whatever image I want。 So for instance here。
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的条目。最后我得到两个阈值，我用它们来过滤预测，并使用ST.image来绘制相应的图像。所以使用起来非常简单。我还可以做更多。例如，我可以直接在我想要的任何图像上测试模型。比如说这里。
- en: '![](img/5650230baed0245b16b87a96032fe4fe_4.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5650230baed0245b16b87a96032fe4fe_4.png)'
- en: I have an upload widget。 So let's say I want to try it on a cat。 And here the
    model says。
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我有一个上传小部件。假设我想在一只猫身上试验它。这里模型说。
- en: '![](img/5650230baed0245b16b87a96032fe4fe_6.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5650230baed0245b16b87a96032fe4fe_6.png)'
- en: it's a cat and it's pretty sure it's a cat。 So it's working well。 So let's say
    I want to。 try my model on edge cases。 Let's take this one for instance。 So obviously
    I don't have。 lion in the New Zealand train or the test sets。 And with ST。image
    it's very easy to build a。 UI to test the model on whatever image you want。 So
    here I get the image and the model。
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这是只猫，模型很确定它是只猫。所以效果很好。假设我想在边缘情况下尝试我的模型。我们以这个为例。所以显然，我在新西兰的训练或测试集中没有狮子。使用ST.image构建一个用户界面来测试模型在任何你想要的图像上是非常简单的。这里我得到了图像和模型。
- en: says surprisingly that it's pretty sure it's a dog。 How do I do that？ The code
    is a bit longer。 but not that long。 I have a function that loads the model with
    tons of flow。 I get the。 upload widget with ST。file uploader。 I get the uploaded
    image in here。 It's a pillow image。 And if I upload it a file then I open the
    file and I pass it to the model on print prediction。
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 出乎意料的是，模型很确定它是一只狗。我该如何做到这一点？代码稍微长一些，但并没有那么长。我有一个加载模型的函数，带有大量的流程。我通过ST.file uploader获得上传小部件。在这里我获取上传的图像，它是一个Pillow图像。如果我上传一个文件，我就打开文件并将其传递给模型进行预测。
- en: And that's it。 So what if now we combine strength of both tools？ On one hand
    the DVC。 is very good at tracking the data but it does not provide any tool to
    build complex visualization。 On the other hand， Sremit is very good at building
    interactive web app on complex data。 visualization。 So let's combine them to build
    something like that。 So here it's a table of。
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样。那么如果我们现在结合这两个工具的优势呢？一方面，DVC非常擅长跟踪数据，但并没有提供构建复杂可视化的工具。另一方面，Sremit在构建复杂数据可视化的交互式网页应用方面非常出色。所以让我们将它们结合起来，构建这样的东西。这是一个表格。
- en: experiments application。 Here you have a table with all experiments。 It's very
    similar to。 what you get when you run DVCX show but it's in Sremit。 So since it's
    in Sremit I can do。 whatever I want with it。 For instance I can sort the experiment
    by accuracy。 And since。 this data is available I can easily plot whatever I want。
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 实验应用。在这里你有一个包含所有实验的表格。这和运行DVCX show时得到的非常相似，但它在Sremit中。所以因为它在Sremit中，我可以对它做任何我想做的事情。例如，我可以按准确性对实验进行排序。由于这些数据是可用的，我可以轻松绘制我想要的任何内容。
- en: So this is the accuracy across experiments， but I can print the number of frozen
    epochs and I can have more complex plots。 So here， for instance I plot the number
    of unfrozen epochs against the accuracy but I can change。 dynamically this。 So
    all this interface， it's the code is here。 So it's a bit longer but。 it's not
    that long。 And the most important part in this code is these three lines because。
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这是跨实验的准确率，但我可以打印出冻结周期的数量，并且可以生成更复杂的图。比如说，我绘制了未冻结周期的数量与准确率的关系，但我可以动态地改变这个。所以所有这个接口，代码在这里。虽然有点长，但其实并不算太长。这个代码中最重要的部分是这三行，因为。
- en: they are the ones where I fetch the experiment information。 So let's see how
    it works。 First。 I create a DVC repo in Python。 It's very similar to the Git Python
    API。 And then I retrieve。 all the experiment commits by running this experiment。ls。
    It's similar to DVCX list command。 but it's in Python。 And what it gets you， it's
    this dictionary where you have the parent。
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 他们是我获取实验信息的地方。让我们看看它是如何工作的。首先，我在Python中创建一个DVC仓库。这与Git的Python API非常相似。然后，我通过运行`experiment.ls`来检索所有实验提交。它类似于DVCX的列表命令，但它是在Python中进行的。它给你的是一个字典，其中包含父级信息。
- en: commit here and the list of experiments that derives from that commit。 Now that
    I have。 this I can run DVCX to show but in Python providing the references here。
    And what I will get is。 anything I need。 Here I have the two parent commits and
    for each of them I have for each。 experiment。 The list of used parameters。 The
    dependencies， the output， the metrics and the。
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里提交以及从该提交派生的实验列表。现在我有了这个，我可以运行DVCX来显示，但在Python中提供这里的引用。我将得到我需要的任何信息。这里我有两个父提交，对于每个提交，我有每个实验的使用参数列表、依赖项、输出、指标和提交信息。
- en: experience name。 So once I get that it's very easy to build the table of experiment
    apps。 because all I need to do is to use streamlits to show the data the way I
    want。 So here I。 retrieve the experiment metadata。 I just flatten the data and
    put it in the data frame。 I use a edgid streamlits library。 It's originally a
    JavaScript library and there is a streamlit。
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 实验名称。所以一旦我得到这个，构建实验应用的表格就非常简单，因为我所需要做的就是使用streamlit按我想要的方式展示数据。所以在这里我检索实验元数据。我只是将数据展平并放入数据框中。我使用了edgid
    streamlit库。它最初是一个JavaScript库，而现在有了streamlit。
- en: component that wraps it。 And I show the table here and after that it is very
    easy to build。 the plots with streamlits。 Something else I could do is a DIFing
    app。 It's similar to， when you cut。 You want to compare branches when you do a
    pre-request for instance to see。 the difference between your cut。 Here it's the
    same you want to compare to model。 So let's。
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 组件将其包装起来。我在这里展示了表格，之后构建图表变得非常简单，使用streamlit。我还可以做的另一件事是DIFing应用。这类似于你切割时，你想比较分支，例如在进行拉取请求时查看你的切割之间的差异。在这里也是一样，你想比较两个模型。所以让我们。
- en: say I want to see the images on which two models disagree。 So here I have two
    selectors。 to select the experiment I want to compare。 So let's say I take this
    one。 Okay， seems the， agree。 Okay。 So this one is very interesting because as
    you can see the accuracy is the。 same but there is two images on which the model
    disagree。 So the two labels are cut and。
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我想查看两个模型不同意的图像。这里我有两个选择器来选择我想比较的实验。假设我选择这个。好吧，似乎它们是一致的。好的。这个实验很有趣，因为正如你所见，准确率是相同的，但有两张图像是模型不同意的。所以这两个标签被切割掉了。
- en: the dogs and the first model is wrong on the first image and the second model
    is wrong on。 the second image。 And here I see the two images。 So this is the code
    to build this DIFing app。 And what is important in here is the way I load the
    data because to build to know on。 which images the model disagree I need to load
    the predictions that are tracked on different。
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 狗和第一个模型在第一张图像上出错，而第二个模型在第二张图像上出错。在这里我看到这两张图像。这是构建DIFing应用的代码。在这里重要的是我加载数据的方式，因为为了知道模型在哪些图像上不同意，我需要加载在不同提交上跟踪的预测。
- en: commits。 So the predictions file it's not on my current raw space it's stored
    in another， commit。 So to do that I use the DVC open function which is very similar
    to the core open Python。 function except that it takes a commit revision as an
    argument and what it will do is that。 it will yield a file descriptor that you
    can use to do whatever you want。 Here I just read。
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 所以预测文件不在我当前的原始空间，而是存储在另一个提交中。为此，我使用DVC的open函数，它与核心的Python open函数非常相似，只是它将提交修订作为参数，并且它将生成一个文件描述符，你可以用它来做任何想做的事情。这里我只是读取。
- en: the CZ file with PONAS。 So once I have this it's very easy to build this because
    all I。 need to do is to retrieve the two commits I selected from the select box
    here。 This is。 the first commit revision and then I load the prediction providing
    the commit。 And once。 I have the data frame I simply can merge them and compute
    which images the most model disagree。
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 包含 PONAS 的 CZ 文件。因此，一旦我拥有这个，就可以很容易地构建这个，因为我需要做的就是从这里的选择框中检索我选择的两个提交。这是第一个提交修订版，然后我加载提供该提交的预测。一旦我有了数据框，我可以简单地合并它们并计算出模型最不一致的图像。
- en: And that it。 So to sum up if we take a step back as I show you Streamit allows
    to build。 a very custom web application that allows you to compare experiment，
    organize your experiments。 and it's also very convenient for collaboration because
    as a Streamit it's just Python script。 you can just version them you can share
    them across the team and you can improve them during。
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样。所以，总结一下，如果我们退一步，我向您展示了 Streamit 允许构建一个非常自定义的 Web 应用程序，让您比较实验，组织实验。这对于协作也非常方便，因为作为一个
    Streamit，它只是一个 Python 脚本，您可以对其进行版本控制，可以在团队间共享，并且可以在此期间改进。
- en: the project lifetime。 So to sum up the main advantages of this approach is that
    you can。 do whatever you want with the UI。 It's very customizable。 You can make
    evolve the UI and。 there is practically no limit to what you can do whenever Streamit
    allows you to do， it。 And it's close to zero set up time because you just pip
    install Devs in Streamit and you。
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，这种方法的主要优势在于您可以随心所欲地使用用户界面。它非常可定制。您可以不断发展用户界面，实际上几乎没有限制，只要 Streamit 允许您做的事情。设置时间几乎为零，因为您只需在
    Streamit 中运行 pip install Devs。
- en: can go there is no infrastructure behind it you don't need Kubernetes or whatever。
    On the。 other hand it requires that you have some software engineering skills
    because if in your team。 you have data scientists that are not comfortable with
    software engineering it might not be a。 good idea probably a better idea to go
    with MLflow or framework like that。 And since it's。
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 可以去那里，没有后端基础设施，您不需要 Kubernetes 或其他任何东西。另一方面，它要求您具备一定的软件工程技能，因为如果您的团队中有不熟悉软件工程的数据科学家，这可能不是个好主意，可能更好的选择是使用
    MLflow 或类似框架。由于这是项目的生命周期。
- en: code you have to maintain that code and to deal with technical depth。 And the
    next step。 here I just show you a few examples of Streamit apps but it's local
    you have to start it locally。 and the next step is to deploy them in remote servers
    so that anyone can access them including。 non-technical team members。 And there
    are many other tools that are provided with Streamit。
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 代码，您必须维护这段代码并处理技术债务。接下来的步骤，我只是给您展示一些 Streamit 应用程序的示例，但它是本地的，您必须在本地启动它。下一步是在远程服务器上部署它们，以便任何人都可以访问，包括非技术团队成员。Streamit
    还提供许多其他工具。
- en: and Devs for instance with Devs you have a CML that stands for continuous machine
    learning。 it allows you to branch your pipeline execution with your CI/CD so whenever
    you push on some。 branches it will automatically trigger training or something
    like that。 So that's it for me。
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，Devs 有一个 CML，代表连续机器学习。它允许您与 CI/CD 分支管道执行，因此每当您在某些分支上推送时，它会自动触发训练或类似的操作。这就是我的全部内容。
- en: '![](img/5650230baed0245b16b87a96032fe4fe_8.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5650230baed0245b16b87a96032fe4fe_8.png)'
- en: thank you for your attention and you can find the code for the pipelines and
    the slides on。 this repo and you can find me on Twitter or on GitHub。 Thank you
    very much。 And for the questions if you have any Antoine will be on the corridor
    to see what your questions。 and thank you all to everyone。 Thank you。
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢您的关注，您可以在这个仓库找到管道的代码和幻灯片，您也可以在 Twitter 或 GitHub 上找到我。非常感谢。如果您有任何问题，Antoine
    会在走廊里查看您的问题。谢谢大家。谢谢。
