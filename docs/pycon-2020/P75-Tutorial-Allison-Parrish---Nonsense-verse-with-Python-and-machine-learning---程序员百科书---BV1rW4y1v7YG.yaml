- en: P75：Tutorial Allison Parrish - Nonsense verse with Python and machine learning
    - 程序员百科书 - BV1rW4y1v7YG
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: P75：教程阿莉森·帕里什 - 使用Python和机器学习的无意义诗 - 程序员百科书 - BV1rW4y1v7YG
- en: Oh， oh my God。
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 哦，我的天啊。
- en: '![](img/8b020ff93a34aaaec015555fe5d65b80_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8b020ff93a34aaaec015555fe5d65b80_1.png)'
- en: So hi there。 This is the recording for the PyCon 2020 workshop on sound poetry
    and machine learning。 models。 My name is Alison Parrish。 I'm a poet and computer
    programmer and an assistant arts professor at New York University。 Just a sort
    of an introduction to the code material that we're going to go over later。 I have
    a slide deck prepared that has some of the underlying artistic and aesthetic issues。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 嗨，大家好。这是关于声音诗歌和机器学习模型的PyCon 2020研讨会的录音。我叫阿莉森·帕里什。我是一名诗人和计算机程序员，也是纽约大学的助理艺术教授。这是对我们稍后将要讨论的代码材料的介绍。我准备了一份幻灯片，包含一些基本的艺术和美学问题。
- en: that are at play in these models。 And it also has a little bit about the technical
    details of the implementation of the models。 just as some background knowledge
    as we move ahead with the material。 So this is a machine learning model that I
    made called Pinsulate that knows how to spell。 and sound out words。 So I'm going
    to talk a bit about that。
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型中存在的作用。它还包含了一些关于模型实施的技术细节，作为我们前进时的背景知识。这是我制作的机器学习模型Pinsulate，它知道如何拼写和发音。我将对此稍作讨论。
- en: show some of the mischief that I've gotten up， to with the model。 Mischief that
    you two can get up to。 But the first half of this is going to be about why I as
    a poet would need such a thing。 such a thing as a machine learning model of spelling
    and how to sound words out。 The second half gets a bit more into the technical
    and the gritty of how the model works。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 展示我与模型一起捣鼓出的恶作剧。你们也可以参与其中。但这部分的前半部分将讨论作为一名诗人，我为什么需要这样的东西。像拼写和发音的机器学习模型。后半部分将更深入探讨模型的工作原理的技术细节。
- en: So starting off with phonesthetics， sound symbolism and sound poetry。 So first
    off we should talk about the genre of nonsense first of which the best known。
    examples in English。 One of the best known examples is Lewis Carroll's Java Walkie
    and I have the first stand set。 of that poem here。 Toes Brilig and the Slivy Tove's
    to Guyer and Gimbal in the Wave。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 所以从音韵美学、声音象征和声音诗歌开始。首先，我们应该谈谈无意义的类型，其中最著名的例子是路易斯·卡罗尔的Java Walkie，我这里有那首诗的第一节。Brilig的脚趾和Slivy
    Tove的Guyer和Gimbal在波浪中。
- en: all Mimsie where the， Boro goes and the Moam Raff's out grave。 What's interesting
    to me about this poem is that the words like Brilig and Gimbal and。 out grave
    was well invented for this poem。 But even though they're made up words and they're
    not in the dictionary。 they still seem to， just meaning by virtue not just of
    the context they occur in。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 所有Mimsie，Boro和Moam Raff的坟墓。对我来说，这首诗有趣之处在于像Brilig和Gimbal这样的词，以及out grave为这首诗所创造。尽管它们是虚构的词汇，不在字典中，但凭借它们所处的上下文，它们似乎仍然具有某种意义。
- en: like this syntactic context， that they occur in in this poem， but also in the
    way that they sound。 In other words， Alice says this in Through the Looking Glass
    about Java Walkie。 Even though it doesn't make sense， it quote somehow seems to
    fill my head with ideas。 This concept of sounds， the sound of words filling our
    heads with ideas shows up in a。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 像这种语法上下文，不仅出现在这首诗中，还体现在它们的声音上。换句话说，爱丽丝在《镜中奇遇记》中提到过Java Walkie。尽管这没有意义，但这个引述似乎以某种方式填满了我的脑海。这种声音的概念，单词的声音充满我们脑海的想法在一个地方出现。
- en: bunch of interesting places， especially in psychology and anthropology。 Studies
    in synesthesia have shown that people from all around the world that are native
    languages。 of many different languages or native speakers of many different languages
    across different。 age groups， across cutting across all kinds of demographics。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 一些有趣的地方，尤其是在心理学和人类学方面。对联觉的研究表明，来自世界各地的多种语言的母语者，跨越不同年龄组，各种人口统计学背景。
- en: They all have something in common which is that if you point them to these two
    shapes。 and you ask them to label which one they think is kiki and which one they
    think is booba。 they almost always point to the sharp pointy shape as being kiki
    and the round bulbous。 shape as being booba。 This is what's called phonesthetics。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 它们都有一个共同点，即如果你指向这两种形状，并要求它们标记哪个是kiki，哪个是booba，它们几乎总是将尖锐的形状指为kiki，将圆形的形状指为booba。这被称为音韵美学。
- en: phonesthetics meaning the study of what words feel like， the。 emotional response
    that you get from words， the synesthetics sense that you get from words。 A literary
    genre that offers just easy examples of sound symbolism is fantasy and science
    fiction。 An example that I like to bring up with this is Sophia Samatar who's
    one of my favorite。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 音韵美学，即研究词语给人感觉的学科，词语带来的情感反应，以及词语带来的联觉感。一个容易提供声音符号的文学类型是奇幻和科幻小说。我喜欢用的一个例子是索非亚·萨马塔，她是我最喜欢的作家之一。
- en: fantasy authors。 In an interview she describes a process about inventing languages
    for fantasy novels。 Stranger， and Elondria and the Link histories which are my
    two favorite fantasy novels by the way。 She says the creation of the Elondrian
    language was closely tied to the development of names。 to invent the names I choose
    small chunks of sound that seemed pretty to me and played。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 奇幻作家。在一次采访中，她描述了为奇幻小说发明语言的过程。陌生人和埃隆德里亚，以及链接历史，这是我最喜欢的两部奇幻小说。她提到埃隆德语言的创造与名字的发展密切相关。为了发明这些名字，我选择了听起来对我而言美妙的小音节进行组合。
- en: combining them。 It's that seemed pretty to me thing that is interesting to me
    and I imagine the process。 works in similar ways for other fantasy authors。 Here
    again。 structures of language are being composed not for their conventional meaning。
    but for the aesthetics of their acoustic and articulatory material， making up
    words based。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 结合它们。这让我感兴趣的事情似乎是有趣的，我想象这个过程。对于其他奇幻作家来说，工作方式也类似。在这里，语言的结构不是为了它们的传统意义而构成的，而是为了其声学和发音材料的美感，构成了基于词汇的内容。
- en: on whether they sound pretty。 If you take that idea of inventing words for their
    phonetic properties to the logical extreme。 you get a genre of poetry called sound
    poetry and that's a form of poetry that emphasizes。 the sound of speech and dismisses
    the importance of conventional syntax and semantics as principles。 to organize
    text。 As a representative example of Dada era sound poetry。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 无论它们听起来是否美妙。如果你将为其音韵特性发明词汇的想法推至逻辑的极致，你就会得到一种被称为声音诗的诗歌类型，这是一种强调语言音响，并且忽视传统语法和语义作为组织文本原则的诗歌形式。作为达达时代声音诗的一个代表例子。
- en: I offered this excerpt from Duet， I， Gassing， Ryn Jalliment by the artist and
    Dada poet。 Elsevan Frytak， Loringovin。 I learned this poem a lot。 I haven't ever
    rehearsed it so I don't know if I want to read it but you can look at this。 and
    get kind of a sense of it。 Another example of sound poetry。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我提供了来自达达诗人艾尔塞万·弗里塔克的《二重奏，我，气体，林·贾利门特》的摘录。我对这首诗了解颇多。我从未排练过它，所以我不知道是否想要朗读，但你可以看看这首诗，感受到它的意境。另一个声音诗的例子。
- en: digging a bit deeper into the history of this， this， is a poem from Alexei Kruchanik's
    1913 book。 Palmaada。 Kruchanik was a member of the Russian avant-garde， called
    by Wikipedia， quote。 "perhaps the most， radical poet of Russian futurism。"。 He
    was proponent of a form of poetry called Zam， which takes the idea of foregrounding
    the。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 深入挖掘这个历史，这是来自亚历克谢·克鲁恰尼克1913年书籍《帕尔马达》的一首诗。克鲁恰尼克是俄罗斯先锋派的成员，维基百科称他为“或许是俄罗斯未来主义中最激进的诗人”。他是一个名为Zam的诗歌形式的支持者，该形式强调语言的前景。
- en: acoustic and articulatory materiality of language to the extreme。 There's a
    great paper about the work of Kruchanik called "To Destroy Language" by Craig
    Dworkin。 And in that paper he says， "Zam is a writing without vocabulary or grammar
    which include。 complete neologisms and new modes of combining them so that some
    instruction and word formation。
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 将语言的声学和发音材料推至极致。有一篇关于克鲁恰尼克工作的论文，名为《摧毁语言》，作者是克雷格·德沃金。在那篇论文中，他说：“Zam是一种没有词汇或语法的写作，包括完全的新造词和新的组合方式，以便进行一些指导和词汇形成。”
- en: would generate new understandings。 This poetry hints that grammatical syntax
    does not actually exist except through a retrospective。 analysis of utterances
    in which we impose artificial word boundaries that cannot actually。 be heard in
    spoken language。 Zam， to paraphrase Wittgenstein。 is a play of sounds without
    vocabulary or grammar。 And as a poet I find that idea really compelling。
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 将会产生新的理解。这首诗暗示语法句法并不存在，除了通过对话的回顾性分析，我们强加的人工词边界实际上是无法在口语中听到的。Zam，借用维特根斯坦的话，可以理解为没有词汇或语法的声音游戏。作为一名诗人，我发现这个想法非常吸引人。
- en: the idea of words having being the subject， to play outside of vocabulary and
    grammar。 Just while I was researching this material， I sort of took a great interest
    in this process。 that Kruchanik calls "Zam-nification。"， And this is a process
    where via a conventional poem can be dissolved and reconstructed into。 a "Zam"
    poem， and playing "Elegian" and "Anagram-etization" following a sonic rather。
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 词语作为主题的想法，让它们在词汇和语法之外发挥作用。就在我研究这些材料时，我对这个过程产生了浓厚的兴趣，克鲁恰尼克称之为“Zam-nification”。这是一个过程，通过它，一个传统的诗歌可以被溶解并重构为“Zam”诗，并遵循一种声学而非指称逻辑的“优雅”与“变换”。
- en: than referential logic。 What's shown here is the process applied to a poem by
    one of Kruchanik's contemporaries。 Alexander Chachikov， with the original poem
    there on the left and the "Zam-nified" poem。 on the right。 According to Jorkin，
    none of these fragments。 aside from the demonstrative pronouns "to"， and "etote"
    - I don't know actually - "to" and "etote" - I don't know how to pronounce。
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这里展示的是应用于克鲁恰尼克一位当代诗人亚历山大·查奇科夫的一首诗的过程，左边是原始诗，右边是“Zam-nified”诗。根据乔金的说法，这些片段中，除了示范代词“to”和“etote”外，我实际上不知道——“to”和“etote”，我不知道怎么发音。
- en: the Russian。 None of these words are actually recognizable Russian words。 But
    there are what Jorkin calls "provocative echoes" that come through。 Jorkin translates
    the word "chumir" as a potential portmanteau that could roughly。 be translated
    as "tent earth。"， So what I like about this process is that it's - Kruchanik's
    process is almost automatic。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 俄语。这些词实际上都不是可识别的俄语单词。但有一些乔金所称的“挑衅回声”透出其中。乔金将“chumir”翻译为一个潜在的混合词，大致可以翻译为“帐篷地球”。所以我喜欢这个过程的是，克鲁恰尼克的过程几乎是自动的。
- en: It's not a computer program that's doing this， but he still seems to be applying
    this。 sort of computational-ish logic to it， the logic of compression in order
    to bring out。 some aspect of the text that can't be seen if the text actually
    makes sense。 As an aside。 the word "zam" comes from the Russian pre-tech "zam"
    meaning "across"， and "um" which means "mind。"。
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不是一个计算机程序在做这些，但他似乎仍在应用某种计算逻辑，即压缩逻辑，以揭示文本中一些在文本实际有意义时无法看到的方面。顺便说一下，“zam”这个词源于俄语的前科技词“zam”，意为“穿越”，而“um”则意味着“心智”。
- en: A fair translation of this would be "trans-rational。" which I think means we
    could call any conventional， non-zam poetry "sis-rational。"。 So that's just a
    little neologism that you get for free with this workshop。 In any case。 the point
    of phonesthetics， sound symbolism， which is another word for phonesthetics。
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 公正的翻译是“超理性”，我认为这意味着我们可以称任何传统的、非扎姆诗歌为“姐妹理性”。所以这只是你在这个研讨会上免费获得的小词汇新造。
- en: and sound poetry is that they facilitate linguistic phenomena and forms of expression
    that are。 impossible with other forms of writing。 Sound poetry scholar Steve McCaffrey
    states it like this。 The acoustic poem bypasses the cortex and addresses itself
    to the central nervous system。 Energy transmits as fragmented linguistic particles，
    sound vibration， and electrochemical forces。
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 声音诗歌促进了语言现象和表达形式，这在其他书写形式中是不可能的。声音诗歌学者史蒂夫·麦卡弗里这样表述：声学诗歌绕过皮层，直接作用于中枢神经系统。能量以碎片化的语言粒子、声波和电化学力量的形式传递。
- en: to the spinal column。 To sum that "up" sound poetry somehow seems to fill my
    head with ideas。 but not just my， head， my entire body。 Sound is the part of language
    that activates the body both on the part of the speaker and。 on the part of the
    listener。 So I want to write computer programs that make poetry like this。 I love
    these poems， I love these poets， I love this idea of being able to write poetry
    that。
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 到脊柱。总结一下，“声音诗”似乎在我的头脑中充满了想法，但不仅仅是我的头，我的整个身体。声音是激活说话者和听众身体的语言部分。因此，我想编写计算机程序来创作这样的诗歌。我爱这些诗，我爱这些诗人，我喜欢能创作出这样的诗歌的想法。
- en: bypasses parts of the brain to more directly address particular aesthetic emotional
    effects。 So how do you write a computer program to deal with language like this？
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 绕过大脑的部分，更直接地应对特定的美学情感效果。那么，你如何编写一个计算机程序来处理这样的语言？
- en: How do you write a computer program that generates words that elicit specific，
    synesthetic effects？
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 你如何编写一个计算机程序来生成引发特定联觉效果的词汇？
- en: To answer that question， it's worth talking about why should we write a computer
    program。 to do this in the first place？ Also on Frightag， Blurring Urban did find
    without a computer program to write sound poetry。 who try to find without one。
    But for me， making programs that generate poetry is a way of investigating aesthetic。
    ideas。 It's a way of figuring out how a poem or a type of poem works。 As Emily
    Short puts it。
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答这个问题，值得谈谈为什么我们一开始应该编写计算机程序来做这件事？在Frightag上，Blurring Urban确实发现了不使用计算机程序来写声音诗的人。试图在没有程序的情况下进行创作。但对我来说，编写生成诗歌的程序是一种探讨美学理念的方法。这是一种理解一首诗或某种类型的诗是如何运作的方式。正如Emily
    Short所说的。
- en: '"It''s a subjective process of uncovering unarticulated aesthetic， preferences。"，
    And importantly。 this is a process of understanding not of automation。 I''m not
    trying to replicate these sound poems。 I''m trying to write a computer program
    that gives me the tools to write sound poems。 I''m not trying to put poets out
    of a job。 I''m trying to be a poet。'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: “这是一种揭示未表述的美学偏好的主观过程。”而且重要的是，这个过程是理解而不是自动化。我并不是在试图复制这些声音诗。我是在尝试编写一个计算机程序，给我工具来写声音诗。我不是在试图让诗人失业。我是在努力成为一名诗人。
- en: The problem with using conventional tools for doing work with language when
    meeting this。 particular task is what you're seeing in the slide here， which is
    you can see the angry。 red squiggly lines underneath these words in Jabberwocky。
    This is actually a screenshot of what Keynet shows me when I'm editing the slide，
    like the。
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 使用传统工具处理语言时所面临的问题就是您在幻灯片中看到的，您可以看到在《杰伯沃基》中这些单词下方的愤怒红色波浪线。这实际上是我在编辑幻灯片时Keynet给我的截图。
- en: previous slide in this presentation。 Those squiggles mean that these words have
    been misspelled according to Keynet's spell。 check。 But they are actually spelled
    out， right？ Even though these words aren't in the dictionary。 we still know how
    to pronounce them and we， still get a feeling from them。 The spelling suggests
    a particular set of sounds。 And that's what concerns me with this machine learning
    model that we're going to talk about。
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次演示的前一张幻灯片中。这些波浪线意味着根据Keynet的拼写检查，这些单词拼写错误。但它们实际上是拼写正确的，对吧？即使这些单词不在字典中，我们仍然知道如何发音，并且我们仍然能从中感受到某种意义。拼写暗示了一组特定的声音。这就是我对我们将要讨论的机器学习模型所关注的。
- en: That is， how did Lewis Carroll or Kuchenic or Sophia Samitar or a Baroness Elsa
    von Freitag。 Loranghoven， how did they decide how to spell the words that they
    made up？ They had a phonetic idea。 but then they put it on the page in a particular
    way。 So how do you spell made up words and then how do you read them？ So if I'm
    going to do that。
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，路易斯·卡罗尔、库亨尼克、索非亚·萨米塔尔或巴伦娜·艾尔莎·冯·弗莱塔格·洛朗霍芬是如何决定他们创造的单词拼写的？他们有一个语音想法，但然后以特定的方式将其写在页面上。那么，如何拼写虚构的单词，又如何阅读它们？所以如果我要这样做。
- en: if I'm going to write a computer program that does those。 two stops of taking
    a phonetic idea and turning it into the written word and taking the written。 word
    and turning it into a phonetic idea， I need a program that can do two things。
    It needs to be able to convert sounds to letters and it needs to be able to convert
    letters to。
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我要编写一个程序来实现这两个步骤，即将语音想法转化为书面文字，并将书面文字转化为语音想法，我需要一个能够执行两项功能的程序。它需要能够将声音转换为字母，并且需要能够将字母转换为。
- en: sounds。 Another word for the sounds of language is its phonology。 An individual
    sounds and language are called phonemes。 The word for the writing system of language
    is orthography。 So when I'm talking about letters and spelling， I'm talking about
    the language is orthography。
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 声音。语言的声音的另一个词是音韵学。语言中的个别声音称为音素。语言的书写系统称为正字法。因此，当我谈论字母和拼写时，我是在谈论语言的正字法。
- en: So I need a phoneme to orthography program and an orthography to phoneme program。
    There is actually a resource that makes this process easier and that's the CMU
    pronouncing。 dictionary。 This is an online freely available list of over 100，000
    English words along with their。 phonetic transcriptions。 The transcriptions are
    in a phonetic alphabet called arperbets。
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我需要一个音素到正字法的程序和一个正字法到音素的程序。实际上，有一个资源可以使这个过程更简单，那就是CMU发音字典。这是一个在线的免费可用的英语单词列表，超过100,000个单词及其语音转录。转录使用一种称为arperbets的音标字母表。
- en: So for each individual word， you get the sounds of that word。 And we're actually
    going to talk about how to use the CMU pronouncing dictionary to do。 certain tasks。
    That'll be the first thing that we cover in the workshop。 But it doesn't quite
    get us to where we need to be。
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个单独的单词，你可以获取该单词的发音。我们实际上将讨论如何使用CMU发音词典来完成某些任务。这将是我们在研讨会中要覆盖的第一项内容，但这并不能完全满足我们的需求。
- en: But you can easily imagine how this would help us solve some of this task。 If
    I do want to know how a particular word is pronounced， I can just look it up。
    I can take the spelling of the word and get the sounds of the word from the CMU
    pronouncing。 dictionary。 Likewise， if I have the sound of some word and I want
    to know what that word is。
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 但你可以很容易想象这将帮助我们解决一些任务。如果我想知道某个特定单词的发音，我可以查找它。我可以拿到单词的拼写并从CMU发音词典中获取单词的发音。同样，如果我有某个单词的发音，想知道那个单词是什么。
- en: I could， do a reverse look up， like look up the word based on its pronunciation。
    One thing that I do want to note about this pronouncing dictionary is that it's
    based。 on one particular variety of English， which is that sort of nameless Midwestern
    North American。 variety of English。 So this isn't， you know， doesn't cover different
    varieties of English。
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以进行反向查找，根据发音查找单词。我想指出，这个发音词典基于一种特定的英语变体，即那种无名的美国中西部英语变体。所以这并不涵盖不同的英语变体。
- en: different kinds of spelling， so different varieties and so forth。 That's definitely
    a weakness of this data set。 On the other hand。 that's the standard that informs
    the rules of spelling that are ingrained。 in our brains by the US educational
    system at least。
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 不同类型的拼写、不同的变体等等。这显然是这个数据集的一个弱点。另一方面，这就是由美国教育系统灌输的拼写规则的标准。
- en: So if we are going to be making a system that works against the standard， like
    something。 that allows us to make unusual words， we have to do that based on some
    original standard。 and that's what this ends up doing。 But I want to note that
    I don't enjoy the idea or promote the idea that there is an。 official way to spell
    a particular word or an official way to pronounce it and that is。
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们要制作一个与标准相对立的系统，比如让我们能够构造不寻常的单词，我们必须基于某种原始标准来实现，而这就是最终的目的。但我想指出的是，我并不享受或提倡某个特定单词有官方拼写或发音的想法。
- en: definitely enforced by the existence of this dictionary。 But the main problem
    with this dictionary is that it is fixed。 It will allow us neither to spell nor
    sound out words that are not in that dictionary。 So we couldn't use this dictionary
    to analyze also on Frightycloring Hoven's sound poetry。
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这一定程度上受到词典存在的影响，但这个词典的主要问题在于它是固定的。它既不允许我们拼写也不允许我们发出不在该词典中的单词。因此，我们无法使用这个词典来分析Frightycloring
    Hoven的声音诗。
- en: which I imagine mostly consists of words that aren't in the sea when pronouncing
    dictionary。 like Aztax-Wass-Knox。 That's not in the sea when you pronounce a dictionary。
    So it can't tell us what the phonetic content of this word is。 So neural networks
    for the rescue。 What we need is a statistical model of what letter will come next
    in a word conditioned。
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我想它主要由不在CMU发音词典中的单词组成，比如Aztax-Wass-Knox。这不在CMU发音词典中，所以它无法告诉我们这个词的音素内容。因此，神经网络来救援。我们需要一个统计模型来预测一个单词中下一个字母的出现。
- en: on some phonetic information or conversely what phoneme， what sound will come
    next in。 a word's pronunciation， conditioned on some orthographic representation
    or its spelling。 If we had that， it would make it possible to spell and to sound
    out made up or nonstandard， words。 So towards that end， over the past actually
    couple of years at this point， I've been developing。
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些音素信息上，或者反过来，某个单词的发音中，下一个声音是什么，这取决于某种拼写或正字法的表现。如果我们有这些信息，就能拼写和发出虚构或非标准单词的声音。因此，在过去几年里，我一直在开发这个系统。
- en: a model and pipe on library called Pinsulate， which has a machine learning model
    that does。 both of these things， converts sounds to text and text to sounds。 So
    Pinsulate is free and open source。 It's Python 3。6 and later。 You can install
    it using PIP and we'll do that a bit later in the workshop。
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 一个名为Pinsulate的模型和管道库，拥有一个机器学习模型，可以实现这两项功能，将声音转换为文本，也将文本转换为声音。因此，Pinsulate是免费且开源的，支持Python
    3.6及以上版本。你可以使用PIP安装，稍后我们将在研讨会中进行安装。
- en: This is the basic use of this and we're going to go through a bunch of more
    sophisticated。 examples of the library， but just to give you a preview。 Pinsulate's
    machine learning model gives you phonemes based on a spelling that you give， it。
    even if it isn't the senior pronounced dictionary， and it can produce plausible。
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这是该工具的基本使用，我们将深入探讨该库的一些更复杂的示例，简单预览一下。Pinsulate的机器学习模型根据你提供的拼写给出音素，即使它不是正式发音字典中的内容，也能生成合理的。
- en: spellings of arbitrary sequences of phonemes。 I'm not the first person to do
    this。 Obviously。 your theory knows how to， has a rudimentary idea of how to spell
    out words。 that aren't in its dictionary， like people's names and stuff， even
    if you say a name into， it。 it'll take a pretty good guess。 There's a whole bunch
    of research that exists on this。
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我并不是第一个这样做的人。显然，你的理论知道如何拼写字典中不存在的词，比如人名等，即使你把一个名字说给它，它也会做出相当不错的猜测。这方面有大量的研究存在。
- en: The thing that's missing from this existing research is the thing that I'm actually
    focused。 on in a poet， which is the internal phonetic representation of a word。
    A lot of the most recent research on spelling to speech， most of these applications
    are。 in text to speech， is learning the actual audio waveform based on the spelling
    of the， word。
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现有研究中缺少的东西是我作为诗人实际关注的东西，即一个词的内部音位表示。最近关于拼写到语音的研究，尤其是在文本转语音方面，大多数应用正在学习基于单词拼写的实际音频波形。
- en: and doesn't have that intermediate phonetic representation at all。 As a poet。
    that's not super useful to me because I'm interested in the printed word on the，
    page。 so being able to spell out a nonsense word isn't actually something that's
    covered。 by a lot of this existing research。 The model that I designed and implemented
    and trained is based on largely the curious。
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 并且根本没有中间音位表示。作为一名诗人，这对我来说并不是非常有用，因为我对页面上的印刷字词感兴趣，因此拼写出一个无意义的词实际上并没有被现有的很多研究涵盖。我设计、实现和训练的模型主要基于奇怪的任意音素序列拼写。
- en: sequence-to-sequence example code， but it does have a very particular purpose，
    which。 is for my particular poetic work。 An addition to just spelling and sounding
    words out。 pencil aid makes possible some other， interesting techniques that we'll
    talk about for spelling words expressively that I've been。 using in my own poetry，
    and I'm going to talk about a couple of those techniques in this。
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 序列到序列示例代码，但它确实有一个非常特定的目的，适用于我的特定诗歌创作。除了拼写和发音词语，pencil aid还可以实现一些其他有趣的技巧，我们将讨论我在自己诗歌中使用的这些拼写词语的表现技巧，我将谈到其中几个技巧。
- en: presentation and then later on in the workshop we'll see the code to actually
    make it happen。 So just to give us some concrete vocabulary for discussing the
    model architecture， I'm。 going to talk a bit about how sequence-to-sequence models
    work。 This is an extremely high level explanation。 It's based on sequence-to-sequence
    models that use RNNs。
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 演示，稍后在研讨会上我们将看到实现它的代码。为了给我们讨论模型架构提供一些具体的词汇，我将谈谈序列到序列模型的工作原理。这是一个非常高层次的解释。它基于使用RNN的序列到序列模型。
- en: a lot of the current work in， natural language processing is using a different
    species of a governmental network model called。 a transformer， and I just haven't
    taken the time to learn how transformers work until。 redevelop this model using
    that architecture。 So just take this with a grain of salt that is sort of over-simple-vide
    and also a little。 bit or a little bit far away from the state of the art。
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 目前自然语言处理的许多工作使用一种不同种类的政府网络模型，称为transformer，我一直没有花时间去学习transformer的工作原理，直到重新开发这个模型使用那种架构。所以请稍微保留一点批判态度，这种解释有点过于简单化，并且与最先进的技术有点距离。
- en: But the overall structure is basically the same regardless of the architecture，
    which is。 to say that sequence-to-sequence model consists of an encoder whose
    job is to take a sequence。 of tokens from language A and encode it as a fixed-length
    feature vector。 It does this with a recurrent neural network in the case of a
    pencil aid like an LSTM or， GRU。
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 但无论架构如何，总体结构基本相同，也就是说，序列到序列模型由一个编码器组成，它的工作是将语言A中的一个序列的标记编码为一个固定长度的特征向量。在像LSTM或GRU的pencil
    aid情况下，它是通过递归神经网络实现的。
- en: those are both kinds of recurrent neural network architectures。 And that feature
    vector。 so you encode the sequence with recurrent neural network， it。 gives you
    a feature vector that's sometimes called its hidden state。 The role of the decoder
    is to look at the sequences in language B and predict the next。
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种都是递归神经网络架构。还有那个特征向量。因此，你用递归神经网络对序列进行编码，它会给你一个特征向量，有时称为其隐藏状态。解码器的作用是查看语言B中的序列并预测下一个。
- en: token in the sequence conditioned on the feature vector from the encoder。 So
    it takes two inputs。 which is the sequence in language B and then the feature
    vector from。 language A and then it tries to predict the next item in the sequence
    based on that。 If this were an image captioning model， that feature vector would
    be like the features extracted。
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在序列中基于编码器的特征向量对标记进行条件处理。因此，它接受两个输入，一个是语言B的序列，另一个是来自语言A的特征向量，然后它尝试根据这些预测序列中的下一个项。如果这是一个图像字幕模型，那么那个特征向量就像是提取的特征。
- en: using a convolutional neural network is trained on a set of images。 So actually
    those kinds of architectures have something in common in that it's a text token。
    prediction task that's conditioned on the same preexisting feature。 The sequence-to-sequence
    model is what happens when you put these two elements together。
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 使用训练在一组图像上的卷积神经网络。所以，实际上这些类型的架构有一些共同点，那就是这是一个基于相同已有特征的文本标记预测任务。序列到序列模型就是将这两个元素结合在一起时发生的事情。
- en: You get something that looks like this。 You put language A in and you put language
    B in and then you get predictions about language。 B out to condition on language
    A。 Now the most typical use of sequence-to-sequence networks is machine translation。
    If you have a bunch of paired sentences， you can train the model to make an automated
    system。 that appears to translate from say English to Chinese。
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 你得到的结果看起来像这样。你输入语言A和语言B，然后你就可以得到关于语言B的预测，以条件语言A。序列到序列网络的最典型用法是机器翻译。如果你有一堆配对的句子，你可以训练模型来构建一个自动化系统，这个系统似乎是将英语翻译成中文。
- en: That's like the regular use of sequence-to-sequence models is in machine translation。
    In my case。 the languages that I'm translating between are the spelling of the
    word and the。 phonemes in the word。 For one， sequence-to-sequence models and then
    a second sequence-to-sequence model that's。 included in the insulate translates
    from phonemes to spelling。
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 正常使用序列到序列模型的地方是在机器翻译。在我的情况下，我所翻译的语言是单词的拼写和单词中的音素。一个序列到序列模型，然后是一个第二个序列到序列模型，它包含在绝缘中，将音素翻译成拼写。
- en: So those are the two languages involved in the sequence-to-sequence task。 It's
    actually a bit more sophisticated than that and we'll get into that later。 The
    phonemes are represented in an interesting way that gives us a bit more flexibility。
    Then just using the original phoneme data in the Seamium-Pronouncing Dictionary。
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这就是在序列到序列任务中涉及的两种语言。实际上，它比这要复杂一些，我们稍后会谈到。音素以一种有趣的方式表示，这给我们提供了更多的灵活性。然后只是使用原始音素数据在Seamium发音字典中。
- en: But we will get to that。 So to do all the weird stuff with spelling that I want
    to do。 actually the network of， this library， the way that these models are applied，
    forms a loop。 In other words， you start with the spelling。 The spelling is translated
    into the phonemes and then the phonemes are translated back to。 the spelling。
    Basically， you put the text in， the model sounds it out and then it attempts to
    spell。
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们会谈到这个。所以，为了做我想做的关于拼写的奇怪事情，实际上，这个库的网络，这些模型的应用方式，形成了一个循环。换句话说，你从拼写开始。拼写被翻译成音素，然后音素又被翻译回拼写。基本上，你输入文本，模型发音，然后尝试拼写。
- en: it again based on how it sounded out。 That seems kind of useless on the surface。
    If you've already got the orthography， why do you need to sound it out just to
    get the。 orthography again？ The architecture actually provides a great deal of
    flexibility。 In particular。 I can use the feature vectors of the encoder as an
    intermediate representation。
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 根据它发音的结果再次拼写。这在表面上似乎有点无用。如果你已经得到了正字法，为什么还要发音再获得正字法呢？这种架构实际上提供了很大的灵活性。特别是，我可以将编码器的特征向量用作中间表示。
- en: of the word sounds and I can manipulate those representations， resize them，
    blur them， randomize。 them， add noise to them and then put them back into the
    network in order to translate。 them back into regular spelling。 I can also write
    code to guide the decoding process at either point of decoding to boost。 or attenuate
    the probabilities of certain letters or phoneme features being predictive。
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以操控这些词音的表示，调整它们的大小，模糊它们，随机化它们，添加噪声，然后再将它们放回网络中，以便将它们翻译回常规拼写。我还可以编写代码，在解码的任何点引导解码过程，以增强或衰减某些字母或音素特征的预测概率。
- en: and this gives us the ability to do to create some interesting phonetic or orthographic，
    effects。 This is a demo。 I'll actually see the code behind this later where I
    can reduce the probability。 say， of， the letter E occurring or I can take down
    the probability of any vowel occurring。 These sliders are attenuating the probabilities
    in the softmax prediction layer of the neural。
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这使我们能够创造一些有趣的语音或正字法效果。这是一个演示。我实际上稍后会看到背后的代码，我可以降低字母E出现的概率，或者我可以降低任何元音出现的概率。这些滑块在神经网络的softmax预测层中衰减概率。
- en: network model for these features。 I can tell the model to spell out these words
    as though these letters do not exist。 Likewise I can apply these same transformations
    to phonetic features。 This is another example with orthography。 I forgot everything
    that was in this video。 I can decrease the probability of the word ending at all
    and then the model just has to。
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这些特征的网络模型。我可以告诉模型拼写这些单词，好像这些字母不存在一样。同样，我可以将这些相同的变换应用于语音特征。这是另一个关于正字法的例子。我忘记了这个视频中的一切。我可以降低单词结束的概率，然后模型只需继续。
- en: keep on spelling the word as though the word doesn't end or I can increase the
    probability。 of a particular letter happening。 Now it tends to pick H when it
    could pick some other letter which gives you this weird。 effect。 Likewise with
    this model I can adjust the phonetic probabilities so I can increase the。 particular
    phonetic features in the output。 This is making consonants more velar which is
    the flashy part at the back of your tongue。
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 拼写这个单词，好像这个单词没有结束，或者我可以增加特定字母出现的概率。现在它倾向于选择H，而不是其他某个字母，这就给你这种奇怪的效果。同样，利用这个模型，我可以调整语音概率，从而在输出中增加特定的语音特征。这使得辅音更具软腭音，这正是舌头后部的闪亮部分。
- en: I can make them more nasal by picking sounds that tend to go through your nose。
    This is reducing the voiced property of consonants whether they are spoken with
    your vocal chord。 vibrating and increasing the voiceless making it sort of sound
    like a weird German accent。 or increasing the earnest of words using the rautosized
    feature turns it into a weird meme。
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以通过选择那些往往通过鼻子发出的声音来让它们更鼻音。这减少了辅音的有声特性，无论它们是用声带发出的，振动的，同时增加了无声，使其听起来有点像奇怪的德语口音。或者通过使用拉乌特化特征增强单词的严肃性，使其变成一种奇怪的迷因。
- en: I'm going to get a little more here。 Bilebial features are using more of the
    lips and then increasing I think I have this doing。 More lips， more rounding。
    By boosting these phonetic probabilities you can rewrite this text to make it
    seem as though。 in this case it's like someone saying this phrase but with their
    mouth full or something。 You can apply these transformations to entire texts。
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我这里要多说一点。双唇特征更多地使用嘴唇，然后我觉得我在做到这一点。更多的嘴唇，更多的圆润。通过增强这些语音概率，你可以重写这段文本，让它看起来像是某人在嘴里满是东西的情况下说出的这句话。你可以将这些变换应用于整个文本。
- en: For example by subtracting nasalness but adding stop-iness and voice you can
    rewrite a text。 to make it seem like someone has a head cold。 This is the first
    chapter of Genesis but with a head cold。 It did be getting God created。 They'd
    have it add the earth and the earth was without for avoid。 A darket was a pod。
    The face of the deep。 You can denoise sequences of random characters by sounding
    them out。
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，通过减少鼻音但增加停顿性和声音，你可以重写文本，让它看起来像某人感冒了。这是《创世纪》的第一章，但带着感冒的声音。它是这样开始的：上帝创造了天地，而地是荒凉空虚的。深渊的面貌。你可以通过发声来去噪一串随机字符。
- en: So these are just like sequences random sequences of English characters and
    then it tries to。 sound them out and then writes out what how they should be pronounced。
    You can add random noise to feature vectors to create new magic words。 This is
    taking the underlying predicted phonetic feature vector of the word abracadabra
    and。
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这些只是随机的英语字符序列，然后它尝试发出声音，再写出它们应该如何发音。你可以向特征向量添加随机噪声以创造新的魔法单词。这是对单词 abracadabra
    的潜在预测音位特征向量进行处理，并。
- en: adding normally distributed random noise to it。 We'll see an example of how
    to do this in the code later。 This is generating new words that combine phonetically
    the two words on either side。 So it's basically taking the feature vector for
    both of the words on either side and adding。 them together dividing by two finding
    essentially the midpoint between on the line that connects。
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 向其添加正态分布的随机噪声。我们稍后将在代码中看到如何做到这一点。这是在生成新单词，从发音上结合两侧的单词。所以基本上是取两个单词两侧的特征向量，将它们相加，除以二，找到连接它们的直线的中点。
- en: these two feature vectors and then generating word from that point。 So then
    you get the word that's halfway between those two words phonetically。 So you have
    paper。 the seat， plastic， kitten， puppy， puppy， birthday， Arthur day anniversary，
    artificial。 and teleficile intelligence。 Finally you can do a kind of auto-zoundification。
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个特征向量，然后从那个点生成单词。所以你得到的是在这两个单词之间的单词，从发音上来说。因此你有 paper、seat、plastic、kitten、puppy、puppy、birthday、Arthur
    day anniversary、artificial 以及 teleficile intelligence。最后你可以做一种自动声音化。
- en: So here I am taking the character sequences and turning them into phonetic feature
    vectors。 with the phonetic decoder and then resampling that array with all of
    the resulting vectors。 to have a different size。 So I'm then decoding the spelling
    from the resize vectors。 This is essentially like taking the sound of these words
    and then resizing it to be half。
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 所以在这里，我将字符序列转换成音位特征向量，使用音位解码器，然后用所有结果向量重新采样这个数组，以得到不同的大小。所以我随后从调整大小后的向量中解码拼写。这本质上就像是将这些单词的声音取出，然后将其调整为一半大小。
- en: as big the same way that you would do that with like an audio file or an image。
    Likewise this is taking that same file and or taking that same text and expanding
    it。 making it half or making it double the length that it was before by taking
    the phonetic information。 and stretching it out。 So it turns language into this。
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 和音频文件或图像一样，以同样的方式进行处理。同样，这取用了相同的文件，或者说取用了相同的文本，进行扩展。将其缩小一半或加倍长度，通过提取音位信息并将其拉伸。所以它将语言变成这个。
- en: the sound of language into this kind of malleable material。 that we can manipulate
    using actually the same algorithms that you would use to manipulate。 sound or
    image data。 A piece that I made with this that I want to share here at the end
    of this presentation。 is called compasses。 And this piece is a chapbook and Andreas
    Bullhoff's Sink series that generates new words。
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 语言的声音变成这种可塑性材料。我们可以使用实际上相同的算法来操作声音或图像数据。我制作的这一作品，我想在这个演讲的最后分享，叫做 compasses。这件作品是一本小册子和
    Andreas Bullhoff 的 Sink 系列，它生成新单词。
- en: between other words。 The way that it works is like this it starts with four
    words that form a quartet and then。 it finds the words that are between each one
    of those words and then averages them to put。 the average of all of those words
    is put into the middle。 So you get a poem that's like north， east。 south， west，
    west， west， and then a earth， in the middle。
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在其他单词之间。它的工作方式是这样的：它从四个单词开始，形成一个四重奏，然后找到那些在每一个单词之间的单词，然后将它们平均，以将所有单词的平均值放在中间。所以你得到一首像
    north、east、south、west、west、west，然后在中间是 earth 的诗。
- en: So I'm going to read like a couple of these using like an animated format so
    that it doesn't。 reveal everything it was。 So here's another one， noon through
    three， this six， nick， nine， noon。 nine。 Sian， Maylett， yellow， Balow， black，
    Bleeing， Nita， Google， Aglesen， Amazon。 a Spound Facebook， as pool， apple， apple，
    as bowl。
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我打算用一种动画的格式读出其中的一些，这样不会揭示所有内容。所以这里是另一个例子，noon through three，这六，nick，nine，noon。nine。Sian，Maylett，yellow，Balow，black，Bleeing，Nita，Google，Aglesen，Amazon。a
    Spound Facebook，as pool，apple，apple，as bowl。
- en: So this is some of the things that we're going to do with the phonetic model。
    Coming back to sound poetry and nonsense for a second， Cred d'Orcan has this to
    say about， Xam。 owing to the way it challenges conventional interpretation， it
    shows the inadequacy of linguistic。 models based on the language game of giving
    information that this use of language is just。
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，这就是我们将用语音模型做的一些事情。回到声音诗和无意义的主题，Cred d'Orcan对此有话要说，Xam由于挑战传统解释的方式，显示了基于提供信息的语言游戏的语言模型的不足之处。
- en: one among many and that even in this use language still pursues its independent
    parallel formal。 games and that those formal properties can themselves be used
    for aesthetic and rhetorical。 purposes。 In the context of machine learning and
    natural language processing and just computational。 analysis of text altogether，
    almost all of that work is focused on syntax and semantics。
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在众多模型中，即使在这个使用中，语言仍然追求其独立的平行形式游戏，这些形式特性本身也可以用于美学和修辞目的。在机器学习、自然语言处理以及文本的计算分析方面，几乎所有的工作都集中在句法和语义上。
- en: with the idea of being able to extract meaning from new texts。 You have like
    sentiment analysis models， you have summarization models， you have things。 like
    GPT-2 that are based on trying to find the next token in a sequence of text based。
    on a large purpose。 What this model is supposed to。
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 旨在从新文本中提取意义。你有情感分析模型，有摘要模型，还有像GPT-2这样的东西，它们试图基于大型目的，在文本序列中寻找下一个标记。这个模型应该。
- en: what my intention of this model is to draw attention to this。 other part of
    language that is equally as important， the sound of language and what the。 sound
    of language can do to us emotionally when it does to us aesthetically。 It contributes
    to the way that we experience language in a very embodied， material way。
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我这个模型的意图是引起对语言另一部分的关注，这同样重要，即语言的声音，以及语言的声音在美学上对我们情感的影响。它贡献了我们以一种非常具身的、物质的方式体验语言的方式。
- en: and yet hardly any attention is paid to it in formal academic research。 The
    purpose of this model is to try to get these tools into the hands of people to
    show。 that computation can give us access to this whole other aspect of language
    that requires。 us to think about language in an embodied aesthetic way。
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在正式的学术研究中几乎没有人关注它。这个模型的目的是尝试将这些工具交到人们手中，展示计算如何让我们接触到语言的另一个方面，这要求我们以一种具身的美学方式思考语言。
- en: We'll move on to the tutorial in just a second。 Let's get started with the code
    portion of this tutorial。 All the materials for the workshop are at this GitHub
    repository。 It's github。com/aparish/nonsense-pycon-2020。 If you go here， there's
    GitHub repository that has a number of Jupyter notebooks that have。 the example
    code for the class。 The way that I'm going to recommend that you do this。
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们马上就会进入教程部分。让我们开始这个教程的代码部分。研讨会的所有材料都在这个GitHub仓库中。网址是github.com/aparish/nonsense-pycon-2020。如果你访问这里，会有一个包含多个Jupyter笔记本的GitHub仓库，这些笔记本有课堂示例代码。我推荐你这样做。
- en: the way that you follow along with， me is to clone the repository。 make a Python
    virtual environment and then install the requirements。 that are inside of the
    repository and requirements。txt and then launch Jupyter notebook at the command，
    line with the Jupyter notebook command。
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 你跟着我做的方法是克隆这个仓库，创建一个Python虚拟环境，然后安装仓库和requirements.txt中的要求，然后在命令行中使用Jupyter
    notebook命令启动Jupyter笔记本。
- en: If you're not familiar with any of those steps， I'm going to leave it up to
    you to seek out。 the information to do that。 If you're not familiar with Jupyter
    notebooks。 in the home page for the tutorial， I link， to my own little short tutorial
    notebook that has keystroke shortcuts and basic explanation。 of what a Jupyter
    notebook is。
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对这些步骤不熟悉，我将留给你去寻找相关信息。如果你对Jupyter笔记本不熟悉，在教程的主页上，我链接了我自己的简短教程笔记本，其中有按键快捷键和Jupyter笔记本的基本解释。
- en: '![](img/8b020ff93a34aaaec015555fe5d65b80_3.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8b020ff93a34aaaec015555fe5d65b80_3.png)'
- en: If you look at the actual notebook， you can see that they have all of the code
    that I'm。 going to go through already pre-written GitHub will actually render
    these。 You can use these notebooks pre-written。 What I'm going to do in the tutorial
    though is I'm going to go through and I'm going to。 re-type some of the example
    code while I'm going through it。
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看实际的笔记本，你会发现他们已经预先编写了我将要讲解的所有代码。GitHub实际上会渲染这些内容。你可以使用这些预先编写的笔记本。不过在教程中，我将逐步重新输入一些示例代码。
- en: Then occasionally I might just cut and paste a larger example directly from
    the notes when。 it doesn't really make sense to type it off from scratch。 Just
    be aware of that。 I'm going to be doing live coding this material and explaining
    it as I go through。 But if you fall behind or don't want to type along with me，
    you can always refer back to。
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 然后偶尔我可能会直接从笔记中剪切并粘贴一个较大的示例，当从头输入没有意义时。请注意这一点。我将现场编码这些材料，并在进行时进行解释。但是如果你跟不上或者不想和我一起输入，你可以随时返回查看。
- en: the original notebook。 Let's get started here。 The first thing I'm going to
    do is switch over to my terminal window。 I'm just going to make a directory here
    in my home directory。 I'm going to call it nonsense PyCon 2020。 Actually let's
    just clone it right here。 I'm going to do get clone and then copy in the URL of
    the repository。
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 原始笔记本。让我们开始吧。我要做的第一件事是切换到我的终端窗口。我将会在我的主目录中创建一个目录。我会把它命名为nonsense PyCon 2020。实际上，我们就在这里克隆它。我将执行`git
    clone`，然后复制仓库的URL。
- en: That's going to clone it into a directory called nonsense verse PyCon 2020。
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这将把它克隆到一个名为nonsense verse PyCon 2020的目录中。
- en: '![](img/8b020ff93a34aaaec015555fe5d65b80_5.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8b020ff93a34aaaec015555fe5d65b80_5.png)'
- en: You can see all the files there。 I'm going to create a PyCon virtual environment。
    I'm just going to call it n。 If you want to use anaconda or whatever other way
    of doing Python stuff。 that's fine。 I just think that virtual environments are
    a nice way to do it。 Plus we're going to have to install TensorFlow as part of
    this process。
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到所有的文件。我将创建一个名为n的PyCon虚拟环境。如果你想使用anaconda或其他方式进行Python操作，没问题。我只是认为虚拟环境是一种不错的方式。而且我们在这个过程中必须安装TensorFlow。
- en: I find that the TensorFlow installation process is easiest through PIP。 I'm
    going to activate that environment。 Source and vbin activate。 Then I can do PIP
    install from requirements。txt。 This might take a little bit of time to install。
    I already have all of these packages cached。 Hopefully I don't need to do any
    building or anything like that。
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我发现通过PIP安装TensorFlow的过程是最简单的。我将激活那个环境。运行`source vbin activate`。然后我可以从`requirements.txt`中执行PIP安装。这可能需要一点时间来安装。我已经缓存了所有这些包。希望我不需要进行任何构建或其他操作。
- en: I should just be able to put them right into the directory。 I'm going to go
    ahead and move my notes over to my second screen so I can follow them。 The outline
    of what we're going to do today is first。 I'm going to show you about the CMU
    Pronouncing Dictionary and how that works。
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我应该可以直接把它们放到目录里。我要把我的笔记移到第二个屏幕，这样我就可以跟着它们了。我们今天要做的事情的提纲是首先。我将向你展示CMU发音字典及其工作原理。
- en: To do that we're going to use a library that I wrote called Pronouncing which
    is a Python。 library that gives you an easy computational or easy API to the CMU
    Pronouncing Dictionary。 That's already going to be installed once you're done
    installing the packages over here。 GitHub is being very reticent about actually
    previewing my notebooks。
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，我们将使用我写的一个名为Pronouncing的库，这是一个Python库，提供了对CMU发音字典的简单计算接口或API。一旦你安装完这里的包，它就会自动安装。GitHub在预览我的笔记本时非常犹豫。
- en: I might have to bring it up on my computer in a different window。 This will
    work。 So this is still taking a bit of time to compile。 While we're waiting for
    that to happen。 let's talk about the CMU Pronouncing Dictionary。 As you may know，
    if you are an English speaker。 especially if you learned English as a second，
    language。
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我可能需要在我的电脑上打开一个不同的窗口来查看它。这是可行的。所以这仍然需要一点时间来编译。在我们等待这一过程的时候，让我们谈谈CMU发音字典。你可能知道，如果你是说英语的人，尤其是如果你把英语作为第二语言学习的话。
- en: I find that this tends to be more relevant or more salient。 The way that it
    sounds are not related to each other in meaningful ways。 For that reason。 if you
    want to have a computer program that knows how words are spelled based。 on the
    way they sound， you need some kind of dictionary generally that gives you that
    correspondence。
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我发现这通常更相关或更显著。它们的发音之间没有有意义的关系。因此，如果你想要一个能够根据单词的发音了解单词拼写的计算机程序，你通常需要某种词典来提供这种对应关系。
- en: between the two things。 The CMU Pronouncing Dictionary is an online dictionary
    that is currently maintained by。 CMU。 It was originally funded with the United
    States Defense Department funding。 This is the homepage of the CMU Pronouncing
    Dictionary。 You can look up words inside of here。 I could look up， for example，
    I don't know， water cress。 I don't know why that's on my mind。
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: CMU发音词典是一个在线词典，目前由CMU维护。最初是由美国国防部资助的。这是CMU发音词典的主页。你可以在这里查找单词。我可以查找，例如，我不知道，水田芥。
    我不知道为什么我会想到这个。
- en: Then it gives you the word and the words pronunciation。 These pronunciations
    are in a phonetic transcription system called the ARPABET。 There's a guide to
    the ARPABET here。 This shows you the phoneme symbol and the sound that it corresponds
    to in English。 It's important to remember for this entire workshop that there
    isn't a one-to-one correspondence。
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 然后它会给你单词和单词的发音。这些发音使用一种叫做ARPABET的音标转录系统。这里有ARPABET的指南。这向你展示了音素符号以及它在英语中的对应声音。对于整个研讨会来说，重要的是要记住字母和声音之间并不是一一对应的。
- en: in English between a letter and a sound。 In some languages you get pretty close
    to that。 but in English very famously about English， we don't have that。 We need
    to use。 if you want to get the pronunciation for a word， the easiest way to do
    that is with。 the CMU Pronouncing Dictionary。 Now a problem with the CMU Pronouncing
    Dictionary is that if I type in something like Pikachu。
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在英语中，字母和声音之间没有一一对应。在某些语言中，你可以相当接近这个，但在英语中，众所周知，我们并没有这个。如果你想获取一个单词的发音，最简单的方法就是使用CMU发音词典。现在CMU发音词典的问题是，如果我输入像皮卡丘这样的词。
- en: it says Pikachu is not in the dictionary。 The dictionary is very thorough and
    you can look at the full dictionary here。 Here's all of the words that are inside
    of it。 There's 130，000 words in here。 but there are a lot more words in English
    than 130，000 that。 you might find yourself using that you might find in any given
    corpus。 It's not perfect。
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 它显示皮卡丘不在词典中。这个词典非常全面，你可以在这里查看完整的词典。这是里面所有的单词。这里有130,000个单词，但英语中有远不止130,000个单词。你可能会发现自己在任何给定语料库中使用的单词。它并不完美。
- en: It doesn't give us all of the words that we want to be able to use。 That's a
    limitation of the CMU Pronouncing Dictionary。 Just as a starting point。 I think
    it's helpful to talk about this before we go on to methods。 of coping with the
    fact that the CMU Pronouncing Dictionary doesn't cover all the words that。
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这并没有给我们提供我们想要使用的所有单词。这是CMU发音词典的一个局限性。仅仅作为一个起点。我认为在我们讨论应对CMU发音词典未涵盖所有单词的方法之前，谈论这个是有帮助的。
- en: you might want。 My libraries are now installed， so I'm going to launch Jupyter
    Notebook and bring over。 my Jupyter Notebook window。 I'll launch it on my other
    screen， so I'm going to pop it over here。 Now you have Jupyter Notebook running
    and then these are the example notebooks that I am going。 to go through。 Like
    I said， I'm going to do this instead of taking you through the notebooks。
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能想要的。我的库现在已安装，所以我将启动Jupyter Notebook并打开我的Jupyter Notebook窗口。我会在另一个屏幕上启动它，所以我把它放到这里。现在你已经运行了Jupyter
    Notebook，然后这些是我将要讲解的示例笔记本。正如我所说，我将这样做，而不是带你逐个查看笔记本。
- en: I'm going to live code some of the examples and take you through those examples。
    But again。 if you fall behind， if you don't know what I'm talking about or if
    you don't。 want to do all the typing on your own， then you can always just open
    the notebook that。 I'm working from， cut and paste the examples and it's going
    to be fine。
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我将实时编码一些示例并带你了解这些示例。但再次强调，如果你跟不上，如果你不知道我在说什么，或者如果你不想自己打所有的字，那么你总是可以打开我正在使用的笔记本，复制粘贴这些示例，这样就没问题。
- en: So I'm going to make a new notebook here and we will just go through with that。
    So a question in these， I'm just going to make a header here， PyCon 2020 tutorial
    with， a listen。 parish。 A question that I like to take people through when I'm
    doing workshops like this is to ask。 I'll make this a little bit bigger， how many
    vowels are there in English？
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我这里要做一个新的笔记本，我们就用这个来进行。这里有一个问题，我将做一个标题，PyCon 2020教程，带有聆听。一个我喜欢在这类工作坊中带领大家的问题是问。我会把这个放大一点，英语中有多少个元音？
- en: Most people in response to this question say， well， there are five， right？ A-e-i-o-u。
    And then sometimes， why？ So five， five or six， five and a half vowels in English。
    That actually isn't the case and I can prove it to you。 There's something in linguistics
    called a minimal pair。
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数人在回应这个问题时说，嗯，有五个，对吧？A-e-i-o-u。有时还有y。所以英语中有五个、五个或六个、五个半元音。实际上并不是这样，我可以证明给你看。语言学中有一个叫做最小对立体的东西。
- en: A minimal pair is a way of knowing whether two words sound differently by the
    fact that。 we can distinguish between the two of them。 So an example of a minimal
    pair might be like bat and pat。 right？ These two words are the same except for
    their initial sound。 So we know that ba and pa are separate sounds in English
    because these are different words， right？
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 最小对立体是一种知道两个单词通过声音的不同而区别开来的方法。一个最小对立体的例子可能是bat和pat，对吧？这两个词除了它们的初始音外是相同的。所以我们知道ba和pa在英语中是不同的声音，因为这些是不同的单词，对吧？
- en: So for us to know how many vowels there are in English， we'd have to find some
    way to。 make a minimal pair is for every possible vowel sound。 A good example
    or a good way of doing that is with followed by， and see how many vowels。 we can
    put in between those two consonants and see how many words we can make that way。
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 所以要知道英语中有多少个元音，我们必须找到某种方法。制作一个最小对立体，以便为每个可能的元音音素提供例子。一个好的例子或做法是跟随，并看看我们可以在这两个辅音之间放入多少个元音，看看我们可以这样形成多少个单词。
- en: So I can make a bunch of them。 We have tik。 We have tik。 We have tak。 There's
    the word tak。 There's the word talk。 We have the word tok。 Where what am I looking
    for？ Tok like that。 like toking from a smokable substance。 And then we have， this
    isn't in American English。 but apparently you can have a tuk。 Maybe it's spelled
    like this as a word for like a woolen cap。
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我可以做很多。我们有tik。我们有tik。我们有tak。还有单词tak。还有单词talk。我们有单词tok。我在找什么？Tok像那样。像吸食可吸入物质的那样。然后我们有，这在美式英语中没有。但显然你可以有一个tuk。也许这个单词是拼写成像一个羊毛帽子。
- en: We also have the word tak。 So that's already like one， two， three， four， five，
    six， seven， eight。 nine separate vowel， sounds。 And then of course we have the
    word tuk。 That's a different vowel sound altogether。 If we start counting diphthongs。
    then we end up with words like tik。 That's another one that can go in there。
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还有单词tak。所以这已经像是一个、两个、三个、四个、五个、六个、七个、八个、九个不同的元音音素。然后当然我们还有单词tuk。这是完全不同的元音音素。如果我们开始计算双元音，那么我们会得到像tik这样的词。这是另一个可以放进去的。
- en: There isn't a word in English called that sounds like toik。 There could be。
    but there just doesn't happen to be a word tik。 But you can imagine， like。 we
    can distinguish between the words tiki and the word word sequence， tiki。 So tiki，
    tiki。 the only way that they differ is with that voice sound。 So again， depending
    on your accent。
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 英语中没有一个听起来像toik的单词。可能会有，但恰好没有一个单词tik。但是你可以想象，我们可以区分单词tiki和词序tiki。所以tiki，tiki。它们唯一的区别在于那个语音。因此，再次根据你的口音。
- en: depending on， you know， how you count what a vowel is， in English， we have at
    least one， two， three。 four， five， six， seven， eight， nine， ten， eleven， twelve
    different vowel sounds。 This is actually a really large number of vowel sounds
    for a language。 Most languages in the world have on average like four to six distinctive
    vowel sounds。
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你知道的，如何计算什么是元音，英语中至少有一、二、三、四、五、六、七、八、九、十、十一、十二种不同的元音音素。这实际上是一个相当大的元音音素数量。世界上大多数语言平均只有四到六个独特的元音音素。
- en: And if you're a native speaker of a language like Spanish or Mandarin Chinese，
    that's about。 how many vowels those languages have。 It's just English is a part
    of this group of northern Germanic languages that for some。 reason have lots and
    lots of different vowel sounds。 This should demonstrate to you at least that。
    well， a couple of things。 One is that when we talk about vowels， when you say
    there are five vowels。
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是西班牙语或普通话的母语者，这大约是这些语言中的元音数量。英语是北日耳曼语言群的一部分，出于某种原因，拥有许多不同的元音音素。这至少应该向你展示几个事情。其中之一是，当我们谈论元音时，当你说有五个元音时。
- en: what you mean， is that there are five letters， maybe six。 that are used conventionally
    to represent vowel， sounds in English words。 Right？
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 你的意思是，有五个字母，可能还有六个，通常用于表示英语单词中的元音音素，对吗？
- en: So English doesn't have five vowels。 There are five vowels in the writing system
    that are conventionally used to represent vowel。 sounds。 The other thing to know
    is that， you know， these words， we don't actually。 we can't actually， work out
    reliably the way that they're pronounced based on the way that they're spelled。
    Like， there just isn't enough information in any one of these words to know how
    they're。
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 所以英语没有五个元音。书写系统中有五个元音，通常用于表示元音音素。另一个需要知道的事情是，我们实际上不能可靠地通过拼写来判断这些单词的发音。因为在这些单词中没有足够的信息来确定它们的发音。
- en: pronounced based on how they're spelled。 So this is just to show the necessity
    of something like the CMU pronouncing dictionary to give。 us an idea of how a
    word is spelled。 Or how a word is sound。 how a word sounds based on how it's spelled，
    or how a word is， spelled based on its sounds。 on how it sounds。 So the library
    that we're going to be using to access the CMU pronouncing dictionary is。
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 发音是根据它们的拼写来确定的。这只是为了展示像CMU发音词典这样工具的必要性，以便让我们了解一个单词是如何拼写的，或者一个单词的发音是如何与拼写相关的，或者一个单词是如何根据其发音进行拼写的。我们将要使用的库来访问CMU发音词典是。
- en: called pronouncing。 So this should already be installed if you installed from
    requirements。txt。 So import pronouncing is the way to bring it in。 I'm actually
    going to do import pronouncing as PR just to make a bunch of these calls。 shorter
    and easier to type。 So the first， like， the easiest thing to do with pronouncing
    is the function "phones"。 for word。 And what you do is you pass to that a string。
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 被称为pronouncing。如果你从requirements.txt中安装了，这应该已经安装好了。因此，import pronouncing是引入它的方法。我实际上会将import
    pronouncing简写为PR，以便更短且更易于输入。因此，使用pronouncing最简单的事情是“phones”函数，用于单词。你所要做的就是传递一个字符串。
- en: lowercase string that has an English word in， it and it returns when it loads
    different pronunciations for that string。 So these are the phones or the phonemes，
    the sounds that are in this word that I passed， in here。 You'll notice that this
    list that gets returned has two elements。 That's because "phone for word" returns
    all possible pronunciations of a word。
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 小写字符串中包含一个英语单词，它返回加载该字符串的不同发音。因此，这些是我在这里传递的单词中的音素或音节。你会注意到返回的这个列表有两个元素。这是因为“phone
    for word”返回一个单词的所有可能发音。
- en: This is another thing to know about English is that a single word can have multiple
    pronunciations。 and a single pronunciation can correspond to multiple words。 It's
    many to many relationships。 This is telling us a bunch of different stuff about
    how this word is pronounced。 So let's just take a look at the first one here。
    You have the "sunt p" the vowel sound "er"。
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 关于英语，另一件需要了解的事是一个单词可以有多种发音，而一个发音可以对应多个单词。这是多对多的关系。这告诉我们很多关于这个单词发音的不同信息。那么我们先来看这里的第一个例子。你有“sunt
    p”和元音音素“er”。
- en: That's another one that we didn't actually put up in here。 So if we did a word
    like "turk" in English， that's another distinctive vowel sound。 So "p" or "m"
    "i" is "i" and then "t"。 So these are the list of the phonemes in that word according
    to the ARPABAT transcription。 And again， you can see the ARPABAT， the values for
    these ARPABAT phone symbols on the C-new。
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们实际上没有在这里列出的另一个。所以如果我们在英语中说“turk”这个词，那是另一个独特的元音音素。因此“p”或“m”，“i”是“i”，然后是“t”。这些是根据ARPABAT音标转录的该单词中的音素列表。同样，你可以在C-new上看到这些ARPABAT音符符号的值。
- en: pronouncing dictionary homepage。 And there's a second pronunciation。 "p" or
    "m" it。 The only way that these two pronunciations differ actually is the stress。
    So English has what's known as lexical stress， which is words have their own stress
    patterns。 And you have to memorize the stress patterns that go along with words。
    In this case。
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 发音词典主页。还有第二个发音。“p”或“m”。这两种发音的唯一不同之处在于重音。因此，英语有所谓的词汇重音，即单词有各自的重音模式。你必须记住与单词相对应的重音模式。在这种情况下。
- en: this word here has two different pronunciations。 Permit with the stress on the
    second syllable and permit with the stress on the first syllable。 The way that
    this differ is "permit" is a verb。 I permit you to program and "permit" is "down"。
    So I have a programming permit。 There are a couple of other words that follow
    the same pattern。 So the number on the end of the vowel is telling you the stress
    of that syllable。 And weirdly。
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这个单词有两种不同的发音。重音在第二个音节的“permit”和重音在第一个音节的“permit”。这两者的不同在于“permit”是动词。我允许你编程，而“permit”是“许可”。所以我有一个编程许可证。还有一些其他单词遵循相同的模式。因此，元音末尾的数字告诉你该音节的重音。奇怪的是。
- en: the stress has a strange pattern。 "0" means unstressed。 "2" means secondary
    stress。 And "1" means primary stress。 So in English， we have three different values
    or three different levels of stress in that。 other indicated in the C-new pronouncing
    dictionary。 So importantly。 "2" is the second level of stress， not the highest
    level of stress。
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 重音有一个奇怪的模式。“0”表示不重音。“2”表示次重音。“1”表示主要重音。因此，在英语中，我们有三种不同的值或三种不同的重音级别。在新的发音词典中有所指示。因此，重要的是，“2”是第二级重音，而不是最高级重音。
- en: '"1" is the highest level of stress， which is a neat even mind。 So with that。
    let''s just do like a quick example。 So I''m going to do-- here is a-- we''ll
    just make a text here。 This will be what we use for the rest of the examples in
    this notebook。 "April is the cruelest month， reading， lilacs out of the dead。"，
    Just a little phrase from T。S。'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: “1”是最高的重音级别，这是一个整洁的心态。因此，有了这一点。我们来做一个快速示例。所以我要做——这里是一个——我们只需在这里创建一个文本。这将是我们在这个笔记本中其余示例所用的内容。“April
    is the cruelest month，reading， lilacs out of the dead。”这是 T.S. 的一句小短语。
- en: Eliot's The Wasteland， The Modernist masterpiece。 So let's do some rudimentary
    analysis on this。 So for example， let's count what are the most common sounds
    in this text。 If we wanted to do the most common letters in the text， that would
    be fairly straightforward。 We could do from collections import counter and then
    counter text is just going to count。
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 艾略特的《荒原》，现代主义杰作。因此，让我们对其进行一些基本分析。例如，让我们计算在这个文本中最常见的声音是什么。如果我们想找出文本中最常见的字母，那会相对简单。我们可以从
    collections 导入 counter，然后 counter 文本就会进行计数。
- en: up all of the letters in the text like that。 And then we could do most common。
    giving you like the most common five letters。 And those common five letters are
    space， E-T-I-L。 This is sort of close to what you would expect for any， any reasonably
    long stretch of English。 text， right？ If we wanted to find the most common sounds
    in this text， it's a little bit trickier。
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 像那样将文本中的所有字母汇总。然后我们可以找出最常见的字母，给你前五个最常见的字母。这五个常见的字母是空格、E-T-I-L。这与任何合理长度的英语文本大致相符，对吧？如果我们想找出该文本中最常见的声音，那就有点棘手。
- en: right？ You wouldn't be able to do that just by looking at the text normally。
    So instead。 what we'll do is I'm going to create a list of words， which is going
    to be text。split。 And then I'm going to loop over that list of words。 But first
    I'm going to make like。 we'll make a counter here， count equals counter。 And then
    say forward in words。
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 对吧？你不能仅仅通过正常查看文本来做到这一点。因此，我们将做的是，我要创建一个单词列表，这将是文本。分割。然后我将遍历这个单词列表。但首先我要做的是。我们会在这里创建一个计数器，count
    = counter。然后说向前在单词中。
- en: pronunciation equals pronouncing your PR phones forward， passing in that word。
    That should return a list of all of the possible pronunciations for that word。
    And actually just as a first step， I'm just going to pronounceiations。 Just print
    that out so you can see what that would look like。 Or word in words。
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 发音等于将你的 PR 音前移，传递这个单词。那应该返回该单词所有可能的发音列表。实际上，作为第一步，我只是要发音。只需打印出来，让你看看那会是什么样子。或者单词中的词。
- en: So here you have April is the coolest month breeding lylax out of the dead，
    right？
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这里你有“April”是最酷的月份，能从死亡中孕育出丁香，对吧？
- en: And some of these words have multiple pronunciations。 We don't actually have
    any good criteria to use to decide which one of these pronunciations。 we're going
    to use。 So I'm just going to pick the first one just arbitrarily when I'm doing
    the count。 So then I'm going to say count。update， pronunciations zero dot split。
    So these are。
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 而且这些单词有多个发音。我们实际上没有任何好的标准来决定要使用哪个发音。因此，在进行计数时，我只是随意选择第一个。因此，我将说count.update，发音的零点分割。所以这些是。
- en: it's a list of strings where all of the phones have a space in between， them。
    So this dot split is just going to break that into a list。 And then we update
    the count with that list。 And then here at the end。 I'm going to do count most
    common。 Let's just do the most common five。
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个字符串列表，其中所有电话之间都有一个空格。所以这个点分割只是将其拆分成一个列表。然后我们用那个列表更新计数。然后在这里的最后。我将执行计数的最常见项。我们就找出最常见的五个。
- en: So now we see that the most common sounds in this text are the sound here， which
    is this。 is an unstressed schwa。 That's just like a vowel that's sort of right
    in the middle of your mouth。 Extremely common vowel sound in English。 Basically
    anywhere you have an unstressed syllable。 there's a good chance it's going， to
    be a schwa。 Or， and the th is the zest in the。
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们看到这段文本中最常见的音是这个声音，这个。是一个非重音的schwa。这就像是一个在你嘴中间的元音。在英语中极其常见的元音。基本上只要你有一个非重音的音节。它很有可能是一个schwa。或者，th是这个的精髓。
- en: So nothing super surprising here。 We have mostly， if we were to summarize this
    text phonetically。 you would say or zv， which， actually kind of April is the coolest
    month reading。 why it looks out of the dot。 Kind of sounds like that。 Right。 So
    this is just like a rudimentary text analysis task that we can do only with the
    help of the。
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这里没有什么特别令人惊讶的。如果我们从语音学上总结这段文本。你会说或 zv，实际上四月是最酷的月份的阅读。为什么它看起来像点。听起来有点像那样。对吧。所以这只是一个基本的文本分析任务，我们可以仅凭帮助来完成。
- en: CME pronouncing dictionary。 The next thing that I want to show you is search。
    So what we might want to be able to do is look for words that have particular
    phonetic。 patterns in them。 So for example， let's look for pronouncing phones
    for word size and just get the zeroth。 response from that。 So phones is now going
    to have this size in it。
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: CME发音字典。接下来我想给你展示的是搜索。因此，我们可能想做的是寻找包含特定音位模式的单词。例如，让我们查找单词“size”的发音音素，并仅获取第零个响应。因此，音素现在将包含这个“size”。
- en: If we wanted to find all of the words that have the sequence size in those words，
    like。 all of the words that have size somewhere in them， you would do pronouncing
    dot search。 And then pass in that string that has the phones that you're looking
    for。 And this gives us all of the words that have size somewhere in them。 In size，
    in size， in size。
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想找出所有在这些单词中有“size”序列的单词，比如。所有在它们中有“size”的单词，你会执行发音的搜索。然后传入那个包含你所寻找的音素的字符串。这会给我们所有在它们中有“size”的单词。在大小，在大小，在大小。
- en: or in size， or in size， or in size， or in size， or in size， make more size。
    the weird pronunciation of that word， but okay， over size， over size， and pint
    size， pint size。 size， make size， blah， blah， blah， blah。 So search function returns
    a list of words that in any of their pronunciations has that。 sequence of phonemes。
    We can write these on our own。 So for example， if I wanted to find。
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 或者在大小，或者在大小，或者在大小，或者在大小，或者在大小，增加更多大小。这个词的奇怪发音，但好吧，超大，超大，还有品脱大小，品脱大小。大小，制造大小，等等等等。所以搜索功能返回一个单词列表，这些单词在任何发音中都有那个音素序列。我们可以自己写这些。因此，例如，如果我想找到。
- en: let's find all of the words that have a e sound， a stressed e sound followed
    by a c sound， eek。 everything that has eek in it。 This gives me that list and
    there's a whole bunch of them。 Sometimes just so that I don't end up putting a
    whole bunch of like a big list in the notebook。 I just summarize those results
    by grabbing the first 10 of them using Python list notation。
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们找到所有有“e”音的单词，一个重音的“e”音后面跟着一个“c”音，eek。所有包含eek的内容。这给我一个列表，还有很多。有时为了不把一大堆内容放在笔记本上，我会用Python列表表示法抓取前10个结果来总结这些结果。
- en: And there's those right there。 This function also supports redjacks anchors。
    It actually supports any redjacks in talks that anchors are important。 So if you
    only want to search at the beginning of the word， you can use carrot。 If you only
    want to search at the end of the word， you can use a dollar sign like that。
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 而这些就在这里。 这个函数还支持正则表达式锚点。 它实际上支持任何正则表达式，锚点是重要的。 如果你只想在单词的开头进行搜索，可以使用插入符号。 如果你只想在单词的结尾进行搜索，可以使用像这样的美元符号。
- en: So if I just wanted to find all of the words that begin with eek， I don't actually
    know。 if there are any of those， but here's how I'd write it。 E。 Oh yeah， there
    we go。 A whole bunch of them actually。 E-commerce， ecosystem， eek and berry。 I
    don't know about some of these words。 There's some strange words in some of these
    in the senior pronounced dictionary。
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 所以如果我只想找到所有以 eek 开头的单词，我实际上不知道是否有这些，但我会这样写。 E。 哦，是的，来了。 其实有一大堆。 E-commerce，生态系统，eek
    和 berry。 我对其中一些单词并不确定。 在某些发音字典中有一些奇怪的单词。
- en: Likewise， let's say that I wanted to find all of the words that end in it all。
    So like the word fiddle。 What are all the words that end in that？ I would do pr。search。
    It all looks like this。 Id all like that。 And this gives me all of the words that
    end in while this gives me all of the words that。 contain it。 Sorry。 I have things
    like middle town。 If I want all the words that end it。
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，假设我想找到所有以 it all 结尾的单词。 比如说单词 fiddle。 那么有哪些单词以此结尾呢？ 我将做 pr.search。 一切看起来像这样。
    Id all 这样。 这将给我所有以 while 结尾的单词，这将给我所有包含 it 的单词。 对不起。 我有像 middle town 这样的东西。 如果我想要所有以它结尾的单词。
- en: then I put a dollar sign there and that terminates。 that only searches for that
    pattern at the end of the sequence。 Just one thing to know is that for convenience
    it does automatically put word boundary anchors。 at the beginning and the ending
    of the phrase。 That's just so that you don't accidentally search for like in the
    middle of the phoneme。
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我在那儿放了一个美元符号，它结束了。 这只会搜索序列末尾的那个模式。 需要知道的一件事是，为了方便，它会自动在短语的开始和结束处放置单词边界锚点。
    这只是为了避免你意外地在音位的中间进行搜索。
- en: notation。 So that's search。 So it lets you look upwards according to particular
    sound patterns。 Next thing， or like an example that we can use to take advantage
    of that， let's do a rewriting。 exercise。 A lot of the examples in this tutorial
    are going to be about rewriting texts。 So we rewrite by using the phones of particular
    words。 So for example， we'll take our text。
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: notation。 所以这是搜索。 它允许你根据特定的声音模式向上查找。 接下来，或者说我们可以利用这个的一个例子，让我们进行一次重写练习。 本教程中的许多例子将涉及重写文本。
    我们通过使用特定单词的音位来重写。 例如，我们将提取我们的文本。
- en: which again looks like this。 And let's rewrite it so that we are only using
    or rewriting these texts。 replacing words， with another word that has the beginning，
    the same first two phonemes。 And the way that we would do that is I'm going to
    create a little empty list here。 I'm going to import the Python random module。
    And then just loop over the text for word in text。
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 它看起来像这样。 让我们重写它，使我们只使用或重写这些文本。 用另一个以相同的前两个音位开头的单词替换单词。 我们将这样做，我将在这里创建一个空列表。
    我将导入 Python 的随机模块。 然后就循环遍历文本中的每个单词。
- en: split， which is going to give us all， of the tokens in that string。 Get the
    pronouncing phones for word for that word and just get the zeroth one there。 We're
    assuming that all of these are present inside of the text or inside of the pronouncing。
    dictionary for now。 And then the first two phonemes will grab by doing phones。
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: split，这将给我们该字符串中的所有标记。 获取该单词的发音音位，并仅获取第一个。 我们假设这些都存在于文本中或发音字典中。 然后前两个音位将通过执行
    phones 来获取。
- en: split and just grabbing the first， two of those。 Our search string is going
    to be the first two。 just joining those back together。 And then we will do our
    candidates by going to be pr dot search and then looking for that。 search string。
    But we actually only want to look for words that have that search string at the
    beginning。 So I'm going to put that anchor right there。 And before I put it all
    together。
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 分割并仅获取前两个。 我们的搜索字符串将是前两个，然后将它们重新组合。 然后我们将通过 pr.dot search 来寻找候选项。 但实际上我们只想查找那些以该搜索字符串开头的单词。
    所以我将在这里放置一个锚点。 然后在我把它们组合在一起之前。
- en: I'm just going to do print out the candidates。 Maybe just print out the first
    five candidates for each word。 So just does a debug to see what this is doing
    before we finish with it。 This is showing the word and the first five words begin
    with the same two syllables。 So APACs begins with like April does。 One day begins
    with the same two sounds as month。
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我将打印出候选项。也许仅仅打印出每个单词的前五个候选项。这只是调试一下，以查看这在做什么，然后我们再完成它。这显示了该单词以及与之开头的前五个单词是相同的两个音节。所以“APACs”就像“四月”一样开始。“One
    day”与“month”开头的两个声音相同。
- en: So like bra begins with the same two phonemes as breeding and so forth。 So to
    rewrite this text。 I'm just going to， for each one of these， do out dot append
    and。 then pick one of these at random random dot choice candidates。 And then at
    the end。 print joining that together。 So April is the cruelest month。 April is
    the cruelest month。
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 像“bra”就与“breeding”开头的两个音素相同。为了重写这段文本，我将对每一个进行`dot append`，然后随机选择其中一个候选项。最后，打印将它们连接在一起。所以四月是最残酷的月份。四月是最残酷的月份。
- en: Breeding lilac side of the dead becomes aplicism themselves crimes mugging broadest
    lights。 allow patient ovens them to burr。 Let's maybe let's tweak this a little
    bit。 If we imagine the first three sounds， we can still get it。 So April might
    actually end up being one of only a handful of words that begin with a， aplur。
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: “Breeding lilac side of the dead”变成了“aplicism themselves crimes mugging broadest
    lights”。让我们也许稍微调整一下。如果我们想象前面的三个声音，仍然可以得到它。所以四月实际上可能是仅有的几个以“a”开头的单词之一，*aplur*。
- en: April is a door of themselves。 Crewer， Munser， Rivest， Lyles， out date of the
    debtor。 So you have this new sequence of words that sort of sounds like the original，
    not quite。 but sort of。 Most of the applications that I've imagined for this library。
    I think that there's lots， of different things you could do with it， but I'm a
    poet。
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 四月是他们自己的一个门。Crewer，Munser，Rivest，Lyles，债务人的到期日。所以你有了一系列的新单词，听起来与原来的相似，但并不完全相同。我想象的这个库的许多应用，我认为可以做很多不同的事情，但我是一名诗人。
- en: so I'm mainly thinking of poetic， applications。 When you're talking about poetry。
    one of the main things that you do in poetry is meter。 A meter is like using the
    sound of words。 the rhythmic property of words and incorporating， that into the
    composition of the poem。 One of the big parts of meter is syllable count， so how
    many syllables does a particular word， have？
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我主要考虑的是诗歌应用。当谈到诗歌时，诗歌的一个主要方面就是韵律。韵律就像是使用单词的声音，将单词的韵律属性融入到诗的创作中。韵律的重要部分之一是音节数，那么一个特定单词有多少个音节呢？
- en: In the scheme of pronouncing dictionary， we have all of the information that
    we need to。 count syllables。 And because it's just a common task。 I built that
    into the pronouncing library as well。 So what you can do is get， again。 a list
    of different pronunciations。 Say， "phones，" what's "phones" for word programming。
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在发音字典的方案中，我们有所有需要的信息来计算音节数。因为这是一个常见的任务，我也把这个功能构建到了发音库中。所以你可以再次获得不同发音的列表。比如，“phones”，“phones”在编程一词中的发音是什么。
- en: And we'll just get the zeroth one there。 Here's what's in "phones。" so this
    is the pronunciation of programming。 "Puh" or "o" or "guh" or "a" in。 So programming
    with the stress on the first syllable。 If we wanted to know how many syllables
    there are in that， you can actually look at this。
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将获取第一个结果。这就是“phones”的内容，这里是编程的发音。“Puh”或“o”或“guh”或“a”。所以编程的重音在第一个音节上。如果我们想知道里面有多少个音节，实际上可以查看这个。
- en: string and you could deduce how to do this。 And the way that you're thinking
    of implementing this is actually probably pretty close to the。 way that it's implemented
    in the library。 Basically all we're doing is we're counting how many vowels are
    there。
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 字符串，你可以推导出如何做到这一点。而你想到的实现方式实际上可能与库中的实现非常接近。基本上我们所做的就是计算其中有多少个元音。
- en: That's a good way of determining how many syllables there are in an English
    word。 So the function for that in pronouncing is syllable count。 And you pass
    in a string of "phones。"。 So if I just pass in "phones" there， it tells us there
    are three words in that word。 If we wanted to count how many syllables there are
    in an entire text， here we have our， text again。
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这是确定一个英文单词有多少个音节的好方法。所以在发音中，计算音节数的函数就是`syllable count`。你传入一个字符串“phones”。所以如果我传入“phones”，它会告诉我们这个单词有三个音节。如果我们想计算整段文本中的音节数，这里又有我们的文本。
- en: And then I'm going to do "phones equals pronouncing "phones forward" for "w"
    in text。splice。 And again， I'm just going to grab the first pronunciation。 And
    then to get this tells us this gives us a list of all of the pronunciations for
    every。 word in this text， a list of strings。 And then we could do just sum them
    up。 So "pr。
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我要做的是“phones 等于 pronouncing 'phones forward' for 'w' in text。splice”。再次，我只是要获取第一个发音。然后得到的这个告诉我们，给我们提供了文本中每个单词的所有发音的列表，一个字符串列表。然后我们可以将它们相加。所以
    "pr。
- en: syllable count item for item in "phones。"， Just using list comprehension to
    make it a little bit more compact。 So summing here the syllable count for that
    particular item for all of the items in this。 list of "phones" for each one of
    these words。 This tells us there are 15。 We can try to count them ourselves。 "April"
    is the "crew list month" "breeding" "lie" "lax" out of that。
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 针对 "phones" 中的每个项目进行音节计数，使用列表推导使其更紧凑。因此这里计算特定项的音节计数，涉及到这个 "phones" 列表中的所有项。这告诉我们有15个音节。我们可以尝试自己数一下。"April"
    是 "船员名单月"、"繁殖"、"懒" 从中得出。
- en: That seems like 15 syllables to me。 Different pronunciations might have a different
    syllable count。 so we don't actually know for， sure if that's the case， but it's
    a good starting point。 So syllable counting is the first thing that you need to
    be able to do to simulate poetic， meter。 And the other thing that you need to
    be able to do is know about word stresses， where the。
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在我看来，这似乎是15个音节。不同的发音可能会有不同的音节计数，所以我们并不确切知道是否如此，但这也是一个很好的起点。因此，音节计数是你需要能够做的第一件事，以模拟诗的韵律。而你需要了解的另一件事是单词重音的位置。
- en: stress falls in the word。 And English again is sort of unusual among the world's
    languages in that it has lexical。 stress。 You have to memorize the stress， where
    the stress falls in each word。 In other languages the stress is dictated by the
    language itself。 Like the stress always falls in a particular syllable of the
    word， but in English you have。
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 重音落在单词中。英语在世界语言中算是有些不同，因为它有词汇重音。你必须记住重音，每个单词中重音的位置。在其他语言中，重音由语言本身决定。比如重音总是落在单词的特定音节上，但在英语中，你必须记住。
- en: to memorize it。 So the stress is function， pr。stresses。 It takes in a list of
    phones that you get from say the phone's word for word function。 I'm just going
    to cut and paste this again。 So this is the pronunciation of programming。 If you
    do pr。stresses and then pass in that string， it returns what I call a stress path，
    pattern。
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 所以重音是函数 `pr。stresses`。它接受一个来自例如 `phone's word for word` 函数的音素列表。我将再次剪切并粘贴。这是“编程”的发音。如果你使用
    `pr。stresses` 然后传入那个字符串，它返回我称之为重音路径模式。
- en: which is it tells you where the stress falls in the word。 This is just all of
    the numbers for each one of those stresses in one string。 So programming from
    this we can tell is a three syllable word with the stress on the first。 syllable，
    secondary stress on the second syllable， and no stress on the third syllable programming。
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉你单词中重音的位置。这就是所有重音的数字汇总在一个字符串中。所以从这里编程，我们可以看出这是一个重音落在第一个音节的三音节单词，第二个音节有次重音，第三个音节没有重音的编程。
- en: We could do this with any text。 So for example we could do something similar
    to what we did up here if we wanted to get。 the stress pattern for that entire
    line of poetry。 We could get the phones for that and then do 。or empty string。join
    pr。stresses item for， item in phones。 And this shows you the stress pattern of
    that entire line of poetry。
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用任何文本进行这个分析。例如，如果我们想获取那整行诗的重音模式，我们可以为此获取音素，然后进行或空字符串。将 `pr。stresses` 项目与
    `phones` 中的每个项目连接。这显示了那整行诗的重音模式。
- en: And actually you can see that it follows a fairly predictable stress pattern。
    April is the crew list month reading livex out of the dead。 This isn't like the
    same thing as doing scansion on a text。 If you have been in English class about
    poetry where you actually go through the work of figuring。
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，你可以看到它遵循一种相当可预测的重音模式。四月是“船员名单月”，读取“懒虫”出现在死去的声音中。这与对文本进行音步分析并不相同。如果你上过关于诗歌的英语课，你会真正去分析。
- en: out where the stresses fall。 Because for example we might。 in actual scansion
    we might not count of and the as being stressed。 syllables because they are sort
    of small words that get elided or distressed and usually。 interreading。 But it's
    a good first approximation。 So this can help us in a number of ways。
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 找出重音落在哪里。例如，我们在实际的扫描中，可能不会把“of”和“the”算作重音音节，因为它们是一些小词，通常会被省略或失去重音，并且通常在朗读时。虽然这只是一个很好的初步近似，但这在多个方面都能帮助我们。
- en: And later on in the workshop I'm going to show you some examples of using these
    stresses。 to do things like recombine text， search text， compose poems based on
    the stress pattern。 But for now we're just going to leave it here。 There's also
    a search stresses function。 The search stress function does is it lets you look
    for words that have particular stress。
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在研讨会的后面部分，我将向你展示一些使用这些重音的例子，做一些事情，比如重新组合文本，搜索文本，根据重音模式作诗。但现在我们就先停在这里。还有一个搜索重音的功能。搜索重音功能让你查找具有特定重音的单词。
- en: patterns inside of them。 So if I do 0101 this is going to look for all of the
    words that have an unstressable。 followed， by an unstressable， syllable， syllable，
    followed by a stressable。 And there are a bunch of those。 Here's all of the words
    that have that particular property。 I will say that the transcriptions in the
    scene you're pronouncing dictionary don't。
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 词内的模式。因此如果我输入0101，这将查找所有包含一个不可重音音节，后面接着一个不可重音音节，再后面是一个重音音节的词。有很多这样的词。这是所有具有该特性词的列表。我会说，在你发音词典的转录中并没有。
- en: really-- they aren't super consistent when it comes to stress。 It's actually
    a little bit weird that there are words that have two primary stresses in， them。
    You wouldn't think that that's the case。 But that's just the data that we're working
    with here。 If we wanted to find all of the words that begin and that only consist
    of this pattern， of stresses。
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，它们在重音方面并不是特别一致。实际上，有些词中有两个主重音，这一点有点奇怪。你可能不会认为情况是这样的。但这就是我们这里所处理的数据。如果我们想找到所有以这种重音模式开始且仅由此模式组成的词。
- en: again we can use the anchors just like we did for searching the phonemes before。
    And this shows us there's just one word that consists entirely of an unstressable，
    followed。 by an unstressable， followed by a stressable。 Another helpful-- or a
    thing that I should mention is that this is actually just doing。 a regular expression
    search behind the scenes。 So what you can do here is use regular expression syntax
    to expand your search。
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以像之前搜索音素一样使用锚点。这告诉我们只有一个词完全由一个不可重音的音节，后面接着一个不可重音的音节，再后面是一个重音音节组成。另一个有用的，或者说我应该提到的是，这实际上是在幕后执行常规表达式搜索。所以你可以在这里使用常规表达式语法来扩展你的搜索。
- en: So let's say that we just wanted all of the words where there is an unstressable
    followed。 by either a primary or a secondary stress syllable and two of those
    in a row。 So now it's picking unstressable followed by either primary or secondary
    stress followed。 by unstressable followed by either primary or secondary stress。
    This list is actually much。
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们只想要所有有一个不可重音音节后面跟着一个主重音或次重音音节，并且这两个音节连续出现的词。那么现在它就会选择不可重音的音节，后面跟着主重音或次重音，接着是不可重音的音节，再后面是主重音或次重音。这个列表实际上要大得多。
- en: much longer。 Once we increase that， once we open up new possibilities， there's
    more words that meet。 those criteria。 So we have words like cholesterol， which
    is exactly four syllables， unstressable。 by， stress， unstressable， by stress。
    Comedian， commiserate， companion way， and so forth。 And maybe we could use this
    to make a weird poem。 So we'll call this our corpus。
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 要长得多。一旦我们增加这个，一旦我们打开新的可能性，就会有更多满足这些标准的词。所以我们有像胆固醇这样的词，它恰好有四个音节，依次为不可重音，重音，不可重音，重音。喜剧演员，怜悯，共伴方式，等等。也许我们可以用这个来写一首奇怪的诗。所以我们将其称为我们的语料库。
- en: And then let's just do like four ion range。 14， we'll make a little weird sonnet
    print join together random dot sample and we'll。 sample。 In ion bic pentameter，
    there are five ions combined。 So we won't do ion bic pentameter here because we
    have two ions here。 Let's just do an ion bic hexameter maybe。 So sample three
    items from this corpus join them together。
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们就来做四个离子范围。14，我们将制作一个奇怪的小十四行诗打印，将随机点样本连接在一起。进行样本。在离子双五音步中，有五个离子组合。因此，我们在这里不做离子双五音步，因为我们这里有两个离子。我们来做一个离子双六音步吧。于是从这个语料库中抽取三个项目并将它们结合起来。
- en: Just print that out。 The vaud missile to mystify evaluates enumerates associate
    per sariot， america。 x-6-8， amalgamates， ejaculate， decaprio， confederate， cochio，
    parenthesis， reiterate， evaporate。 delineate， propagate。 So you can make like
    a weird poem that has like a particular stress pattern that goes。 along with it，
    which I think is pretty neat。 Another quick example。
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 只需打印出来。模糊导弹使人困惑，评估、枚举、关联每个*sariot*，*美国*。x-6-8，结合，喷出，*迪卡普里奥*，*联盟*，*科基奥*，括号，重申，蒸发。描述，传播。所以你可以做出像一个奇怪的诗，具有特定的重音模式，这与它相辅相成，我觉得这很有趣。再来一个快速示例。
- en: we can find all the words that have two an pests。 So I'm bringing up terms from
    metrical feet here。 Like if that's a way of breaking up a line of poetry。 One
    that I just talked about is an IAM。 which is an unstressed syllable followed by
    either， a stressed or followed by a stressed syllable。 whether it's primary or
    secondary stress。 Another one is an anapest。
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以找到所有具有两个抑扬格的单词。所以我这里引入了*韵脚*的术语。如果这是分解一行诗的方式之一。我刚刚谈到的是*IAM*，这是一个无重音音节后接一个重音或重音音节，无论是主要重音还是次要重音。另一个是一个抑扬格。
- en: which is two unstressed syllables followed by an a stressed or an unstressed。
    Oops。 I wanted to make that mark to unsolved。 If I wanted to find all of the words
    that consist of two anapests。 what I would do is pr。search， stresses。 Begin with
    0， 0， 1， 2， 0， 0， 1， 2， close it out。 And then we see that there are only three
    such words。 Neopositivist， neopositivist。
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这是两个无重音音节后跟一个重音或一个无重音。哎呀。我想把那个标记为未解决。如果我想找到所有由两个抑扬格组成的单词，我会做的是pr。搜索，重音。以0，0，1，2，0，0，1，2开始，然后关闭它。然后我们看到只有三个这样的单词。*新实证主义者*，*新实证主义者*。
- en: That seems like a weird scandron of that word， but okay。 Under capitalized and
    under capitalized。 So under capitalized neopositivist is two or four anapests
    in a row。 So let's do another example with this。 We'll say rewriting by stress。
    And what we're going to do in this example is rewrite our text again。 Here again。
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 这听起来像是那个词的一个奇怪的扫描，但没关系。低重音和低重音。所以低重音的*新实证主义者*是两个或四个连续的抑扬格。我们再做一个例子。我们将说通过重音进行重写。在这个例子中，我们将再次重写我们的文本。这里再次。
- en: as far as we'll snip it of the wasteland。 I'm going to rewrite this so that
    replacing each word with another word that has the same。 stress pattern。 So I'm
    going to say forward in text。split。 Scroll this up a little bit。 Pronunciation。
    Well， we'll just call this phones。 PR。phones。forward。 looking up that word and
    getting the zeroth item from that list。
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 至于我们将从荒原中裁剪掉它。我将重写这个，将每个单词替换为另一个具有相同重音模式的单词。所以我将说*forward*在text。分割。把这个向上滚动一点。发音。好吧，我们只叫它*phones*。PR。*phones*。向前。查找那个单词并从列表中获取第零个项目。
- en: The pattern that we're going to look for is pronouncing stresses， getting the
    stress。 pattern for that word。 And then the replacements， our candidate replacements。
    are going to be search stresses。 All of the words for their stress pattern based
    on that pattern that we just found。 And I want to anchor that to the beginning
    and the ending of the string。
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要寻找的模式是发音重音，获取那个单词的重音模式。然后替换，我们的候选替换，将是搜索重音。所有单词的重音模式基于我们刚找到的模式。我想将其锚定在字符串的开始和结束。
- en: So we're finding words that only have that consist entirely of that pattern。
    And then here we will do the replacement is random。choice candidates。 And then
    I'm just going to make a list up here for our recomposed poem， out。appentent。replacement。
    I'm just to help you understand this。 I'm going to do a little debug statement
    here where I print the word。
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们在寻找完全由这种模式组成的单词。然后在这里我们将做随机替换。候选项。然后我只是想在这里为我们的重组成诗创建一个列表，*out.appentent*。替换。为了帮助你理解这个，我将做一个小调试语句，在这里打印出这个单词。
- en: the stress pattern， that we're looking for， and just like the first five candidates
    that found the words。 that match that stress。 But I am down here just going to
    print out that replacement joining together list。 Search stress dysfunction is
    a bit slower because it has to check every single word。 So April。 stressed followed
    by unstressed is stressed。 The is unstressed crew list， one zero， month one。
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们所寻找的重音模式，以及找到的前五个符合该重音的候选词。但我在这里只想打印出那个替换连接的列表。搜索重音功能有点慢，因为它必须检查每一个单词。所以四月。重音后接无重音是重音。这个是无重音的队列，零，一，月份一。
- en: reading and so forth。 And you can see that with a lot of these you can tell
    there are lots of words that have。 that particular stress pattern。 If we're seeing
    multiple words that all begin with two A's then probably there's a lot of。 words
    that meet that。 Anyway， here's the output。 April is the coolest month。 Reading
    lilacs out of the dead becomes tople grigs。
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读等等。你可以看到，很多单词都有那种特定的重音模式。如果我们看到多个单词都以两个 A 开头，那么可能有很多满足这个条件的单词。无论如何，这是输出。四月是最酷的月份。从死去的紫丁香中阅读变成了顶级的小虫。
- en: It's around some most gain or Siegfried trick truths just seems。 So same stress
    pattern。 Replacing it with different words。 Trying to think if there's anything
    we want to do there。 Let's just leave it up。 An exercise that you might do is
    now find instead of just replacing instead of just replacing。 it with the stress。
    Find words that also begin with the same initial phonium before picking them。
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 这围绕着一些最常见的真理，似乎是西格弗里德的把戏。所以相同的重音模式。用不同的单词替换它。试着想想我们是否想在这里做什么。我们就这样留下它。你可以做的一个练习是，现在找出不仅仅是替换，而是用重音找到那些同样以相同的首音节开头的单词。
- en: The last thing that I want to cover in pronouncing library is rhymes。 Let's
    bring that up。 One of the main things that poets want to be able to do with the
    scene we're pronouncing。 dictionary is find words that rhyme with a particular
    word。 Rhyme of course is one of the main ways that poems maintain cohesion。
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我在发音库中想要覆盖的最后一件事是押韵。让我们提出这个。诗人想要做的主要事情之一是找到与特定单词押韵的单词。押韵当然是诗歌保持连贯性的主要方式之一。
- en: Lots of forms of poetry have rhyme patterns that I have to correspond to。 So
    one of the tasks that we need to be able to do if we want to do computer generated。
    poetry or even computer like poetry analysis is figure out where those rhymes
    are。 Because it's so common there's a super easy way of doing it with pronouncing
    which is just。
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 许多形式的诗歌都有我必须对应的押韵模式。所以，如果我们想进行计算机生成的诗歌，甚至是计算机风格的诗歌分析，我们需要能够找出那些押韵的位置。因为这非常常见，使用发音库有一个超级简单的方法。
- en: the rhymes method。 So if you pass in a word like failings it's going to return
    all of the words that rhyme。 with failings。 The way that it does that is using
    something called the rhyming part。 The way that you know two words rhyme there
    are different ways of figuring this out。 I think that the naive way of thinking
    of it is like well do they have the same last sound。
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 押韵方法。因此，如果你传入一个单词，比如 failings，它会返回所有与 failings 押韵的单词。它这样做的方式是使用所谓的押韵部分。你知道两个单词押韵有不同的方法来弄清楚。我认为幼稚的想法是，看看它们是否有相同的结尾音。
- en: than they rhyme。 But it's actually not that simple。 Lots of words have the same
    last sound but don't rhyme。 Instead what you need to do is or at least as far
    as I can tell you need to do is look。 back from the end of the string。 So again
    I'm going to do phones equals pr dot phones forward programming。
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 比如它们押韵。但其实并没有那么简单。很多单词有相同的结尾音，但并不押韵。相反，你需要做的是，或者至少就我所知道的，你需要从字符串的末尾回溯。所以我将执行
    phones 等于 pr 点 phones 前进编程。
- en: This might not work。 We'll see if it works。 It's the word programming。 You need
    to go back from the end of the word until you find the stressed syllable。 Everything
    from that stressed syllable to the end is the part that needs to match in some。
    other word at the end of the word for those two words to rhyme。
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能不起作用。我们看看是否有效。这是单词编程。你需要从单词的末尾回溯，直到找到重音音节。从那个重音音节到末尾的部分需要在某些其他单词中匹配，才能让这两个单词押韵。
- en: There's a function in pronouncing to figure that out which is the rhyming part。
    If you pass in a string of phonemes， I'm going to just grab the first element
    from that。 It's actually looking for anything whether it's stressed or unstressed
    or whether it's。 primary stress or secondary stress。 This is saying that in order
    for programming to rhyme with another word that other word has。
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在发音中有一个函数可以弄清楚这个，即押韵部分。如果你传入一个音素字符串，我将只抓取第一个元素。它实际上在寻找任何东西，无论是重音还是非重音，或者是主要重音还是次要重音。这就是说，为了让编程和另一个单词押韵，那个单词必须有。
- en: to end in aiming。 Now if we do pr search and search for words that end in that
    rhyming part。 I'm going to， call this r part。 So if we search for words that end
    in that r part plus the end anchor。 we have these words， that it thinks rhymes
    with programming， diagramming。 programming and reprogramming。 The rhymes function
    basically just bundles up that whole bit of text into one function。
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 以“aiming”结尾。现在如果我们进行PR搜索，搜索以那个韵脚部分结尾的词。我将把这称为r部分。所以如果我们搜索以r部分加上结束锚点结尾的词。我们有这些词，它认为与编程、图解、编程和重新编程押韵。韵脚函数基本上将整个文本部分打包成一个函数。
- en: call for you。 And it also excludes the word that you pass。 So it doesn't tell
    you the programming rhymes with programming which is fairly obvious。 Another way
    to do this is if you just want to check if two words rhyme， so like does。 we's
    rhyme with geese， who would say we's pronouncing or not pronouncing pr。 rhymes。
    Geese。
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 为你调用。它还排除了你传入的词。所以它不会告诉你编程和编程的韵脚，这很显然。另一种方法是如果你只想检查两个词是否押韵，比如说“我们”的韵脚是否与“鹅”押韵，谁会说“我们”是否在发音或不发音的韵脚。鹅。
- en: This tells you that we's does not rhyme with geese。 But if we did cheese in
    pr。 rhymes geese。 that also doesn't rhyme。 What does rhyme with geese？ Okay， a
    whole bunch there。 Just crease rhyme with geese。 Yes， it does。 So one final example
    with pronouncing librar。 I will to rewriting with rhymes。 So again， we're going
    to start with our text。
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉你“我们”并不与“鹅”押韵。但如果我们用“奶酪”来进行发音，鹅那也不押韵。与“鹅”押韵的是什么？好的，有很多。只要“褶皱”与“鹅”押韵。是的，它是的。所以最后一个例子是使用发音库。我将用韵脚重写。所以我们再次从我们的文本开始。
- en: And then what I'm going to do is I'm going to rewrite this text， replacing every
    word。 with another word that rhymes with this text。 So I'm going to do out is
    an empty list for word in text。split。 Get all of the rhymes。 Well， let's just
    do it。 We'll do it in one。 And we'll do it to establish pronouncing rhymes for
    that word。
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我要做的是重写这段文本，用与这段文本押韵的另一个词替换每个词。所以我将把输出做成一个空列表，针对文本。分割。获取所有韵脚。好吧，让我们试试。我们将一次性完成它。并为那个词建立发音韵脚。
- en: Our picked word is going to be random。choice from those rhymes， picking one
    of those， and。 then do out。append。picked word and then print， joining together
    that out。 Oops。 Go to the string。 Oh no。 Okay， so here we have an error。 And this
    error is going to come up a bunch of times when you're working with this library。
    It says， "Can't choose from an empty sequence。"， So let's try to figure out what's
    happening there。
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择的词将是随机的。选择那些韵脚中的一个，然后输出。附加。选择的词，然后打印，连接在一起。哎呀。去字符串。哦，不。好的，我们这里有一个错误。这个错误在你使用这个库时会出现很多次。它说：“无法从空序列中选择。”所以让我们尝试弄清楚发生了什么。
- en: If I do， I'm just going to print the word along with its rhymes for each word。
    What you're going to see is that there are no words that rhyme with April。 Like
    this is an empty list。 When I asked for the number of rhymes， it returns an empty
    list。 And we can't choose random item from an empty list。 That's why it's saying。
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我做，我只是将每个词及其韵脚一起打印。你会看到没有与“April”押韵的词。就像这是一个空列表。当我询问韵脚的数量时，它返回一个空列表。我们无法从空列表中选择随机项。这就是它所说的原因。
- en: '"Can''t choose from an empty sequence。"， This will also come up if you do PR。pronouncing
    or sorry PR。phones for word and you pass in， some word that is not in the scene
    you''re pronouncing dictionary。 It gives you back an empty list。 And then if you
    try to get the zero-th item from that list。 you''re going to get a list， index
    out of range error。'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: “无法从空序列中选择。”如果你执行PR。发音，或者对词执行PR。电话，而你传入一个不在你发音字典中的词，它也会出现这个问题。它会给你一个空列表。然后如果你尝试从那个列表中获取第零项，你会得到一个列表索引超出范围的错误。
- en: I skipped over this detail and the examples up here， just because it's a bummer。
    You have to rewrite this error-checking code over and over again。 But the way
    that you get around this， you just need to figure out， "Well， what are you。 going
    to do in the case where you don't have the word that corresponds to the thing
    that， you want？
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我跳过了这个细节以及上面的示例，只是因为这让人沮丧。你必须一遍又一遍地重写这个错误检查代码。但是解决这个问题的方法是，你只需要弄清楚：“好吧，当你没有与想要的内容对应的词时，你将怎么做？”
- en: '"， In this case， what I''m going to do is I''m going to say if there is at
    least one rhyme。 then print out a rhyming word。 Otherwise I''m just going to append
    the original word and then print this out。 I should have just printed out in our
    debug statement just like the first five， so it。 doesn''t take up too much space。
    So here we go。 "April is the coolest month reading lilacs out of the dead。'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: “在这种情况下，我要做的是，如果至少有一个押韵，就打印出一个押韵的词。否则，我就将原始单词附加上去，然后打印出来。我应该在调试语句中打印出前五个，这样不会占用太多空间。我们开始吧。”四月是最酷的月份，读着死去的紫丁香。
- en: If we rewrite it by rhyme， we have April was the coolest month eating borax
    readout lay。 bob the shed。"， Which again I think is a pretty neat output。 I'm
    just showing you the use of that rhyme function to grab words from the CMU， pronouncing。
    dictionary that rhyme。 All right。 So now we know how to use the pronouncing library。
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们通过押韵重新写，我们得到“四月是最酷的月份，吃着硼砂读出来。bob的棚子。”我认为这是一种相当不错的输出。我只是展示如何使用这个押韵功能，从CMU发音词典中获取押韵的词。好的，所以现在我们知道如何使用发音库。
- en: I think that's helpful even though we're， you know， you may not want to use
    it for other。 projects or whatever。 I think it's helpful to know the basics of
    how you might work with phonetic information。 about words and it's helpful to
    have like， you know， if you're ever using the CMU pronouncing。 dictionary there's
    just like certain code that you're going to end up writing over and。
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为这很有帮助，尽管我们可能不想把它用于其他项目。我认为了解如何处理单词的语音信息的基础知识是有帮助的，而且如果你使用CMU发音词典，肯定会有一些代码你最终会写出来。
- en: over and over again and the pronouncing library has a way to kind of get around
    that。 But there's a pretty serious shortcoming to the CMU pronouncing dictionary
    which is。 that it only knows about the words that are in the dictionary。 And there's
    so many words and so many contacts that aren't in that dictionary and as we saw。
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 一遍又一遍，发音库有办法绕过这个问题。但是，CMU发音词典有一个相当严重的缺点，那就是它只知道词典中的单词。而且有很多单词和上下文不在这个词典中，正如我们所看到的。
- en: in the opening presentation sometimes the things that we want to work with aren't
    words。 that could be in a dictionary at all。 They're nonsense words or words from
    sound poetry。 Like we want to be able to work with both spelling and sound， the
    phonetics of words。 as like malleable entities that we can manipulate。
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在开场演示中，有时我们想处理的东西根本不是可以在字典中的单词。它们是无意义的词或来自声音诗的词。我们希望能够同时处理拼写和声音，将单词的语音视为可以操作的可塑实体。
- en: To do that I need Pinsulate which is a machine learning model that translates
    from spelling。 to sound and from sound to spelling。 And I'm just going to give
    you a tour of how that library works。 Once I'm done showing you the basic overview
    of the functionality I'm going to show you。 a couple of examples of how to do
    corpus driven poetic composition using a combination of。
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我需要Pinsulate，这是一个将拼写转化为声音、将声音转化为拼写的机器学习模型。我将给你展示这个库是如何工作的。一旦我展示了功能的基本概述，我会给你展示几个使用语料驱动的诗歌创作的示例。
- en: these two libraries pronouncing in Pinsulate。 So I started a new notebook here
    and I'm just going to call this Pinsulate stuff。 To use Pinsulate you need to
    import it and again this should be already installed if。 you follow the installation
    instructions from earlier。 It's a little bit tricky to install。 If you've worked
    with machine learning in the past then you know that all of the libraries。
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个库是发音库和Pinsulate。因此，我在这里开始一个新的笔记本，叫做Pinsulate的东西。要使用Pinsulate，你需要导入它，按照之前的安装说明，这应该已经安装好了。安装有点棘手。如果你以前使用过机器学习，你就知道所有的库。
- en: for doing machine learning are like this weird house of cards where things like
    are deprecated。 six months after they're released and the versions of X that work
    with versions of Y。 are like this very tiny Venn diagram and Pinsulate is no different。
    It comes with a pre-trained model with a curious model and it comes with a pre-trained
    model。
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 进行机器学习就像是一座奇怪的纸牌屋，很多东西在发布六个月后就被弃用，版本X与版本Y的兼容性就像一个非常小的维恩图，Pinsulate也不例外。它带有一个预训练的模型和一个奇特的模型。
- en: that will do all the stuff that you want it to do。 So keeping the versions that
    are in that requirements file at the versions that they're。 specified is actually
    important to make sure that it works。 If you do spot a bug with some other version
    that you happen to be using or if there's。
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 这将完成你想要它做的所有事情。因此，确保将要求文件中的版本保持在指定的版本上实际上很重要。如果你发现你正在使用的其他版本存在错误，或者有。
- en: a version that you need to use the library with that isn't currently supported
    then let。 me know open up a pull request or a bug report an issue on the GitHub
    repository and I'll。 try to address it。 So to use Pinsulate first you need to
    import it。 So from the Pinsulate library we're going to import capital P Pinsulate
    which is the class。
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要使用不受支持的库版本，请告诉我，在 GitHub 仓库中提出拉取请求或错误报告，我会尽量解决它。因此，要使用 Pinsulate，首先需要导入它。所以我们将从
    Pinsulate 库中导入大写 P 的 Pinsulate，这就是类。
- en: that implements the model and then I'm going to instantiate that class。 So if
    I do Pinsulate like that this gives us a variable， an object pin that has all
    of。 the methods that we're going to use for working with words。 So the simplest
    thing that you can do with Pinsulate is the sound out function。
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 这实现了模型，然后我要实例化那个类。所以如果我像这样使用 Pinsulate，它会给我们一个变量，一个对象 pin，具有我们将要用于处理单词的所有方法。使用
    Pinsulate 最简单的事情就是声音函数。
- en: So if I do pin dot sound out and then pass it a string like say Allison then
    it returns。 the phones in the word Allison and this comes from the machine learning
    model。 The model is trained on the C&U pronouncing dictionary。 It takes words
    as input and returns phonetic features as output。
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我做 pin.dot.sound out，然后传入一个字符串，比如说 Allison，它就返回单词 Allison 中的音素，这来自机器学习模型。该模型是基于
    C&U 发音字典训练的。它将单词作为输入，并返回音韵特征作为输出。
- en: The sound out function turns those phonetic features into the corresponding
    phonemes that。 are closest to the features that are that are predicted。 So we
    get our pivot phones out from this pronunciation。 This works even for things that
    could not possibly be in the not possibly but things。
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 声音函数将这些音韵特征转换为与预测特征最接近的相应音素。因此，我们从这个发音中得到了我们的支点音素。这甚至适用于那些不可能在的事物。
- en: that don't happen to be in the C&U pronouncing dictionary。 So this gives we
    put in Pikachu which as I've shown is not in the C&U pronouncing dictionary。 It
    returns this pronunciation。 This is like a little bit weird。 It's pikachu with
    this stress on the second syllable instead of on the first syllable so。
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 这些单词恰好不在 C&U 发音字典中。所以我们输入 Pikachu，而我已经展示过它不在 C&U 发音字典中。它返回这个发音。这有点奇怪。它是 pikachu，重音在第二个音节而不是第一个音节上。
- en: you might expect but you know that's good enough。 If I do sound out the word
    MIMSI from Jabber Walkie which is also not in the C&U pronouncing。 dictionary
    we get MIMSI。 That's actually how it's pronounced like it's actually doing MIMSI
    instead of MIMSI。
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会期待，但这已经足够了。如果我从 Jabber Walkie 中读出 MIMSI 这个词，而它也不在 C&U 发音字典中，我们得到的是 MIMSI。实际上就是这样发音，它确实是
    MIMSI，而不是 MIMSI。
- en: But again close enough close enough for our purposes and there isn't really
    you know there。 isn't enough information in the C&U pronouncing dictionary to
    get us 100% accuracy on this， task。 So with made up words it's always going to
    be a little bit skiwampus but it's good enough。 for our purposes generally。 The
    opposite of the sound out is pin。
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 但再次强调，对于我们的目的来说，已经足够接近，而在 C&U 发音字典中没有足够的信息来让我们在这个任务上达到 100% 的准确率。所以对于虚构的单词，总会有一点偏差，但通常来说，已经足够好了。声音函数的反向是
    pin。
- en: spell and with spell what you do is you give it a， list of phonemes。 So I'm
    going to say M-I-I-M-S-E like that and it returns a string that is spelled from。
    that word so we get MIMSI back from that。 This has a little bit of randomness
    in it so we get back we can potentially get back。 different spellings。 We can
    play around with this a little bit if I put a Z in there instead of an S it actually。
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 拼写和拼写时，你给它一个音素列表。所以我会说 M-I-I-M-S-E，然后它返回一个拼写出的字符串。因此，我们从中得到了 MIMSI。这里面有一点随机性，所以我们可能会得到不同的拼写。如果我把
    Z 放在那里而不是 S，我们可以稍微玩一下这个。
- en: spells it the same way。 But importantly this works even for words that are you
    know again not in the C&U pronouncing。 dictionary like even words that I just
    make up on the spot on the spot on the spot on， the spot。 So I'm spelling out
    Blarf here which is a made up word I just made it up and it does。 a pretty good
    job of spelling it back。 This task of spelling based on the sounds is much much
    more difficult than the other way。
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 拼写方式是相同的。但重要的是，即使对于那些不在 C&U 发音词典中的单词，这也能奏效，甚至是我当场即兴创造的单词。所以我在这里拼写 Blarf，这是一个我刚刚编造的单词，它在拼写时表现得相当不错。根据声音拼写的任务比反向拼写要困难得多。
- en: around the model and it's trained only gets to about 80% accuracy on this even
    when I push。 all of the all of the things to maximum because it's actually a really
    difficult job to take。 arbitrary sounds and then spell them because there's so
    many different ways of plausibly。 spelling a given string of English words。 So
    it doesn't do like a 100% great job。
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型周围，它的准确率仅达到大约 80%，即使我将所有参数推到最大，因为将任意声音拼写出来实际上是一个非常困难的任务，因为拼写一个给定字符串的英语单词的方式有很多种可能性。所以它的表现并不是
    100% 出色。
- en: This is well no this is perfect that's how you would spell Blarf right。 But
    there are other you know another potential fine way to spell the word Blarf would
    be。 like you know Bl you are pH right that could also be a good spelling of Blarf。
    Another plausible spelling of Mimsie might be like M-I-M-Z-E-E or something like
    that。
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 这实际上是完美的，这就是你拼写 Blarf 的方式。但还有其他的，你知道，拼写 Blarf 的另一种可能的正确方式是，像你知道的 Bl，你是 pH，对吧？这也可能是
    Blarf 的一个好拼写。Mimsie 的另一个可行拼写可能是 M-I-M-Z-E-E 或类似的东西。
- en: So that that that task of doing the phoneme to graphing conversion is much more
    involves。 a lot more guesswork。 So just remember that when you're working with
    that side of the model。 Everything to remember is that because it is trained on
    the senior pronouncing dictionary。 it only recognizes characters that are in the
    senior pronouncing dictionary。
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，进行音素到图形转换的任务涉及的内容更多，猜测成分也更多。所以请记住，当你在模型的这一侧工作时，重要的是要记住，由于它是基于高级发音词典训练的，因此它只识别那些在高级发音词典中的字符。
- en: So if I try to spell something like a T-E which is a French word meaning like
    a small。 What does a tween mean nobody knows what a tween is。 But it is it is
    a French word。 You'll notice that we get an error here it says key error E with
    an accent that means。 that that character is not inside of the vocabulary of the
    model。
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 所以如果我尝试拼写像 T-E 这样的东西，这是一种法语单词，意思是小。tween 是什么意思，没人知道。但这是一个法语单词。你会注意到我们在这里遇到一个错误，提示键错误
    E 带有重音，这意味着该字符不在模型的词汇中。
- en: So just also remember that that it only deals with words that have lower case
    A through， Z periods。 hyphens and apostrophes are also potential parts of words。
    So with that in mind let's do some phoneme frequency analysis。 And we did this
    before with just a small snippet of the Wasteland by TS Eliot。
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 所以请记住，这仅处理小写字母 A 到 Z，句号，连字符和撇号也是单词的潜在组成部分。考虑到这一点，让我们进行一些音素频率分析。我们之前已经用 T.S.
    艾略特的《荒原》中的小片段做过这个。
- en: And I sort of like doctored that snippet so it only had words that whose spellings
    or。 whose particular spellings were in the senior pronouncing dictionary。 But
    using pencil it we can actually do this on arbitrary English text。 You don't have
    to like massage it first to make sure that all of the words are already。
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 我对那个片段进行了一些处理，所以它只包含那些拼写在高级发音词典中的单词。但使用 Pencil，它实际上可以在任意的英语文本上做到这一点。你不必先对其进行处理，以确保所有单词都是有效的。
- en: in the senior pronouncing dictionary。 In this repository if you clone the repository
    there is a copy of Jabberwocky by C。S。 Lewis。 C。S。 Lewis that's not the person
    who wrote Jabberwocky。 It would be Lewis Carroll。 It would be nice to see the
    version of Jabberwocky written by C。S。 Lewis with all of its weird。 Christian
    iconography but no one is the actual extant version of this poem。
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在高级发音词典中。如果你克隆这个仓库，其中有 C.S. 路易斯的《杰伯沃基》的副本。C.S. 路易斯并不是写《杰伯沃基》的人，而是刘易斯·卡罗尔。看到
    C.S. 路易斯写的《杰伯沃基》版本，充满奇怪的基督教意象会很好，但没有人有这首诗的实际存在版本。
- en: So to load that in I'm going to and that's just included as Jabberwocky。txt。
    So to load that in I'm going to do text equals open Jabberwocky。txt。read。 And
    then here's that text of Jabberwocky。 So the task that I want to set before us
    just as like a quick learning exercise is let's。 find out what the most common
    phonemes are in this text。
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 为了加载这个文件，我会使用 Jabberwocky.txt。要加载它，我将做 `text = open("Jabberwocky.txt").read()`。然后这里是
    Jabberwocky 的文本。所以我想给我们设定的任务，作为一个快速学习练习，就是找出这个文本中最常见的音素。
- en: And again we did this with that small snippet of the wasteland but now we're
    going to do。 it with this poem。 That's a large proportion of this R words that
    are not in C。M。U。 pronouncing dictionary。 We have to guess what the pronunciation
    of these words is。 So I'm going to just add a really really quick way of doing
    this。
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前用《荒原》的小片段做过这个，但现在我们要用这首诗来做。这是一个很大比例的 R 词不在 C.M.U. 发音词典中。我们必须猜测这些单词的发音。所以我将添加一种非常快速的方法来做到这一点。
- en: I'm going to get a list of words from the text like this。 So using regular expressions
    I'm going to convert to lowercase。 Finding all of the word boundaries followed
    by the word characters followed by word boundary。 in the text。 This isn't perfect
    because you're skipping over words that have like apostrophes。
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我将从文本中获取一个单词列表。使用正则表达式，我将转换为小写。查找所有单词边界，后跟单词字符，再后跟单词边界。在文本中。这并不完美，因为你会跳过带有撇号的单词。
- en: And then if there are any in this text， I don't know。 It's not like a perfect
    way of tokenizing a text but it's good enough for what we're going， to do。 One
    thing that I like to do when I'm working with text is just do random。choice or
    random。sample。 just as a way of checking my work and then just grab ten words
    and random。
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，如果文本中有任何音素，我不知道。这不是一种完美的文本分词方式，但对我们要做的事情来说已经足够好。我喜欢在处理文本时做随机选择或随机抽样，只是检查我的工作的方式，然后随机抓取十个单词。
- en: And this kind of shows us for sure that we're working with the data that we
    actually wanted。 to work with。 So now we can。 For any one of these words I could
    do pin。sound out words。 let's say 32。 That's to be the。 Clouse。 What is words？
    33。 Oh， claws。 Yeah， that's the word claws。 For any one of these words I can just
    pass in the text of the word and get back the phonemes。
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 这确实向我们展示了我们正在处理的数据正是我们想要的。因此，现在我们可以。对于这些单词中的任何一个，我可以做“pin”来发出单词声音，比如说 32。这是“Clouse”。这个词是什么？33。哦，“claws”。对，这就是“claws”这个词。对于这些单词中的任何一个，我只需传入单词的文本，就能得到音素。
- en: The phonemes come back in a list。 This is unlike the pronouncing dictionary
    that returns them as a space delimited string with。 pencil at we give them back
    as a list。 So doing the phonemes is super super easy。 I'm going to do from collections
    import counter。 Phonemes is a new counter。 And then that's actually just going
    to be forward and words phonemes。update sounding out。
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 音素以列表的形式返回。这与发音词典返回的以空格分隔的字符串不同。我们将其作为列表返回。因此，处理音素非常简单。我将从 collections 导入 counter。音素是一个新的计数器。然后这实际上将是
    forward 和 words phonemes。update sounding out。
- en: the word using pencil。 And out， not sound。 Takes a little bit because it's a
    neural network。 And the next notebook we're going to work with the cache so that
    we don't have to wait。 once the word has been looked up。 And now we can print
    out those phonemes counts。 Let's get the most common 12 of those phonemes counts。
    So this is interesting。
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 使用“pencil”这个词。而且不是音。因为这是一个神经网络，所以需要一点时间。我们接下来的笔记本将使用缓存，这样就不用再等待。一旦单词被查找，我们就可以打印出这些音素的计数。让我们获取这
    12 个音素计数中最常见的几个。这很有趣。
- en: I think this is unusual to have the most common sound。 And I don't even know
    if you would get that impression looking at the text。 It doesn't seem like there
    are that many does in there but there are。 It's the most common phonem。 There
    are four more of them and the second one is common phonem。
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为有最常见的声音是不同寻常的。我甚至不知道你在看文本时是否会有这样的印象。看起来并没有那么多“does”在里面，但实际上有。这是最常见的音素。还有四个，第二个是常见音素。
- en: And that is actually like a sound that does seem like maybe it occurs a bit
    more frequently。 in this text。 Maybe just because it's in jabber walk that happens
    all over the place。 Jabber walk。 Band or snatch。 Yeah， I don't know。 Maybe that's
    unusual。 I don't know。 If we wanted to know if it was unusual then what we could
    do is we could compare it to， a base text。
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 这实际上听起来像是可能在这个文本中出现得更频繁的声音。也许只是因为它在**Jabber walk**中到处发生。**Jabber walk**。带或抢。是的，我不知道。也许这很不寻常。我不知道。如果我们想知道这是否不寻常，那么我们可以将其与基文本进行比较。
- en: So we actually have a base text available to us that would be great for doing
    this comparison。 if we again import pronunciations as PR or not pronunciations。
    So pronouncing。 And then if we do PR。init CMU here then PR will have this big
    list called pronunciations。 Let's grab the first hundreds of those。 It is actually
    a list that has the word as the first item in a tuple and then the pronunciation。
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们实际上有一个可用的基文本，非常适合进行这种比较。如果我们再次导入发音作为PR或非发音。所以发音。如果我们在这里执行PR.init CMU，那么PR将拥有这个称为发音的大列表。让我们抓取前几百个。这实际上是一个元组中第一个项目是单词，第二个项目是发音的列表。
- en: of the second item in the tuple。 We can use this as a baseline purpose to see
    like， well。 are these sounds actually unusual？ Is Jabber walk actually unusual
    in its sonic composition？
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 元组中的第二项。我们可以将其用作基线目的，以查看这些声音是否实际上不寻常？**Jabber walk**在其声音组成中是否实际上不寻常？
- en: The way we'll do that is just to make account of all of the words in the CMU
    and pronouncing。 dictionary。 So we'll do CMU。 Count is another counter。 And I'm
    for wordphones in PR。pronunciations。 CMU count dot update。 We actually have to
    split this because these are strings of phones and we want to count。 individual
    phonemes。 And then we'll do CMU count the most common 12。 So this shows us that
    actually。
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的方法就是对CMU发音词典中的所有单词进行统计。因此我们将进行CMU计数作为另一个计数器。然后我在PR的发音中进行wordphones的计数。CMU
    count点更新。我们实际上必须拆分这个，因为这些是音素字符串，我们想要计数单独的音素。然后我们会做CMU count中最常见的12个。这实际上向我们展示了。
- en: yeah， it is unusual because if you take the entire CMU。 pronouncing dictionary
    and count them as common phonemes is by far the most， well not， by far。 It's at
    the top of the list of the most common phonemes。 There are 63，000 of them followed
    by mmm。 old， irk。 So just like common consonant sounds。 And stressed I is the
    second most common vowel and er is the third most common vowel。
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，它不寻常，因为如果你取整个CMU发音词典并将其作为常见音素来计算，确实是最常见的，不是说最常见。它在最常见音素的列表顶部。它们有63,000个，后面是mmm、old、irk。所以就像常见的辅音音。重音的I是第二常见的元音，er是第三常见的元音。
- en: So actually like Jabber walk is unusual because it is mostly like dat， like
    dat， and I and。 I and sounds like that are much more common than they would be
    in this bass line corpus。 Which I think is actually super interesting。 It helps
    you understand like what is Jabber walk actually doing？
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 所以其实像**Jabber walk**是异常的，因为它大多是这样的，像这样的，而我和。我和听起来像那样的在这个基线语料库中要比它们更常见。我认为这实际上是超级有趣的。它帮助你理解**Jabber
    walk**实际上在做什么？
- en: Like how is the poem？ How does the poem make us feel the way that we feel when
    we read it？
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 这首诗是什么样的？当我们阅读它时，诗歌是如何让我们感受到我们所感受到的？
- en: And that's partially because it sounds unusual。 It doesn't sound like a regular
    English text。 Another thing that we can do with the CMU pronouncing dictionary
    now that we have inside。 of here is maybe spell words from random phonemes。 So
    this is like a more elaborate example but let's see how it goes spell。
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 这部分是因为它听起来不寻常。它听起来不像普通的英语文本。我们现在可以利用CMU发音词典，也许可以从随机音素拼写单词。这是一个更复杂的例子，但我们来看看它是如何拼写的。
- en: What I'm going to do here is we actually just created a big， with this counter
    we created。 a big list of all of the phonemes that are present in any CMU pronouncing
    dictionary word。 So I'm going to get all of the phonemes by converting the CMU
    count keys into a list。 Like that。 And now here are all of the possible phonemes。
    If I wanted to get all of the frequencies or like if I wanted to get an idea of
    how common。
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 我在这里要做的是，我们实际上刚刚创建了一个大的，通过这个计数器，我们创建了一个大列表，包含CMU发音词典中任何单词中存在的所有音素。所以我将通过将CMU
    count的键转换为列表来获取所有的音素。就这样。现在这里是所有可能的音素。如果我想获取所有的频率，或者如果我想了解它们的常见程度。
- en: are each one of these phonemes。 The thing that I might want to do is I'm going
    to get phonem frequencies just as a big list。 of those CMU count values。 Now I
    have a big list that has the same indexes as the all phonemes of the phonem frequencies。
    So there's like the first ten of those。 This tells us how many times each one
    of those occur all phonemes。 So these actually correspond。 The indices correspond。
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 每一个音素。这些音素中我可能想要做的事情是将音素频率作为CMU计数值的大列表。现在我有一个大列表，它与音素频率中的所有音素具有相同的索引。因此，这十个中的每一个。这告诉我们每一个音素出现的次数。所以这些实际上对应。索引对应。
- en: I'm going to convert that to a NumPy list or a NumPy array。 Phoneme frequencies
    equals。 well I need to import NumPy before I can use it。 Import NumPy as NP。 NumPy
    by the way is if you're not familiar with it is a Python library that has fast
    and。 sort of more convenient math routines for working with long arrays or multidimensional。
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 我要将其转换为NumPy列表或NumPy数组。音素频率等于。好吧，我需要在使用之前导入NumPy。导入NumPy作为NP。顺便提一下，NumPy如果你不熟悉的话，是一个Python库，它有快速且更方便的数学例程，用于处理长数组或多维数组。
- en: arrays of numbers。 And it gives us some interesting functionality that would
    be typical to you otherwise。 So I'm going to convert that to a NumPy array， the
    phoneme frequencies。 Make sure that we get it as a floating point array。 And then
    turn those frequencies into probabilities by dividing it by the sum of the list。
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 数字数组。它给我们一些有趣的功能，否则你可能不会得到。所以我要把音素频率转换为NumPy数组。确保我们得到的是浮点数组。然后通过将其除以列表的总和来将这些频率转换为概率。
- en: So now if we look at phoneme frequencies， the first ten， this is telling us
    what percentage。 of all sounds in the same unit pronouncing dictionary is comprised
    by the corresponding， phoneme。 So all phonemes。 If I look at the top ten， this
    is saying that B is a little more than 2% of all phonemes。 T is a little more
    than 5% of all phonemes and so forth。 So what we have here is actually a model。
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 所以现在如果我们看音素频率，前十个，这告诉我们在同一单位发音字典中，相关音素占所有声音的百分比。所以所有音素。如果我查看前十个，这表示B占所有音素的稍微超过2%。T占所有音素的稍微超过5%，等等。所以我们这里实际上有一个模型。
- en: a very simple statistical model of how English， words are formed phonetically。
    We know that certain sounds are rare and certain sounds are frequent。 So if you
    wanted to generate a new English word phonetically， one way of going about it。
    would be to pick a sequence of letters or a sequence of sounds based on how frequent
    those。
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 一个非常简单的统计模型，说明了英语单词是如何在语音上形成的。我们知道某些声音是稀有的，而某些声音是频繁的。因此，如果你想在语音上生成一个新的英语单词，一种方法就是根据这些音素的频率选择一个字母序列或声音序列。
- en: sounds are。 This is sort of like a unigram model， like a unigram Markov chain
    where we're not actually。 taking into account any of the previous state。 We're
    just picking them one by one。 To do that pick。 NumPy has this function called
    np。random。choice where you pass in the。 thing that you want to choose from， which
    in this case is all of the phonemes。
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 声音是。这有点像单元语法模型，就像一个单元马尔可夫链，我们实际上并没有考虑任何前一个状态。我们只是逐个选择。为了做到这一点，NumPy有一个叫做np.random.choice的函数，你传入你想选择的内容，在这种情况下是所有的音素。
- en: And then you have a parameter p which is the frequency or the weight that should
    be applied。 to each one of those items based on their index in the list。 So if
    you do this。 it's going to pick phonemes， but it will more frequently pick the
    ones that。 are common based on the thing based on values that were in this phoneme
    frequencies array。
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你有一个参数p，它是基于列表中每个项目的索引应该应用的频率或权重。因此，如果你这样做，它会选择音素，但更频繁地选择那些基于音素频率数组中值的常见音素。
- en: So if we chain those together， let's say np。random。choice for i in range 5。
    that's going to give me a 5 phoneme word whose phonemes are selected。 based on
    how frequent those underlying phonemes are in the scene we were pronouncing dictionary。
    Here we get a word that says less， which is kind of a fun word。 Here's a word
    kabayl kabayl。
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 所以如果我们将它们串联在一起，假设np.random.choice对于i在范围5内。这将给我一个由5个音素组成的单词，这些音素是根据它们在我们发音字典中的基础频率选择的。这里我们得到一个单词“less”，这是一个有趣的词。还有一个单词“kabayl
    kabayl”。
- en: And here is moles。 So not necessarily great randomly generated words。 but they
    contain English phonemes in， roughly the proportion that we expect from English
    words。 I'm going to take this and I'm going to put it into a function called gen_neologism。
    I won't take a parameter and then we'll just do this， return this。
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是 moles。所以并不一定是很好地随机生成的单词，但它们包含英语音素，比例大致符合我们对英语单词的预期。我将把这个放入一个名为 gen_neologism
    的函数。我不会接受参数，然后我们就这样做，返回这个。
- en: I might want this instead of always doing 5， I want to return range。 So I do
    random。rand range。 let's say from 3 up to but not including 10。 And then we'll
    just call this function。 generate any eologism。 And we get a dust-titin。 Not bad。
    Not what we can do with the Pinsley library as we can spell that。 We get test-gen-dleble，
    ahiachula。
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 我可能想要这个，而不是总是做 5，我想返回范围。所以我做 random.rand range。假设从 3 到但不包括 10。然后我们就调用这个函数，生成任何新词。我们得到了一个
    dust-titin。不错。我们可以用 Pinsley 库拼写它。我们得到了 test-gen-dleble，ahiachula。
- en: latte check， a zompchabur， arightiote， viamia。 So now we're generating new spellings
    of words based on this very simple statistical model。 of how English words sound。
    I'm just to illustrate this。 I've created a lot of empty cells。 I don't need all
    of those。 Maybe to illustrate this a little bit better。 I'm going to make a loop
    here for i and range。 I'll just make 12 of them。 The phones。
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: latte check，一个 zompchabur，arightiote，viamia。所以现在我们根据这个非常简单的统计模型生成单词的新拼写，模型是关于英语单词的发音。我只是为了说明这一点，创建了很多空单元格。我不需要所有这些。也许为了更好地说明这一点，我要在这里为
    i 和 range 做一个循环。我会做 12 个。这些音素。
- en: I'm going to say is the gen eologism。 Spell is going to be pin dot spell， the
    phones。 And then we'll print both the spelled version and the phonemes that came
    from it。 So you can see off to the right these are the phonemes that generated
    it。 And then to the left is the word that came from that。 And sometimes these
    are going to be closed。
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 我将说 gen eologism。拼写将是 pin.dot spell，这些音素。然后我们会打印出拼写版本和它生成的音素。所以你可以看到右侧是生成它的音素。左侧是从中得出的单词。有时这些会是闭合的。
- en: Sometimes they're not。 The model， the language model in the decoder for the
    spelling model is sometimes when it。 comes across a sequence of sounds that it
    just hasn't seen before。 It's kind of just like muddles its way through it by
    picking more or less high frequency sequences。 of letters。 But for the most part
    they're fairly plausible。
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 有时它们并不是。拼写模型中的语言模型，有时在解码器遇到它之前从未见过的声音序列时，便会有些混乱。它通过选择高频字母序列来勉强应对。但大多数情况下，它们还是相当合理的。
- en: This is ersninger and we get backstringe。 This is ereken and we get backring。
    We get chlilotmo。 So this is just kind of a way to use this library to create
    plausible randomly generated words。 Plausible both in the sense that they contain
    sounds and about the same proportion as English。 contains them and plausible in
    that they are spelled in a way that is close to how that。
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 ersninger，我们得到了 backstringe。这是 ereken，我们得到了 backring。我们得到了 chlilotmo。所以这只是一种使用这个库创建合理随机生成单词的方法。合理的意思是它们包含的声音和英语中的比例大致相同，并且在拼写上也接近于这样的方式。
- en: original sequence of sounds。 This is something that Pinsley can do that you
    wouldn't be able to do this with just the。 seem you pronounce in dictionary。 Let's
    move on to a little bit of a technical detail about the Pinsley model and that
    is。 phoneme features。 So far we've been treating the phoneme as the basic unit
    of English phonetics。 But phonemes themselves can be decomposed which is to say
    we can actually analyze phonemes。
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 原始声音序列。这是 Pinsley 可以做到的，而你仅仅用字典中的发音是无法做到的。让我们继续讨论一下 Pinsley 模型的一个技术细节，那就是音素特征。到目前为止，我们一直将音素视为英语语音学的基本单位。但音素本身可以被分解，也就是说我们实际上可以分析音素。
- en: and look at particular parts of the phoneme essentially。 The way that linguists
    do this is that let's take a sound like ba for example。 If you actually pronounce
    it with your mouth you can tell that it's doing a couple of things。 and linguists
    have words for those things。 So ba is what's called a bilabial consonant which
    means that you make it with your lips。
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 主要看音素的特定部分。语言学家这样做的方式是，比如说取一个声音像 ba。如果你真的用嘴发音，你可以知道它在做几件事情，而语言学家对这些事情有术语。所以
    ba 是一个双唇辅音，这意味着你用嘴唇发出这个声音。
- en: with your two lips touching together。 It's also a stop。 And a stop is a kind
    of consonant where when you are pronouncing it all of the airflow。 is stopped
    from homing out of your mouth。 So if you notice when you are saying ba you go
    up and no more sound comes out when you're。 doing that。 I actually made like a
    glottalized stop when I was doing that to demonstrate but that's。
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 用两个嘴唇相互接触。它也是一个塞音。塞音是一种辅音，当你发音时，所有的气流都会被阻止，不再从你的嘴里出来。所以如果你注意到在说“ba”时，声音上升，随后就没有声音再发出。我实际上是在做这个以演示时产生了一个喉塞音，但那是。
- en: what a stop does。 It stops the air from flowing momentarily。 It also stops the
    air from flowing and some consonants don't do that。 We'll look at some examples
    of that。 It's also voiced which means roughly and it's a bit more complicated
    in this in English。 but this is a good first approximation of how to talk about
    it。
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 塞音的作用是暂时阻止空气流动。某些辅音并不会做到这一点。我们会看看一些例子。它也是有声的，这在英语中大致意味着更复杂一点，但这是讨论它的一个良好初步近似。
- en: Your vocal chords are vibrating when you're making that sound。 So if you say
    ba you can see you're like that。 We can contrast this with a different sound。
    Let's say pa for example。 So pa and I'm probably like pa pa pa pa into the microphone
    when I'm saying this sorry。 But pa is also bilabial。 You make it with your lips。
    It also stops。
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 当你发出这个声音时，声带是振动的。所以如果你说“ba”，你会看到你是这样的。我们可以将其与不同的声音进行对比。比如“pa”。所以“pa”，我可能在对着麦克风说“pa
    pa pa pa”时不好意思。不过“pa”也是双唇音。你是用嘴唇发音的。它也会停止。
- en: However pa if you make the word pa you'll notice your vocal chords。 You can
    feel your vocal chords when you're doing this。 They're not vibrating。 This is
    what's called voiceless。 Vocal chords are not vibrating。 Actually these two phonemes
    are similar in a lot of ways。 In fact they share two characteristics。
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，如果你发“pa”这个词，你会注意到你的声带。你可以在这个过程中感受到你的声带。它们并没有振动。这被称为无声。声带并未振动。事实上，这两个音素在很多方面是相似的，实际上它们共享两个特征。
- en: They're both bilabial and they're both stops。 The only way that they differ
    at least according to this analysis is whether or not they're voiced。 or voiceless。
    So these two phonemes are actually similar to each other。 You can contrast that
    with a different sound。 Let's say like is not a bilabial sound。 You don't make
    it with your lips。 It doesn't really matter what your lips are doing。
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 它们都是双唇音，且都是塞音。根据这种分析，它们的唯一区别在于是否发声或无声。所以这两个音素实际上是相似的。你可以将其与不同的声音进行对比。例如，/l/就不是一个双唇音。你并不是用嘴唇来发这个音。嘴唇的动作并不重要。
- en: You can kind of like make a difference based on like moving your lips。 like
    you can go ssssssss。 but that doesn't affect whether we think of that sound as
    /s/， Right？
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过移动嘴唇来制造一些区别，比如你可以发出ssssssss的声音，但这并不会影响我们如何看待这个声音为/s/，对吧？
- en: It's actually an alveolar constant。 If you feel where your tongue is when you're
    making that sound -- /s/ -- the way that your。 tongue is sort of up at the front
    of your mouth。 That's an alveolar position for a consonant。 It's also not a stop。
    Air keeps flowing while you're making that sound。 This is what's called a fricative。
    The main thing that you're doing when you're making this consonant sound is you're
    making。
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，这是一个齿槽辅音。如果你感受一下舌头在发音时的位置——/s/——舌头在嘴前的上方。这是辅音的齿槽位置。它也不是塞音。在发这个音时，空气持续流动。这被称为**摩擦音**。发这个辅音音时，你主要在做的就是。
- en: noise by pushing the air against parts of your mouth with your tongue， and that's
    a， fricative。 S is also voiceless。 The voiced counterpart is /z/。 So the sound
    /z/ is the same as except its voiced。 You can actually feel that if you switch
    between the two sounds very quickly。
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 通过用舌头推空气与嘴部的某些部位接触，可以发出噪音，这是一种**摩擦音**。S也是无声的，其发声对应音是/z/。所以音/z/与其相同，只是发声方式不同。如果你在这两种声音之间快速切换，你实际上可以感觉到这一点。
- en: Feel how your head starts vibrating， basically， when you make the /z/ sound。
    Because your vocal chords are vibrating。 So there are a whole bunch of these are
    called phonetic features。 We can break down phonemes into these component features。
    Pinsulate as a model is actually trained on not in virtual phonemes but on the
    phonetic， features。
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 当你发出/z/音时，感受一下你的头部是如何开始振动的。这是因为你的声带在振动。这些被称为音韵特征。我们可以将音素分解成这些组成特征。Pinsulate作为一个模型，实际上是基于音韵特征而非虚拟音素进行训练的。
- en: That becomes important for a number of different reasons that we'll see in a
    second。 To see all of the possible features of all of the phonemes in the Pinsulate
    model， you。 can do this from Pinsulate。featurephone。 Import phone feature map。
    And then we can look at that phone feature map。 It uses these abbreviations for
    each one of the features。
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 这对多个不同的原因很重要，我们马上就会看到。要查看 Pinsulate 模型中所有音位的所有可能特征，你可以从 Pinsulate.featurephone
    导入音位特征图。然后我们可以查看那个音位特征图。它为每个特征使用这些缩写。
- en: These three letter abbreviations。 But this shows you what the features are that
    correspond to each possible phonemes。 So /n/ is a bilabial nasal phonem。 It's
    just like /b/ actually except with the errors coming out of your nose。 Whereas
    with /b/ no air comes out at all。 Another example might be with the vowels。 It's
    a little bit more complicated。 There are a whole bunch of different features of
    vowels。
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 这些三个字母的缩写。但这向你展示了与每个可能音位对应的特征是什么。所以 /n/ 是一个双唇鼻音。它实际上与 /b/ 很像，只是气流从你的鼻子出来。而对于
    /b/，则没有空气流出。另一个例子可能是元音，稍微复杂一点。元音有很多不同的特征。
- en: The quality of a vowel depends on where the tongue is in your mouth when you're
    making。 a vowel sound。 So for example， /i/ the vowel sound /i/ your tongue is
    in the front of your mouth and。 it's high up in your mouth and your lips aren't
    rounded。 So that's /i/ your mouth is spread open while you're making it and your
    tongue is really， far up。
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 元音的质量取决于你在发元音音时舌头在口腔中的位置。例如，/i/ 的元音音 /i/，你的舌头在口腔前部，并且位于口腔的上方，嘴唇没有圆起来。所以这是 /i/，在发这个音时你的嘴是张开的，舌头非常靠上。
- en: With this sound like /u/ for example， /u/ is a lot like /i/ except with two
    differences。 The tongue is still high in the mouth but your tongue is now in the
    back of your mouth。 So /i/ /u/ you can feel your tongue attracting when you say
    /u/。 /u/ is also a rounded sound。 So when you make /u/ your lips are rounded versus
    /i/ they're unrounded。
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 这个声音像 /u/，例如，/u/ 和 /i/ 很像，只是有两个不同之处。舌头仍然在口腔中很高，但现在舌头在口腔后部。因此 /i/ 和 /u/，当你发 /u/
    时可以感觉到舌头在向后。/u/ 也是一个圆唇音。因此，当你发 /u/ 时，嘴唇是圆的，而 /i/ 的嘴唇则是不圆的。
- en: In English these are the two vowels that we have that are high vowels。 In French
    there's another vowel that is high and rounded but also in the front that's /i/。
    which is one of my favorite vowel sounds。 So vowels are like they have their own。
    their own mischredals going here。 There are low vowels like /a/ is a low vowel
    because your tongue is low in the mouth。
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在英语中，这些是我们拥有的两个高元音。在法语中，还有另一个高而圆的元音，位于前面的 /i/，这是我最喜欢的元音之一。所以元音就像它们有自己独特的特性。低元音如
    /a/ 是一个低元音，因为舌头在口腔中是低的位置。
- en: Their mid vowels like low mid vowels like /a/ or /a/ is this vowel where the
    tongue is。 halfway between high and low。 So those are the different features of
    phonemes。 In the notes for this I've given a list of what the， actually maybe
    I'll just paste them。 to the notebook so we can look at them together。 So here's
    like all of the features along with their names。
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 他们的中元音，如低中元音 /a/ 或 /a/，是舌头在高和低之间的元音。所以这些是音位的不同特征。在这份笔记中，我列出了实际的内容，或许我直接粘贴到笔记本里，这样我们可以一起看看。这里是所有特征以及它们的名称。
- en: These aren't necessarily going to mean anything to you if you don't have a linguistics
    background。 but I might refer to these later。 The most easy one。 through and birthing
    is like bilabial is a consonant that's made with， your lips。 A velour consonant
    is made with the soft palate， it's called the vellum also。
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有语言学背景，这些内容不一定对你有意义，但我可能会在稍后提到这些。最简单的一个，通过和生育就像双唇音，它是用你的嘴唇发出的辅音。软腭音是用软腭发出的，它也被称为“软腭”。
- en: So like /g/ and /k/ and /ung/ those are velour consonants。 So I'll come back
    to this list later but that's the main thing to know is that in the Pinsulate。
    model phonemes are broken up into the constituent features。 And you can actually
    get back。 this is where we get a little bit deeper into numpy。 What you can do
    is you can say pin。
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 像 /g/、/k/ 和 /ung/ 这些都是软腭音。所以我稍后会回到这个列表，但要知道的主要内容是，在 Pinsulate 模型中，音位被分解成构成特征。实际上你可以回到这里，我们会稍微深入
    numpy。你可以说 pin。
- en: phoneme features， let's say for a word like cat。 Oh before I go to this I should
    say there are two additional weird features。 And those are be/g which means the
    beginning of a word and which means the end of a word。 And just for basically
    implementation reasons of a neural network model we need to have a。 separate like
    basically a marker that says like this is where the word ends。
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 音素特征，假设以单词cat为例。在我继续之前，我应该说还有两个额外的奇怪特征。这些特征是be/g，分别表示单词的开头和结尾。基于神经网络模型的实现原因，我们需要有一个单独的标记，表明这个地方是单词的结束。
- en: That's because it's a sequence to sequence model it's predicting a sequence
    and part of。 it what it needs to predict is this is where the sequence ends。 So
    this is also something that's going to pop up whenever we look at the phoneme
    features。 The first phoneme is always going to be a single phoneme that just says
    it's the beginning。
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为它是一个序列到序列的模型，它在预测一个序列，部分内容是它需要预测的地方是序列的结束。因此，这也是当我们查看音素特征时会出现的内容。第一个音素总是一个单音素，表示这是开始。
- en: of the word with no other features。 And then the second the ending phoneme is
    always going to be a phoneme that has end with。 no other features。 We can actually
    look at Pinsulate's guesses about what the phoneme features are using the。 phoneme
    features function。 This returns this big scary looking numpy array。 So I'm going
    to assign it we'll call this cat feeds。 Cat feeds dot shape。 So this is an array。
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 这个单词没有其他特征。然后第二个音素的结尾总是一个具有结束特征的音素，没有其他特征。我们可以查看Pinsulate对音素特征的猜测，使用音素特征函数。这返回一个看起来很可怕的numpy数组。所以我将给它命名，我们称之为cat
    feeds。cat feeds的形状。
- en: It has five rows and 32 columns。 The five rows represent the five phonemes in
    this word including both the beginning and。 the ending phoneme。 The sort of like
    virtual phonemes that represent the beginning and the end。 And those phonemes
    are cut at right。 So what it's what it's actually predicting when the model predicts
    what it's actually。 predicting is this is a velar voiceless stop。 And then when
    it predicts cat it's predicting that this is a low front。
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 它有五行和32列。这五行代表这个单词中的五个音素，包括开头和结尾的音素。像虚拟音素那样表示开头和结尾。这些音素被准确切分。因此，模型在预测时，实际上预测的是这是一个软腭清音停音。当它预测cat时，预测的是这是一个低前音素。
- en: I forget what the rest of the features are for a low front unrounded vowel。
    And when it predicts tah it's predicting that this is an alveolar voiceless stop。
    Each one of these features， sorry， each one of these features， let's tap that
    over。 Each one of these features corresponds to one of the columns。
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 我忘记了低前非圆唇元音的其余特征是什么。当它预测tah时，它预测这是一个齿龈清音停音。这些特征中的每一个，对不起，每个特征，都对应于一列。
- en: And the mapping between the columns isn't straightforward。 It's arbitrary。 But
    basically what we can do is we can look at a single element of that。 So if we
    get the first row。 this is the row that corresponds to cat。 And then we can look
    through these numbers and these numbers are not very easy to read。 But we can
    actually let's do the numpy print。 Print options is that what it is？ I always
    forget。
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 列之间的映射并不简单。它是任意的。但基本上，我们可以查看其中的单个元素。如果我们查看第一行，这一行对应于cat。然后我们可以浏览这些数字，这些数字不太容易读取。但我们实际上可以做numpy打印。打印选项是这样的吗？我总是忘记。
- en: There's a way with numpy to get it to not use scientific notation。 Set print
    options。 The press equals true。 Okay， so now this is a little bit more readable。
    This is giving us。 A number between zero and one that predicts whether the phoneme
    at this position has the。 given feature。 And you can see that there are three
    right off the bat that are near 100% probability。
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 使用numpy有一种方法可以让其不使用科学计数法。设置打印选项。按下等于true。好的，现在这个看起来更易读了。这给我们一个在0到1之间的数字，预测该位置的音素是否具有给定特征。你可以看到，最开始就有三个接近100%概率的特征。
- en: So these three features here。 And we do expect these features to correspond
    to velar voiceless stop。 Likewise if we were to look at cat feats。 Three。 And
    we would expect to be a velar voiceless stop。 So because these two are shared
    by both。 And these are probably the voiceless stop features。 And then this is
    probably all velar and this is probably velar。 In fact we can check this for sure。
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 这三个特征在这里。我们确实希望这些特征与软腭清音阻塞音相对应。同样，如果我们看一下猫的特征。三种。我们希望是一个软腭清音阻塞音。因此，因为这两个特征是共享的。这些可能是清音阻塞音特征。这可能都是软腭的，而这可能是软腭。事实上，我们可以确认这一点。
- en: Let me go back to this。 There's a method called pin。feature index。 And then
    if you pass in a feature like velar it tells you the index in this array that
    corresponds。 to the given feature。 So if I did do cat feats one and then from
    the second dimension getting pin feature index。 velar。 That's the probability
    that there is a velar feature in this particular phoneme。
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 让我回到这个。有一个方法叫做pin.feature index。如果你传入一个特征，比如软腭，它会告诉你这个数组中对应于给定特征的索引。因此，如果我做猫特征的第一维，然后从第二维获取pin特征索引。软腭。这是这个特定音素中存在软腭特征的概率。
- en: And then we can double check with the rest of these velar。 Is it a stop？ Yes
    stop。 Is it voiced？
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以与其余的软腭进行双重检查。它是一个阻塞音吗？是的，阻塞音。它是浊音吗？
- en: No it is not voiced。 This is a very small number。 Is it voiced less？ Yes it
    is voiceless。 So as a quick example of this。 There are a couple of ways of using
    this and the examples I'm going to show you here are。 not super practical but
    they are kind of fun。 So what we can do is actually manipulate the underlying
    feature array。 So let's get the features for the word bug。 Or for the word bug。
    Let's start with pug。
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 不，它不是浊音。这是一个非常小的数字。它是浊音吗？是的，它是清音。因此，作为一个快速的例子。有几种使用方法，我在这里展示的例子。并不超级实用，但也挺有趣。因此，我们实际上可以操控底层特征数组。因此，让我们获取单词“bug”的特征。或者说“bug”这个词。让我们先从“pug”开始。
- en: So I'm going to do pin。 phoneme features for the word pug。 Like that。 And it
    looks like that。 This is what pug looks like。 You can see here this is the beginning
    phoneme that happens to be index 0。 1， 2， 3。 And then this is the ending phoneme。
    That's the thing that indicates that it's the end。 The model is never entirely
    sure about where it's going to end。
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我要做的是为单词“pug”提供音素特征。像这样。看起来是这样的。这就是“pug”的样子。你可以看到这是发生在索引0的起始音素。1，2，3。然后这是结束音素。这是表明它结束的东西。模型从未完全确定它将在哪里结束。
- en: So there's still some probability that some feature will follow but it is 99。8%
    sure that。 it's going to stop here。 What I can do then is I can say set a value
    in this array。 So I'm going to say pug at the first feature at the pin。feature
    index。 The voiced phoneme feature。 Pug begins with a pug which is unvoiced。 I'm
    going to set that to 1。
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 所以仍然有一些概率会有某些特征跟随，但99.8%确定它会在这里停止。那么我可以做的就是在这个数组中设置一个值。因此，我要说“pug”在第一个特征上，位于pin.feature
    index的浊音音素特征。Pug以一个不带声的pug开头。我将把它设置为1。
- en: And I'm going to set the voice less feature to 0。 Now if I can spell from those
    features using the spell features function。 which is the， opposite universe of
    the phoneme features function。 If I now spell out array。 I get back bug because
    I've taken that first phoneme。 I've taken away its voicelessness and I've added
    in voicelessness and I'm so I've morphed。
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 我将把清音特征设置为0。现在如果我可以使用拼写特征函数从这些特征中拼写出单词。这是音素特征函数的相反宇宙。如果我现在拼出数组。因为我去掉了第一个音素的清音性并加入了清音性，所以我得到了“bug”，我进行了变化。
- en: the word into the word bug by changing those probabilities。 Which I think is
    pretty cool。 You could do this and take any word and then randomly replace features
    and it with other。 features in order to make changes to the way that it's spelled。
    Another thing that we could do is maybe something weird。 If NumPy we can do random。uniform。
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 通过改变这些概率，将单词转变为“bug”。我认为这非常酷。你可以这样做，取任何单词，然后随机替换特征，以改变它的拼写方式。我们还可以做一些奇怪的事情。如果用NumPy我们可以做random.uniform。
- en: This returns a random number from a uniform distribution between 0 and 1。 If
    we give this a shape。 size that is let's say 5 by 32。 This is going to give me
    an array of random numbers that is 5 rows and 32 columns。 Essentially the same
    shape as the phoneme features that are returned from the model。 Then I could use
    this to spell a new word based on this random number。 When we get this。
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 这返回一个在 0 到 1 之间均匀分布的随机数。如果我们给它一个形状，比如说 5 乘 32。这将给我一个随机数数组，包含 5 行和 32 列。基本上与模型返回的音位特征具有相同的形状。然后我可以使用这个随机数拼写一个新单词。当我们获得这个时。
- en: every time I run this I get this random word that's essentially generated。 from
    just a sequence of phonemes that don't actually make any sense。 What I think is
    interesting about this and this wasn't the plan or I don't actually。 think it
    means anything but if I just generate maybe 12 of these in a row and print them。
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 每次我运行这个时，我得到的随机单词本质上是从一系列实际上没有任何意义的音位生成的。我觉得这很有趣，这并不是计划中的事情，我实际上也不认为它意味着什么，但如果我连续生成
    12 个并打印出来。
- en: I get these randomly generated words。 What's interesting to me is that it kind
    of sounds like white noise。 It kind of sounds like somebody imitating the white
    noise from a detuned radio。 This is a lot of like a lot of synonyms。 There's also
    a function called pin。vectorize features。 What that takes is a list of lists of
    features。 If this we can construct a word from scratch。
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 我得到这些随机生成的单词。令我感兴趣的是，它听起来有点像白噪声。听起来就像有人模仿失调收音机的白噪声。这像是很多同义词。还有一个叫做 pin 的函数。vectorize
    特征。它需要一个特征列表的列表。如果可以，我们就能从头构造一个单词。
- en: By labial stop voiced followed by a high front vowel followed by a followed
    by the end of， the word。 Here I'm constructing a new word based on features based
    on phoneme features。 We start with the beginning of the word。 We end with the
    end of the word。 This is a high front vowel。 If I run that then it gives me the
    numpy array that corresponds to that。
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 由唇音阻塞声母后跟高前元音，再跟单词的结尾。这里我正在基于音位特征构建一个新单词。我们从单词的开头开始。以单词的结尾结束。这是一个高前元音。如果我运行它，给我返回对应的
    numpy 数组。
- en: It has to be 32 ommons long。 That's part of the model that you can notice。 That
    right there is the feature for not that one。 This one is the one for ending the
    sequence。 If I assign this to a variable I'm going to call this B and then spell
    pin。spellfeatures。 Again there's some randomness in the spell features function。
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 它的长度必须是 32 ommons。这是模型的一部分，你可以注意到这一点。这个是特征，不是那个。这个是序列结束的特征。如果我将其分配给一个变量，我会将其称为
    B，然后拼写 pin。spellfeatures。同样，在拼写特征函数中有一些随机性。
- en: It doesn't always return the same thing。 There's some temperature in the way
    that it samples from the end layer。 This shows you an example of how you could
    potentially construct a word from scratch using。 just those features。 Another
    fun thing that I'd like to do with these probability arrays is you'll notice。
    that if you're looking at the full cat features array again。 This is a numpy array。
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 它并不总是返回相同的东西。它从最终层采样的方式有一些温度。这给你展示了一个例子，说明如何使用这些特征从零开始构建一个单词。我想做的另一个有趣的事情是，你会注意到，如果再次查看完整的猫特征数组。这是一个
    numpy 数组。
- en: It's two-dimensional。 This has the same structure essentially as an audio file
    in the sense that it's basically。 a series of samples。 These samples are all individual
    vowels that correspond to a point in time。 It's like an audio file。 It's like
    an audio file。 It's even like an image。 Image is also an array of values。 In an
    image there are three-dimensional values。 The red， green。
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 它是二维的。这在结构上与音频文件基本相同，因为它实际上是一系列样本。这些样本都是对应于某个时间点的单个元音。就像一个音频文件。就像一个音频文件。它甚至像一幅图像。图像也是一组值。图像中有三维值。红色、绿色。
- en: and blue channel。 With Pinsulate there are 32-dimensional values where there's
    a feature。 a value for each， phonetic feature。 But based on that intuition we
    can do super weird。 interesting things potentially where， we treat this array
    as though it is an image or a sound file。 Then we can use all of the same functions
    in the Python libraries or in the SciPy libraries。
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 以及蓝色通道。使用 Pinsulate，有 32 维的值，其中有一个特征。每个都有一个对应的音位特征。但基于这个直觉，我们可以做一些非常奇怪的、有趣的事情，比如将这个数组当作图像或音频文件来处理。然后，我们可以使用
    Python 库或 SciPy 库中的所有相同功能。
- en: that deal with images or deal with sounds。 We can apply those with images or
    with audio。 We can apply them to the phonetics of sound as well。 One that I like
    to do is SciPy and D image interpolation。 So zoom is a function that normally
    you use on images。
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 处理图像或处理声音的功能。我们可以将它们应用于图像或音频。我们也可以将它们应用于声音的音韵特征。我喜欢做的一个是SciPy和D图像插值。因此，缩放是一个通常用于图像的函数。
- en: But it actually takes data of any number of dimensions， not just image data。
    So if I get the phonetic feature array for what's say word alphabet， phoneme features，
    alphabet。 This is what that looks like。 This big array looks like what we do expected
    to based on the explanation that I've just。 given。 What we can do with this feature
    array is we can resize it。 So the zoom function。
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 但它实际上可以处理任何维数的数据，而不仅仅是图像数据。所以如果我得到单词“alphabet”的音韵特征数组，这个数组的外观就是我们基于我刚刚给出的解释所期待的样子。我们可以对这个特征数组进行操作，可以调整大小。所以缩放函数。
- en: I can zoom out or zoom in to this array。 So if I zoom into this 0。671 is going
    to give us a shorter array that actually interpolates， between the values in the
    array。 So this gives me a new array that has fewer items in it。 I can then spell
    from that array。 So I do pin spell features like that。 Then I get essentially
    a shorter version of the word alphabet。
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以对这个数组进行缩放。因此，如果我放大这个，0.671会给我们一个更短的数组，实际上在数组中的值之间进行插值。所以这给了我一个新数组，包含更少的项目。我可以从那个数组拼写。所以我这样做拼写特征。然后我得到一个本质上是单词“alphabet”的更短版本。
- en: I can zoom， this is zooming out。 It's making it smaller。 so we're getting a
    higher level viewer of it。 I can zoom in。 let's say I can make this word twice
    as long by doing two there。 And then we get basically the word alphabet if it
    had to be twice as long as it actually， is。
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以缩放，这就是缩小。它让它变小，因此我们获得了更高层次的视图。我可以放大。比如说，我可以通过把这个数字设为二，将这个词变成两倍长。然后我们得到的基本上是“alphabet”这个词，如果它必须是实际长度的两倍。
- en: So you get alphabestab or alphalbeat。 So we've stretched those phonemes across
    a longer array。 And so the model has to now try to spell from that， which I think
    is kind of fun。 And I'm not going to show this in the live typing here， but there's
    an example in the。 pre-written notes that show how to make an interactive widget
    where you can type in arbitrary。
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 所以你得到“alphabestab”或“alphalbeat”。我们把这些音素扩展到更长的数组中。因此模型现在必须尝试从中拼写，我觉得这很有趣。我不打算在这里实时输入，但在预先写好的笔记中有一个例子，展示了如何制作一个交互式小部件，在这里你可以输入任意。
- en: sequences of sounds and then get back or arbitrary strings and then get back
    and then adjust it。 with a slider。 And actually maybe I'll just like， I'm just
    going to pull that。 I'm going to cut and paste that over here because I think
    it's cool and I want to show， it to you。 So to make this work， I have to actually
    import from ipi widget import interact like that。
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 声音序列，然后得到任意字符串，然后再调整它。用滑块。实际上，也许我只是想把它拉过来。我会把它剪切并粘贴到这里，因为我觉得它很酷，我想给你展示。因此，要使其正常工作，我实际上需要从“ipi
    widget”导入“interact”。
- en: So I just cut and pasted this from the full example notebook。 So you can type
    anything you want to in here。 It shows you how the model would spell that。 And
    again， it doesn't necessarily get these words correct。 But now I can re- spell
    it。 stretching it out by dragging this slider。 So when this is twice as long。
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我只是从完整示例笔记中剪切并粘贴了这个。你可以在这里输入任何想要的内容。它会向你展示模型如何拼写这个。而且，它并不一定能正确拼写这些词。但现在我可以重新拼写，通过拖动这个滑块将其拉长。所以当这个长度变为两倍时。
- en: it says how to spell experscribalism。 If I make it， let's say four times as
    long。 there's sort of a limit to how well it can， actually do this， but how becomes
    heow to becomes too。 So spell becomes spepensel and expressively becomes all express
    divalism。 This is a curious feature of the model， which is that towards the end
    of the sequence， it。
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 它说明了如何拼写“experscribalism”。如果我让它，比如说，四倍长，实际上它的表现有一定的限制，但如何变成heow也变得太复杂了。所以拼写变成了“spepensel”，而“expressively”变成了“all
    express divalism”。这是模型的一个奇特特性，即在序列的末尾，它。
- en: sort of loses track and just starts to predict sequences that it thinks are
    high frequency。 and kind of forgets what it was conditioned on to begin with。
    That's just a consequence of this variety of model。 I can change this and so it's
    making it much smaller。
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 它有点失去轨道，开始预测它认为是高频的序列，而忘记了最初的条件。这只是这种模型的一个结果。我可以改变这个，使它变得小得多。
- en: So here's like zooming so it's halfway as long， basically trying to smush all
    about。 phonetic information into a much shorter sequence。 So that's phonetic features
    and there's other stuff that we're going to do with that a little。 bit later。
    But I want to show what I call round-trip spelling manipulation。
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这里就像放大了一样，基本上试图把所有的语音信息压缩成一个更短的序列。所以这就是语音特征，还有其他一些我们稍后会处理的东西。但我想展示我所称的往返拼写操控。
- en: And this is a function in pencilate called pin。minipulate。 And if you pass in
    a word。 let's say spelling， what the manipulate function does， in most， cases，
    it's an identity function。 You pass in the word and then you get the word back。
    What's actually happening with manipulate is you pass in the string。
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 这是pencilate中一个名为pin.minipulate的函数。如果你传入一个单词，比如拼写，操控函数在大多数情况下是一个恒等函数。你传入单词，然后得到原单词返回。实际上，操控是你传入字符串。
- en: The string is going to the graph game to phoneme model。 And then it's going
    from that to the phoneme to graph game model。 And then it comes back to the original
    string。 So it's essentially internally sounding out the word and then spelling
    it from the sounded。 out version to give you the original string。 What I think，
    how this is useful。
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 字符串将传递到图形-音素模型。然后从那转到音素-图形模型。最后再返回到原始字符串。所以本质上它是在内部发音这个单词，然后从发音版本拼写出来，以给你原始字符串。我认为，这个过程是有用的。
- en: that seems pointless on the surface， but how this is。 useful is that this manipulate
    function has a number of parameters that you kind of poke。 at those decoding processes
    on either side。 So if I do pin one is just manipulating the amount of randomness
    that goes into picking。 those phonemes。 So there's a parameter temperature and
    also any function in pencilate that I should do。
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 表面上看似乎毫无意义，但这有用之处在于，这个操控函数有多个参数，你可以通过这些参数影响两边的解码过程。所以如果我将一个参数固定，它只是操控进入选择那些音素的随机性。所以有一个温度参数，还有在pencilate中的任何函数我应该去做的。
- en: spelling has a temperature parameter that you can adjust。 If I give it a really
    low temperature。 then I'm going to get a very predictable spelling。 As I increase
    this temperature value。 if I said like 0。6， if I go up to 1。0， if I go， up to
    1。5， maybe， as you increase the temperature。 there's a little bit of randomness，
    a little， bit more randomness that's applied when it's picking the next letter
    and the sequence。
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 拼写有一个可以调整的温度参数。如果我给它一个非常低的温度，我会得到非常可预测的拼写。随着我增加这个温度值，比如0.6，如果我提高到1.0，再到1.5，也许，随着温度的增加，选择下一个字母时会施加一些随机性。
- en: So you can see in this case， it got through spelling and then it didn't actually
    end the。 string here。 Instead it picked the letter Q and then it had to finish
    spelling the word based on that。 sequence。 So you get spelling or a spell-yoon
    spalling。 So it's picking with a little bit of randomness。 You get kind of like
    a glitchy version of the spelling。
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 所以在这个例子中，它经过拼写，然后实际上没有在这里结束字符串。相反，它选择了字母Q，然后必须根据那个序列来完成拼写。所以你得到拼写或拼写变体。它带着一点随机性选择。你会得到拼写的一个故障版。
- en: which I think is potentially interesting。 If you increase this all the way up
    to something like 4。 then you essentially just start getting， random sequences
    of letters that have absolutely nothing to do with the original word。 There's
    a sweet spot in there somewhere in the 1。75 range where you get what just seemed。
    to be sort of weird variations on the original word。 And to demonstrate that，
    again。
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为这是潜在有趣的。如果你将这个值增加到4，那么你基本上会得到随机字母序列，这些字母和原始单词完全无关。在1.75的范围内有一个甜点位置，你会得到一些奇怪的变体，以展示这一点。
- en: I'm just going to cut and paste one of these examples from， the full notebook。
    This is an interactive widget that lets you adjust this temperature parameter
    dynamically。 So as I take it down， it's producing more likely spallings。 Again，
    with the shorter words。 it kind of doesn't do a great job of predicting them。
    If I increase this temperature。
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 我将从完整的笔记本中剪切并粘贴一个示例。这是一个交互式小部件，可以让你动态调整这个温度参数。所以当我降低它时，它会产生更可能的拼写。同样，短词的话，它在预测上表现得不是很好。如果我提高这个温度。
- en: there's a little bit of lag。 Then we start getting things that are kind of recognizable
    as that original string。 But feel like they've been spoken by an alien who doesn't
    actually know how to speak English。 doesn't have to write vocal operatus for speaking
    English。 When you see a carrot in there。 by the way， it's because it's predicting
    that the word， begins there。
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 会有一点延迟。然后我们开始得到一些与原始字符串有些相似的东西。但感觉就像是一个外星人说出来的，它其实不懂英语。并不需要为说英语写出发声操作。当你看到一个插入符号时，顺便提一下，那是因为它预测这个词从那里开始。
- en: which shows you how much randomness is actually being applied here， because
    the。 beginning of word is obviously never going to come in the middle of the word。
    But the model nevertheless， with enough temperature， tends or sometimes predicts
    that。 Another thing that you can do with this manipulate function is -- and we'll
    go back to the word。
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示了在这里实际上应用了多少随机性，因为单词的开头显然不可能出现在单词的中间。但模型仍然能够在足够的温度下预测到这一点。你可以使用这个`manipulate`函数的另一个功能——我们回到这个单词。
- en: spelling -- is during the decoding process with this phoneme to graph-eam model，
    you can actually。 adjust the probabilities of the possible next letter。 So with
    the sequence-to-sequence model。 what it's doing is that each step in the spelling。
    it's making a guess about what the next letter is going to be based on the list
    of possible。
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 拼写——在解码过程中，通过这个音素到图形模型，你实际上可以调整下一个可能字母的概率。因此，在序列到序列模型中，每一步的拼写都是根据可能的列表来猜测下一个字母。
- en: letters。 Each letter is assigned probability。 What the manipulate function does
    is it lets you play without probability。 And the way that you can do that， one
    is with letters。 So the parameter letters that takes a dictionary with letters
    as keys and then a probability。 modifier as a value。 The probability modifier
    as it goes up。
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 字母。每个字母被分配了概率。`manipulate`函数的作用是让你在没有概率的情况下进行操作。你可以通过字母来实现这一点。参数`letters`需要一个字典，字母作为键，概率修正器作为值。当概率修正器上升时。
- en: it's actually using this to -- it's passing it， to the exponent function on
    the probability itself。 So as the value goes up， it actually makes the probability
    exponentially smaller。 As the value goes down， it's making the probability bigger，
    which is a little bit intuitive， but。 that's just the way that I set it to do
    it。 So if I do this， this is essentially saying。
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 它实际上是将这一点传递给概率本身的指数函数。因此，随着值的上升，概率实际上会指数性地变小。随着值的下降，概率会变大，这有点直观，但这就是我设置它的方式。因此如果我这样做，这实际上是在说。
- en: '"Telling the model， "Hey， whenever you''re， picking the next letter。 reduce
    the probability that E will be picked。"， And the end result of that is that it
    picks another letter instead。 Like another letter that is sort of plausible in
    that position， the letter that had the。 next highest probability。 So this is essentially
    telling it to spell without the letter E。'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: “告诉模型，‘嘿，无论何时你选择下一个字母，都要降低选择E的概率。’”，最终结果就是它选择了另一个字母，比如在那个位置上比较合理的另一个字母，那个字母具有下一个最高的概率。因此，这本质上是在告诉它不要拼写字母E。
- en: I can keep doing that。 I can put like， "I" in there。 "I" we might have to be
    a little bit more aggressive。 And now when it tries to spell spelling。 it's just
    that with the letters "E" and the， letter "I" don't exist。 so it has to spell
    it as spelling like that instead。 We could increase this to do like。
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以继续这样做。我可以把“I”放进去。对于“I”，我们可能需要更积极一些。现在当它尝试拼写时，字母“E”和字母“I”都不存在，所以它不得不这样拼写。我们可以增加这个参数来进行。
- en: just get rid of all of the vowels。 A-e-i-o and "u。"。 And then what we get back
    is sometimes it doesn't do a great job。 You can't really do its job without those
    vowels， so in some cases it just has to make like。 completely wild guesses， but
    this one's pretty good。 So spelling without any vowels。
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 只需去掉所有的元音。A-e-i-o和"u"。然后得到的结果有时做得并不好。在没有这些元音的情况下，它确实无法完成任务，因此在某些情况下，它不得不做出完全疯狂的猜测，但这一次的表现相当不错。所以没有任何元音的拼写。
- en: filling like that。 The same way that we can manipulate the letters。 we can also
    manipulate the sounds。 So if I do pin dot manipulate spelling。 and then the features
    parameter instead of letters。 this applies that same logic except it's happening
    in this part where it's predicting。
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 像那样填充。我们可以以同样的方式操控字母，也可以操控声音。因此，如果我使用`pin dot manipulate spelling`，然后将特征参数改为字母。这适用相同的逻辑，只是发生在预测的部分。
- en: the phoneme features， which is to say at every stop when it's predicting phoneme
    features。 you can adjust the probability that any particular phoneme feature will
    be predicted。 But this lets us do， for example， is I can take this word and then
    increase the probability。 that it will come out as a nasal sound。 So nasal things
    will be predicted instead。
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 音素特征，也就是说在每次预测音素特征时，你可以调整任何特定音素特征被预测的概率。但这让我们可以，例如，我可以取这个单词，然后增加它作为鼻音的概率。所以鼻音将会被预测。
- en: So with that we go from spelling to smenking is how it guesses it when it has
    to put more。 nasalness into it。 Or maybe we could take out all of the voicelessness
    and add in voiceless。 So this is adding some voice to this， so we get spellings
    instead of spelling。 Something that I find you have to do is boost the end probability
    a little bit。 That was too much。
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们从拼写转到smoking，是它如何在需要更多鼻音时进行猜测。或者，也许我们可以去掉所有的无声音，并加入有声音。所以这是在增加一些声音，因此我们得到spellings而不是spelling。我发现你必须稍微提升末尾的概率。这太多了。
- en: To get rid of this final is whenever you tell it to increase the voiced feature，
    it tends。 to take that end feature off to the end of the word。 Maybe there's an
    easy way to fix that with this example。 So this lets you manipulate the sound
    of a word by adjusting the probability that the。
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 为了去掉这个最后的，当你告诉它增加有声特征时，它往往会把那个特征移到单词的末尾。也许用这个例子有一种简单的方法来修复这个。所以这让你通过调整某个声音的概率来操控一个单词的声音。
- en: particular phoneme features will be predicted。 An example that I have， well。
    that's the basics of this。 What I'm going to do now is I'm going to， again。 cut
    and paste a big old example from， the demo notebook。 It's just like super elaborate。
    But this is a big interface that lets you。 I don't want to go into the details
    of how I Python widgets work。
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 特定的音素特征将被预测。我有一个例子，嗯。这就是基础。接下来我要做的是，我将再次从演示笔记本中剪切和粘贴一个大的例子。这非常复杂。但是这是一个大的界面，让你。我不想详细讨论我的Python小部件是如何工作的。
- en: which is the reason， that I'm cutting and pasting it。 But it's a big old interface
    that lets you type in a string down here， spelling words。 of machine learning。
    And then each one of these sliders corresponds to the probability adjustment for
    letters over。 here on the left and sounds over here on the right。
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我剪切和粘贴的原因。但这是一个大的界面，让你在这里输入一个字符串，拼写机器学习的单词。然后这些滑块中的每一个对应于左侧字母的概率调整，右侧是声音的调整。
- en: So I can do things like increase the rauticized probability and now we get like
    spurling for。 herring worders， where's her mercier or herring。 Or I can reduce
    the probability or increase the probability of individual letters。 I can get rid
    of the letter E here。 So getting rid of the letter E。 increasing the rauticization
    gives us this weird bizarre， muffled version of this string。
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我可以做一些事情，比如增加带有声音的概率，现在我们得到像spurling这样的herring worders，her mercier或herring。或者我可以减少单个字母的概率或增加概率。我可以去掉这里的字母E。所以去掉字母E，增加带声化给我们这个奇怪而模糊的字符串版本。
- en: I could do something like if we had to do spelling words with machine learning，
    maybe。 increasing the amount of time， subtly increasing the number of h's in here。
    Like what if you had to spell with just like a couple more h's and you usually
    do， you。 can do that by increasing the probability of h's occurring。
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以做类似的事情，比如如果我们需要用机器学习拼写单词，可能是。增加时间，微妙地增加这里的h的数量。比如如果你需要拼写时多几个h，通常这样做，你可以通过增加h出现的概率来实现。
- en: We could do weird stuff to the vowels here， like maybe round all of these vowels。
    So trying to make all of these vowels rounded in just that up a little bit。 Make
    all of it sounds a little bit more bilabial， like using the lips a little bit
    more。 We get spallum， wombers， womphum， plurm， or murmur。
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以对这里的元音做一些奇怪的事情，比如也许把所有这些元音变圆。所以试图让所有这些元音变圆，只需稍微提高一点点。让所有的声音听起来更双唇化，比如更多地使用嘴唇。我们得到spallum，wombers，womphum，plurm或murmur。
- en: An example of what I did with this particular thing is I made a version of Moby
    Dick， where。 the narrator has a head cold by basically removing all of the nasal
    features from the。 text and a couple of other things。 Like if I get rid of all
    of the nasal。 it doesn't really work with this one， sadly。 But you can use this
    to like do strange things with the sounds of the text。
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 我所做的一个例子是制作了《白鲸》的一个版本，其中叙述者有鼻塞，基本上是通过去掉文本中的所有鼻音特征以及其他一些东西来实现的。可惜的是，如果我去掉所有鼻音，这个版本就不能很好地运行。但你可以利用这个去做一些奇怪的声音实验。
- en: A couple more things that I want to talk about with the pencil a model。 The
    next is phoneme states。 So if we go back to， this is my tiny little illustration
    of how the model works。 I'll just copy and paste this down here。 The way that
    the model works again is that it starts with the string。 The string is converted
    into phonemes into the phoneme features and then those phoneme。
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 我想谈谈与铅笔模型相关的另外几件事。接下来是音素状态。因此，如果我们回到，这就是我对模型工作原理的简略插图。我将在这里复制并粘贴。模型的工作方式是，它以字符串开始。字符串被转换为音素，进而转换为音素特征，然后这些音素。
- en: features are converted back to letters and then comes back to the string。 Here
    in the middle there is a vector。 There's a representation in here。 The graphing
    to phoneme model basically compresses the sounds of the word to this vector。 The
    phoneme to graphing model conditioned on this vector produces the spelling of
    the word。
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 特征被转换回字母，然后返回到字符串中。这里中间有一个向量。在这里有一个表示。图形到音素模型基本上将词的声音压缩到这个向量中。音素到图形模型基于这个向量生成词的拼写。
- en: from that list of phonemes。 The vector is called the hidden state of the RNN。
    That hidden state of the RNN is the thing that goes from the graphing to phoneme
    model。 to the phoneme to graphing model。 It's essentially a compressed version。
    It's a compressed representation of the sounds of the word。
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 从那个音素列表中。这个向量被称为RNN的隐藏状态。这个RNN的隐藏状态是从图形到音素模型再到音素到图形模型的转换。它本质上是一个压缩版本。它是词声音的压缩表示。
- en: There's lots of other tasks that you can do with this and I want to， with that
    value。 It's so useful that I actually made a function called phoneme state。 If
    I say pin phoneme state and then pass in a word， like say， allison， it returns
    the hidden。 state of that RNN model。 It's a 256 dimensional vector。 I did like
    dot shape。
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 还有很多其他任务可以用这个做，我想用这个值。它非常有用，以至于我实际上创建了一个名为音素状态（phoneme state）的函数。如果我说音素状态，然后传入一个词，比如说“艾莉森”（allison），它会返回那个RNN模型的隐藏状态。这是一个256维的向量。我进行了点形状（dot
    shape）操作。
- en: You can see that it has 256 values。 From any given phoneme state， you can do
    pin dot spell state。 I'm going to assign this your say， allison state。 Then I
    can spell the allison state from that original state。 This is actually super interesting
    and useful。 One potential application of this is phonetic similarity because two
    words with similar sounds。 will also have similar phonetic states。 I have a couple
    more poetic ideas in mind。
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到它有256个值。从任何给定的音素状态，你可以进行音素拼写状态。我将把这个状态指定为“艾莉森状态”。然后我可以从那个原始状态拼写“艾莉森状态”。这实际上非常有趣且有用。一个潜在的应用是语音相似性，因为两个发音相似的词也会有相似的音素状态。我还有几个更富诗意的想法。
- en: One is interpolation。 If I have two words， let's say paper state， we'll just
    call this state A。 is pin dot phoneme， state for paper。 Then I have state B。 which
    is pin dot phoneme state for plastic。 If I do the midpoint in between those two
    values is state A plus state B divided by。 two。 These are numpy arrays， by the
    way， which is the reason that I can add them and divide。
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 一个例子是插值。如果我有两个词，假设是“纸”（paper）和“状态”（state），我们称这个状态为状态A。这是纸的音素状态。然后我有状态B，这是塑料（plastic）的音素状态。如果我在这两个值之间找到中点，就是状态A加状态B再除以二。这些是numpy数组，正因为如此，我才能对它们进行加法和除法运算。
- en: them using the regular Python operators。 If you're not familiar with numpy。
    that's one of the main reasons to use it。 You can do this matrix math just using
    the regular operator。 Now I can actually spell from that midpoint。 That gives
    me a word that is halfway between paper and plastic。 If I run this again， we get
    a bunch of different variations on this。 Again。
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 使用常规的Python运算符进行运算。如果你不熟悉numpy，那它就是使用的主要原因之一。你可以仅使用常规运算符进行矩阵数学运算。现在我实际上可以从这个中点拼写出来。这样可以得到一个在“纸”和“塑料”之间的词。如果我再运行一次，我们会得到很多不同的变体。
- en: there's some randomness involved。 We get this word helper。 which is kind of
    a plausible word that's halfway between paper， and plastic。 I'm just going to
    copy in another example from the big notebook。 Here I have a whole bunch of word
    pairs。 Paper plastic， kitten puppy， birthday anniversary。
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 这里涉及一些随机性。我们得到了这个单词助手，它是介于纸和塑料之间的一个合理单词。我将从大笔记本中复制另一个例子。在这里，我有一堆单词对。纸塑料，小猫小狗，生日周年。
- en: artificial intelligence， Allison parish， most of this middle-town day， January，
    December。 This code does the same thing that we're doing up here， but iterating
    over all of these pairs。 You can modify this and make a place to put in your own
    if you want to experiment with。 other things。 It gets the midpoint between the
    two states， spells from that state。
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能，艾莉森·帕里什，大部分是在米德尔镇的日、1月、12月。这个代码做的事情和我们在这里做的一样，但迭代所有这些对。你可以修改这个，并创建一个地方来放入自己的内容，如果你想尝试其他东西。它获取两个状态之间的中点，从那个状态拼写。
- en: and then displays， results。 Allison， Eresh and Parrish， Moses， Middletown， Middletown，
    Day， Day。 Day， Day， January， then Super， December。 The model can give you this
    halfway point between these two things because you can solve。 from arbitrary points
    in that space。 It doesn't do so great。 You can do numpy。 we've seen that random
    uniform function before。 That gives us a uniform random number。
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 然后显示结果。艾莉森、埃雷什和帕里什、摩西、米德尔镇、米德尔镇、日、日。日、日、1月，然后是超级、12月。这个模型可以为你提供这两者之间的中间点，因为你可以从空间中的任意点进行解决。它做得不是很好。你可以使用numpy。我们之前见过那个随机均匀函数。它给我们一个均匀的随机数。
- en: and if I say size equals 256， this gives us a， 256 dimension random number。
    You can try spelling from a random number。 That's actually not bad。 This is for
    i and range。 Let's just make tall of these and then print these out。 This is printing
    12 randomly generated numbers or randomly generated words based on just picking。
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我说大小等于256，这将给我们一个256维的随机数。你可以尝试从随机数中拼写。这其实还不错。这是针对`i`和`range`的。让我们将这些全部制作出来，然后打印出来。这是在打印12个随机生成的数字或基于随机选择的单词。
- en: a uniformly distributed random number in the space。 It's not great。 That's because
    the distribution of the values in the actual model's spelling space don't。 follow
    a uniform distribution。 They don't actually follow any distribution that's explicitly
    modeled。 A little bit of a better match would be a normal distribution。 I did
    normal instead of uniform here。
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个空间中均匀分布的随机数。效果不是很好。这是因为实际模型拼写空间中值的分布并不遵循均匀分布。它们实际上不遵循任何明确建模的分布。稍微更好的匹配可能是正态分布。我在这里使用了正态而不是均匀。
- en: We're going to get some more variation in these。 We're getting nice random words。
    There are also important parts of the distribution of this hidden state that fall
    outside of that。 normal distribution。 But regardless， this is showing you here's
    how you can generate random words based on。 picking a random number from a normal
    distribution。
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 我们会在这些中获得更多变化。我们得到了一些不错的随机单词。还有一些重要部分的隐藏状态分布超出了那个正态分布。但无论如何，这向你展示了如何根据从正态分布中选择的随机数生成随机单词。
- en: Another thing that we can do is if I were to do something like state for s in，
    if I did， like pin。phoneum state for a word in， let's make a small text。 Let's
    actually go back to April is the cruelest month reading lilacs out of the， this，
    that。 how it goes。 I forgot。 Let's go back。 Where did I get that from？ The pronouncing
    tutorial。 Yeah。
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 另一件我们可以做的事情是，如果我做类似`for s in`的事情，如果我做，比如`phoneum`状态针对一个单词，让我们做一个小文本。让我们实际回到“四月是最残酷的月份，拔出丁香”，这个，那个。怎么说来着。我忘了。让我们回去。我是从哪里得到那个的？发音教程。是的。
- en: that's close enough。 I think that's exactly what I just did。 There's text。 If
    we were to do something like this， this is grabbing the phoneme state for each
    one。 of those words in the text， splitting it out。 We can make this whole thing
    into an umpire。 Text state。 Text state。shape。 So now what we have is an array
    that has one row for each one of the words in the text。
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 这差不多了。我想这正是我刚刚做的。这里有文本。如果我们做类似这样的事情，这将为文本中每个单词抓取音素状态，并将其分开。我们可以把整个东西变成一个仲裁者。文本状态。文本状态。形状。所以现在我们拥有的是一个数组，其中每一行对应文本中的一个单词。
- en: and then the columns or the 256 values of the phoneme state。 So again。 we have
    the situation where we have an array that actually we can manipulate as。 though
    it was an audio file or an image file or whatever。 We could do something like
    zoom that text state array and now I want it to be half of， its size。
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 然后是音素状态的256个值。因此，我们有一个可以像音频文件或图像文件那样操作的数组。我们可以对该文本状态数组进行缩放，现在我希望它的大小减半。
- en: The second value in the zoom by the way is the zooming on the second dimension。
    We want that to stay the same because the hidden state has to be 256 dimensions。
    This is going to give me a new array that is half as long as the original array
    but has。 all of the same phonetic information compressed into it。 What I would
    do at that point is pin。
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放的第二个值顺便提一下是在第二个维度上缩放。我们希望它保持不变，因为隐藏状态必须是256维。这将给我一个长度是原始数组一半的新数组，但所有的音韵信息都被压缩进来了。那时我会执行pin。
- en: spellState item for item in that zoom。 This is going to give me basically a
    compressed representation of the sound in all of the text。 So now the sounds from
    words that are next to each other are actually getting compressed。 into each other。
    So April is the cruelest month。 Being lilac out of the dead becomes April demon
    fly lack off dead。 If we double the size then we're going to get a text that is
    twice as long。
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: spellState项目用于缩放中的每个项目。这将基本上给我一个文本中声音的压缩表示。因此，现在相邻单词的声音实际上被相互压缩了。四月是最残酷的月份。由死亡中开出紫丁香变成了四月的恶魔。
    如果我们将大小加倍，那么我们将得到一个长度是原来两倍的文本。
- en: This actually works better if you use the interpolation order。 So now we have
    a new text where the sound of words based on its phoneme state is getting。 spread
    out across adjacent words。 So April is ish the cruelest， cruelest month reading。
    Breeding lilac slide。 Lacks out out of the dead。 So snearing the sound across
    a longer sequence of words。
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 如果使用插值顺序，实际上效果会更好。所以现在我们有一段新文本，其中单词的声音根据其音素状态在相邻单词之间扩散。因此四月是最残酷的，最残酷的月份。繁殖紫丁香滑动。缺失从死亡中。让声音在更长的单词序列中扩散。
- en: I'm going to paste an example from the notes。 Again。 an interactive example
    just to show you what that looks like。 Or you can type in a phrase and then resize
    it。 Compressing that whatever you type in here like alison。 parish， picon， workshop。
    Increasing that to be alison， alison， parish， parish， pecan， pecan， pixon。
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 我要粘贴一个来自笔记的示例。再一次，这是一个交互式示例，只是为了向你展示那是什么样子。或者你可以输入一个短语，然后调整其大小。压缩你在这里输入的内容，比如阿里森。教区，山核桃，研讨会。将其增大为阿里森，阿里森，教区，教区，山核桃，山核桃，派克森。
- en: workshop， workshop， or smushing it all the way down to maybe half the size。
    Alison workshop is all it does。 Alison， parish， workshop， alison， parish， pecan，
    workshop。 So you can do the same thing where you're smushing the values back and
    forth。 The final example that I want to show you with a pencil aid is a phonetic
    variation。
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 研讨会，研讨会，或者将其全部压缩到可能是原来一半的大小。阿里森的研讨会就是这样。阿里森，教区，研讨会，阿里森，教区，山核桃，研讨会。因此，你可以做同样的事情，将值来回压缩。最后一个例子我想用铅笔帮助你展示的是音韵变体。
- en: So I showed just a second ago that you can generate random words by sticking
    random values。 into that feature vector。 And we can see that it doesn't produce
    very good results。 And as good as results， I would want at least a way to make
    this work a little bit better。 is adding a random number to the phoneme state
    for an existing word。
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 我刚刚展示了你可以通过将随机值放入特征向量来生成随机单词。我们可以看到它并没有产生很好的结果。为了获得更好的结果，我至少想找到一种方法来让这个工作得更好，那就是为现有单词的音素状态添加一个随机数。
- en: So if we made something like a setter string to Python， and then we can get
    the state by。 doing pin dot phoneme state for that string。 And then we can add
    a bit of noise to it by doing state plus NumPy random random n is。 a normally
    distributed random number with the number of dimensions that you specify there。
    And then spell from that state， pin dot phoneme or spell state。 Noisey， noisy
    state。
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们创建一个类似于Python的setter字符串，我们可以通过执行pin.dot音素状态来获取该字符串的状态。然后我们可以通过执行状态加上NumPy
    random random n来添加一些噪声，这个n是你指定的维度的正态分布随机数。然后从那个状态拼写，pin.dot音素或拼写状态。嘈杂的状态。
- en: If I keep on running this， I get like essentially variations on the word Python
    adding random。 values to it。 If I do this in a for loop for I and range 10 and
    then print this out。 We get these like Python， but with like a little bit of noise
    applied to it， we can control。 the amount of noise actually by like multiplying
    that randomness by a vowel。 So now with point one。
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我持续运行这个，我会得到 Python 一词的变化，随机值被添加到其中。如果我在一个 for 循环中执行这项操作，比如 `for i in range(10)`，然后打印出来，我们得到这些类似于
    Python 的词，但有一些噪音添加到其中。我们可以通过将随机性乘以元音来控制噪音的量。因此现在是 0.1。
- en: we get sort of just like a couple of small variations。 I point to five。 I get
    a bit more variation at six， six， seven， we begin to get like， path。 in and Python
    and pithman and stuff like that。 If I take it all the way， obviously to like two。
    that nice or kidding things where you， can still kind of tell that maybe Python
    was in there to begin with。
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了一些小的变化。我将其设置为五。我在六和七的时得到更多变化，我们开始得到像 path、Python 和 pithman 这样的东西。如果我把它全部设置为两个，显然会得到一些不错的东西，你依然可以辨别出可能最开始是
    Python。
- en: but like so much weirdness， has been added to it that you can't tell it anymore。
    The final example in the in the example notebook is this interactive example that
    has the same。 code where we're adding the value to the string。 But now we can
    do it on multiple words and then also control the multiplier using the。 slider。
    So if you take it all the way down and just tries to spell it as well as it can
    from the。
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 但是添加了太多奇怪的内容，以至于你无法再辨别了。在示例笔记本中的最后一个例子是这个交互式示例，它使用相同的代码，我们在字符串中添加值。但现在我们可以对多个单词进行操作，并使用滑块控制乘数。因此，如果你将其调整到最低，只能尽量拼写出最好的结果。
- en: original string， we can move it all the way up to two and we get just like weirdness。
    We can change the seed， the random seed， which essentially picks the normal values
    that we。 add to it， making sure that the same normal value is applied to everything
    in the string。 to see what different variations look like inside of there。 Like
    that。
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 原始字符串，我们可以将其调整到两个，结果就像是一些奇怪的内容。我们可以更改种子，也就是随机种子，这基本上选择了我们要添加的正常值，确保同样的正常值应用于字符串中的所有内容，以查看里面不同变体的样子。就像那样。
- en: So the goal of this again was， you know， have this model that allows us not
    just to work。 with words in the pronouncing dictionary that aren't in the pronouncing
    dictionary， they're。 outside of the vocabulary of the CMU pronouncing dictionary，
    but also be able to take all of。 those rich representations that are inside of
    the machine learning model and see if we。
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 所以再次强调，这个模型的目标是，不仅能处理发音词典中不存在的单词，它们超出了 CMU 发音词典的词汇范围，还能利用机器学习模型中的所有丰富表示，看看我们能否做到。
- en: can like push them around and manipulate them and do strange stuff to them to
    give us like。 the ability to modify the way that words sound outside of the realm
    of like how words are。 usually spelled。 Okay， so the last thing that I want to
    show you is some applications of both pronouncing。 and pencil it using them both
    together to find and generate poetry based on existing corpora。
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以对这些词进行调整、操控，并做一些奇怪的事情，从而使我们能够修改词的发音，超出通常拼写的范围。好的，我最后想给你展示的是发音和 Pencil 的一些应用，利用它们共同找到和生成基于现有语料的诗歌。
- en: of text。 So I'm calling this corpus driven approaches。 This is in the code from
    this is in the third notebook in the GitHub repository。 So to get started here，
    I'm just going to import a bunch of the libraries that we've been using。 so far
    from pencil eight import to pencil eight。 We're also going to need NumPy import
    NumPy as NP。
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 文本。因此，我将其称为基于语料库的方法。这段代码来自 GitHub 仓库的第三个笔记本。为了开始，我将导入一些我们到目前为止使用的库。所以从 Pencil
    Eight 导入 Pencil Eight。我们还需要导入 NumPy，使用 `import NumPy as NP`。
- en: And we're going to need an LTK the natural language toolkit that should be installed
    with。 the requirements。txt。 And we'll need a couple of things from the Python
    standard library。 regular expressions， and randomness。 So I'm going to load up
    that pencil eight model first。 So for this to work， but what I want to be able
    to do is actually a couple of things。
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一个自然语言工具包 LTK，它应该和 requirements.txt 一起安装。同时，我们还需要一些来自 Python 标准库的东西，包括正则表达式和随机数。因此，我会先加载那个
    Pencil Eight 模型。为了使这项工作顺利进行，我想能够做几件事情。
- en: I want to be able to look up the pronunciation of any given word。 Now it's faster
    to do this with the pronouncing library because it just has to look it up in。
    a dictionary as opposed to pencil eight where it needs to actually go through
    the prediction。 and inference process for any word。 So I'm going to write a function
    here that's sort of a hybrid between the two call those。
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望能够查找任何给定单词的发音。现在，使用发音库来做这件事更快，因为它只需在字典中查找，而不是使用pencil eight，它需要实际进行预测和推理过程。因此，我将写一个在这两者之间的混合函数。
- en: quick phones。 But it's going to check first to see if the word is in-- thumbs
    for word。 If that word is in pronouncing， if it's not in pronouncing， then we're
    going to look it。 up in-- we're going to do the prediction process with pencil
    eight。 So this is just going to save a little bit of time when we're doing that--
    when we're。
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 快速查找。但是它会先检查这个单词是否在——thumbs for word。如果这个单词在发音中，如果不在发音中，那么我们会在——我们将进行带有pencil
    eight的预测过程。所以这在我们进行查找时会节省一点时间。
- en: doing lookups or words。 So what I'm doing here is I'm just writing a little
    regular expression that's going to。 strip out any characters that aren't in the
    pencil eight model from the word that's passed。 in and then it's going to return
    the result of doing the pencil eight sounding out process。 for that token。 Otherwise，
    it's just going to return the first pronunciation from that-- from pronouncing。
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我在这里做的就是写一个简单的正则表达式，去除输入单词中任何不在pencil eight模型中的字符，然后返回这个标记的pencil eight发音过程的结果。否则，它会返回发音中的第一个发音。
- en: So I'm just going to test this out really quick。 Quick phones should work with
    cheese。 should be really quick。 Or it's-- it actually has to load the pronouncing
    data file first。 So it's not quick on the first time。 But if I do quick phones
    pQ。 then it's actually like doing that sounding out with pencil eight， so it takes
    a little bit longer。
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我只是想快速测试一下。快速查找应该与cheese一起工作，应该非常快速。或者它实际上必须首先加载发音数据文件。所以第一次并不快速。但是如果我做快速查找pQ，那么实际上就是用pencil
    eight进行发音，所以需要更长的时间。
- en: So this is just going to make it possible instead of like having to do this
    if else thing。 and every single time we want to look up a word， this function
    just like collapses the。 two of them into the same function。 So since we're working
    with pre-existing texts。 one of the things we're going to have to do， is divide
    those texts up into meaningful units like sentences and words。
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是让我们能够实现这一点，而不必使用如果-否则的方式。每次我们想查找一个单词时，这个函数就会把这两个过程合并成一个。所以由于我们正在处理现有文本，我们需要做的一件事情是将这些文本分成有意义的单元，比如句子和单词。
- en: In order to do that， we need something called a tokenization function。 A tokenization
    function is you put a string in， it goes into the function， and then what。 you
    get back is a list of tokens。 And those tokens might be words， they might be sentences。
    it might be words along with， punctuation， stuff like that。
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，我们需要一个称为分词函数的东西。分词函数是你输入一个字符串，它进入函数，然后返回一个标记列表。这些标记可能是单词，可能是句子，可能是带有标点符号的单词等。
- en: Splitting text up into words is more complicated than you might think it is，
    if you've never。 done that task before in a way that's well-motivated。 We can
    just split on whitespace but that keeps the punctuation attached to the words。
    We could split using regular expressions but that sometimes doesn't capture all
    the nuances。
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 将文本拆分成单词比你想象的要复杂，如果你以前没有以合理的方式做过这个任务。我们可以简单地根据空格拆分，但那样会把标点符号与单词连在一起。我们可以使用正则表达式进行拆分，但有时这并不能捕捉所有的细微差别。
- en: of what is a word and what is a word。 So just to give us a baseline for that
    we're going to use NLTK。 NLTK has a two functions of use to us。 One is sent to
    tokenize where you pass in a string and it returns a list of sentences。 the other
    is word tokenize where you pass in a string and it returns a list of words。 So
    we're going to use those two things。 In order to use those though you have to
    download a particular corpus to use with the。
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是单词，什么不是单词。为了给我们一个基线，我们将使用NLTK。NLTK有两个对我们有用的函数。一个是sent tokenize，你传入一个字符串，它返回一个句子列表。另一个是word
    tokenize，你传入一个字符串，它返回一个单词列表。因此，我们将使用这两样东西。不过，要使用它们，你必须下载一个特定的语料库。
- en: NLTK library， you should just be able to run that line and it's going to download
    that。 package and install it on your computer。 I've already done that so it doesn't
    actually do anything。 Unfortunately there isn't really a good way to tell PIP
    to do this step when installing。 a requirement。txt so you have to do it by hand。
    But now we have this function。
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: NLTK库，你只需运行那一行，它就会下载并安装该包到你的计算机上。我已经做过了，因此实际上并不执行任何操作。不幸的是，没有好的方法告诉PIP在安装时执行这一步*requirement.txt*，所以你必须手动完成。但现在我们有了这个功能。
- en: NLTK sent tokenize and I can write in some text here。 This is a test。 My mother，
    Mrs。 Parish said that e days， I think these， I just want to show you that this，
    works。 So it gives us these two sentences based on that text。 Even though like
    a more naive sentence tokenizer might stop on these periods and think， oh。
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: NLTK发送了标记化，我可以在这里写一些文本。这是一个测试。我的母亲，帕里什夫人说这些天，我想这些，我只是想给你展示这个，*有效*。所以它根据这些文本给我们这两个句子。即使像一个更简单的句子标记器可能会在这些句号处停止，并认为，哦。
- en: that's the end of the sentence。 NLTK is sentence tokenizer， notice how to do
    that。 Likewise， NLTK。word tokenize， we pass in a text。 It was the best of times。
    It was the worst of times。 This returns all of the words in that text and it slits
    at the punctuation and separates。 tokens as well。 So that's nice to have it。 It'll
    just let us work with these corpus in a way and just have like one single function。
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 这是句子的结束。NLTK是句子标记器，注意如何做到这一点。同样，NLTK的*单词标记化*，我们传入一个文本。*这是最好的时代。这是最糟糕的时代。*这将返回文本中的所有单词，并在标点符号处分割并分开令牌。因此，这样的功能非常好。它只会让我们以一种方式处理这些语料库，并且只需一个函数。
- en: we can use to get stuff out of it。 So our first task is going to be finding
    haiku in an existing text。 This in the notes I've linked to a paper from 1967
    about computer generated haiku。 The sense to be like a go to task for people in
    the classes that I teach about computer。 generated poetry。 It's sort of a classic
    problem in computational poetry is how to generate haiku。
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用来提取内容的。因此我们的第一个任务是从现有文本中寻找俳句。在笔记中我链接了一篇关于计算机生成俳句的1967年的论文。这似乎是我教关于计算机生成诗歌的课程中人们的首选任务。在计算诗歌中，生成俳句是一个经典问题。
- en: The method that we're going to do is we're going to look through an existing
    text and。 see if we can find sentences that are also haiku。 So we need to find
    sentences that are 17 syllables long。 And those syllables have to break down in
    a particular pattern 5， 7， 5 without having。 any word breaks in between。 That's
    the definition of haiku that we're going to use for this experiment。
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要做的方法是查看现有文本，看看能否找到也符合俳句的句子。因此我们需要找到17个音节长的句子。而且这些音节必须以特定的模式5、7、5分解，中间不能有任何单词的断裂。这是我们将用于本实验的俳句定义。
- en: The traditional Western English language haiku is just a poem that consists
    of three lines。 the first with five syllables， the second with seven syllables，
    the last with five syllables。 Without those words， the syllables being spread
    across more than one line。 So we have two tasks。 One is a syllable counting task，
    which is need to be able to count 17 syllables。
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的西方英语俳句仅由三行诗组成，第一行为五个音节，第二行为七个音节，最后一行为五个音节。没有这些词，音节会分布在多行上。因此我们有两个任务。一个是音节计数任务，需要能够数出17个音节。
- en: The second is to check to make sure that those 17 syllables can be broken down
    across this， pattern。 So I have a function that I put into the notes and this
    isn't really like a tutorial on writing。 functions to break down lists into other
    lists。 So I'm just going to paste it in。 This is a。 this is called partition haiku。
    And basically what it does。
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个是检查这17个音节是否可以按照这个模式分解。因此，我在笔记中放入了一个函数，这实际上并不是一个关于编写函数将列表分解为其他列表的教程。所以我将直接粘贴。这是一个，称为*分区俳句*。基本上它的作用是。
- en: you give it a list of works like this partition haiku。 You give it a list of
    syllable counts。 So like three， two， four， three， one， one， three。 And then what
    it's going to do is it's going to check does this add up to 17。 And if it does
    add up to 17， can these numbers be evenly spread across three lines consisting。
    of exactly five， seven and five lines？ And it does this basically by like continuing
    to take more syllables until it reaches the。
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 你给它一个像这样的*分区俳句*的工作列表。你给它一个音节计数列表。比如三、二、四、三、一、一、三。然后它将检查这些是否加起来是17。如果加起来是17，这些数字能否均匀分布在包含恰好五、七和五行的三行中？它基本上是通过继续取更多的音节直到达到这个。
- en: needed count。 If it goes over and needed to count， then it， then it fails。 So
    this is a valid haiku。 And what this is doing is it's telling you after which
    indices should you split this list。 in order to end up with the， with the haiku
    itself。 So this， if we split after index one。 that gives us the first line after
    index three， gives us the second line。
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 需要的计数。如果超过了并需要计数，那么它就失败了。因此，这是一个有效的俳句。这告诉你应该在什么索引之后分割这个列表，以便得到俳句本身。所以如果我们在索引一之后分割，这会给我们第一行，在索引三之后，给我们第二行。
- en: And then after index six or the end of the list gives us the third line。 As
    a famous haiku in English letters， is this I forget who wrote this exactly。 I
    should probably find out the west wind， whisperge and touch。 The eyelids of spring，
    her eyes。 premises。 So that's our haiku。 If we wanted this syllable count for
    each word in this haiku。
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 然后在索引六或列表的末尾给我们第三行。一个著名的俳句用英文字符是，我忘了确切是谁写的。我应该找到的《西风》，低语和触碰。春天的眼睑，她的眼睛。前提。所以这就是我们的俳句。如果我们想要这个俳句中每个单词的音节计数。
- en: we might do something like， pronouncing dot syllable count for quick phones
    of each individual word for word in haiku。 dot split。 And this tells us the number
    of syllables in each word in that poem。 We'll do this like breakdown， just like
    that。 And then partition haiku passing in that list should tell us where the line
    break should。 go after which index the line break should go in order to form this
    haiku and this tells。
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能会做一些事情，比如，为俳句中的每个单词逐个计算音节。然后分割。这告诉我们那首诗中每个单词的音节数量。我们将像这样进行分解。然后分割俳句，传入该列表应该告诉我们在哪里进行换行。换行应该在什么索引之后进行，以形成这个俳句。
- en: us after index three zero one two three。 That's right。 And then after index
    nine four five six seven eight nine。 That's right。 And then after index twelve
    which of course would be the end of the haiku。 If we pass in some list of numbers
    like you know five nine twelve four two two one。
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 在索引三零一二三之后。没错。然后在索引九四五六七八九之后。没错。然后在索引十二，这当然是俳句的结尾。如果我们传入一些数字列表，比如五九十二四二二一。
- en: This returns an empty list because this cannot be partitioned into aiku。 It
    has more than seventeen syllables。 But we also if we did something that does have
    seventeen syllables that wouldn't be neatly。 partitioned。 So if we did like a
    one syllable word followed by a six syllable word followed by a five followed。
    by a five。 This is seventeen syllables but we can't break it up evenly into a
    haiku。
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 这返回一个空列表，因为这无法分割成俳句。它有超过十七个音节。但如果我们做一些确实有十七个音节的内容，而不是整齐的分割。所以如果我们做一个单音节单词后跟一个六音节单词，再跟一个五音节，再跟一个五音节。这是十七个音节，但我们不能均匀地将其分割成俳句。
- en: This would the end of the first line would fall in the middle of this word。
    So this isn't a valid haiku according to our criteria。 Right。 So this partition
    haiku is going to tell us where to put the line a where to put the line。 breaks
    in B whether it can be a haiku at all。 The way we're going to get the syllable
    count is like this using the pronouncing syllable。
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 第一行的结束将落在这个单词的中间。所以根据我们的标准，这不是一个有效的俳句。对吧。因此，这个分割俳句将告诉我们在哪里放置行，在哪里放置换行，在B中是否可以成为俳句。我们获取音节计数的方式是这样的，使用发音音节。
- en: count using the phonemes that come back from the quick phones model。 So we're
    going to load in a source text。 This text is included in the repository if you
    cloned from there。 You can do this with any text as long as it's in plain text
    format。 This is the project Gutenberg version of Frankenstein by Mary Shelley
    if we just did like text。
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 使用来自快速发音模型的音素计数。因此，我们将加载一个源文本。这个文本包含在你从那里克隆的代码库中。只要是纯文本格式，你可以使用任何文本。这是玛丽·雪莱的《弗兰肯斯坦》的古腾堡项目版本，如果我们仅仅像文本那样处理。
- en: Let's look at the first two hundred characters of that。 Project Gutenberg's
    Frankenstein by Mary Wilson craft Godwin Shelley。 So we're going to try to find
    haiku inside of Frankenstein。 And the way that we're going to do that is I'm going
    to get all of the sentences in the。
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看前两百个字符。古腾堡项目的《弗兰肯斯坦》由玛丽·威尔逊·克拉夫特·戈德温·雪莱编写。所以我们要在《弗兰肯斯坦》中寻找俳句。我们要做到这一点的方法是获取所有的句子。
- en: text using an LTKA dot sent tokenize。 The text。 There are not an LKT but an
    LTKA。 There are how many sentences。 There are almost 3200 sentences according
    to an LTKA in Frankenstein。 Now what we're going to do is sift through these sentences。
    And I'm going to write like a simple example of doing this and we're going to
    build to the。
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LTKA点句子分词。文本。并不是LKT，而是LTKA。有多少个句子。根据《弗兰肯斯坦》，几乎有3200个句子。接下来我们将筛选这些句子。我将写一个简单的示例来展示这一点，然后我们将逐步构建。
- en: haiku example。 But the first thing I'm going to do is this。 So for sent in sentences。
    I'm just going to see if we can find all of the sentences that， are 17s， a little
    walls long。 That gets us most of the way to knowing if they're haiku not quite
    all the way but this。 is just so we can see most of the parts working together。
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 俳句示例。但是我首先要做的是这个。对于句子中的每一个句子。我只是想看看我们是否可以找到所有17个的句子，这样我们就大致知道它们是否是俳句，虽然还不完全，但这只是让我们看到大部分部分一起工作。
- en: So the first thing I'm going to do is I'm going to convert this sentence to
    lowercase。 and also the sent tokenize leaves all of the new line characters or
    of the plain text format。 is going to leave all those new line characters in place。
    And sent tokenize doesn't get rid of them so I want to get rid of those。
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我将做的第一件事是将这个句子转换为小写。而且句子分词会保留所有换行字符或纯文本格式。所以我想去掉这些换行符。
- en: I'm just going to place every new line with the space。 And then I'm going to
    get the pronunciations or I'm going to get all of the words in that， line。 So
    word for a word in NLTK。word。tokenize in that sentence but only if the first character。
    in it is often numeric。 And this is just sort of my basic test to make sure that
    it's not punctuation。
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 我将把每个换行符替换为空格。然后我将获取发音，或者获取该行中的所有单词。因此，在那句话中，每个单词通过NLTK.word.tokenize处理，但仅当第一个字符通常是数字时。这只是我基本的测试，以确保它不是标点符号。
- en: Again when we look at the word tokenize function it returns these punctuation
    as individual， tokens。 I don't want to include those in our account。 Our haiku
    aren't going to take account of the intermediary punctuation so I'm just going。
    to leave them out altogether。 So this is going to be all of the words in all of
    the sentences。 Now I'm going to get those syllable counts by doing pronouncing
    dot syllable count。 Count。
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们查看单词分词功能时，它会将这些标点符号作为单独的标记返回。我不想把它们算在内。我们的俳句不会计算中间的标点符号，所以我将完全忽略它们。这将是所有句子中的所有单词。现在我要通过发音.音节计数来获取那些音节计数。
- en: I can spell。 Using that quickphones function for that word， for every word in
    words。 And then I'm going to say if the sum of that syllable count， because again
    this is going。 to be a list with the number of syllables in each word in that
    sentence。 So we're going to say if that sum is equal to 17 then we'll just print
    out the sentence。
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以拼写。利用这个快速拼音功能来处理每个单词。然后我将查看每个句子中音节的总数。如果音节总数等于17，那么我们就打印出这个句子。
- en: and then see what happens。 So no， what did I do wrong？ Syllable counts。 What
    else did I do wrong？
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 然后看看会发生什么。那么，我做错了什么？音节计数。我还做错了什么？
- en: Key error 8。 What？ Why did that happen？ That's so weird。 How did we end up with
    an 8 in one of these strings that doesn't make any sense at all？
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 键错误8。什么？为什么会发生这种情况？这太奇怪了。我们怎么会在这些字符串中得到一个8，这完全没有意义？
- en: Let's just print out， let's do a little bit of debugging here。 Words， Project
    Gutenberg， UTF-8。 if w is alpha。 I must have done something weird here because
    this works in my example notebook but it doesn't。 work here。 Let's see what I
    can do to fix this up really quick。 We'll say if the first character is alpha
    it's clearly getting messed up on UTF-8 right， here。
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们打印出来，做一点调试。单词，古腾堡计划，UTF-8。如果w是字母。我肯定在这里做错了什么，因为这个在我的示例笔记本中有效，但在这里不行。让我看看如何快速修复这个。我们会说如果第一个字符是字母，那么在UTF-8上显然出错了。
- en: So I want to say and then and re。search。 We'll just make sure that it's all
    A through Z。 One or more of those characters to the end。 That's probably how I
    had it originally。 So it's just going to exclude any word that has a number in
    it。 That's not perfect either because we're going to leave out years and stuff
    like that。
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我想说然后再搜索。我们只需确保所有的字母都是A到Z。这些字符中的一个或多个在末尾。这可能就是我最初的设定。所以这将排除任何含有数字的单词。这也不完美，因为我们会遗漏年份和类似的东西。
- en: It should work。 We can test some of these as we're going。 As I spoke a dark
    gloom spread over my lists and nerves， countenance。 Is that right？
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该可以工作。我们可以在进行时测试一些。当我说话时，一种黑暗的忧郁弥漫在我的清单和神经、面容上。这是对的吗？
- en: I might have gotten messed up on this bad quote。 That shouldn't even have been
    included。 She was not her child but the daughter of a Milanese nobleman。 That's
    19 syllables。 No human being could have passed a happier childhood than myself。
    That's 17。 This is mostly right。 It's doing some weird stuff but this is mostly
    doing the thing that I wanted to do。
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 我可能在这个糟糕的引用上搞错了。这本来不应该包括在内。她不是她的孩子，而是米兰一个贵族的女儿。这是19个音节。没有任何人能度过比我更快乐的童年。这是17个音节。这大部分是正确的。它做了一些奇怪的事情，但这基本上达成了我想要的效果。
- en: I don't need to see the rest of them but you can get the idea。 So I'm interrupting
    that。 To make sure that these are haiku， we need to do an additional step which
    is tokenize these。 words and then get this a little count and see if we can partition
    it into a haiku。 If we can。 then we'll print it out adding in line breaks after
    each of the lines and， then print them out。
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 我不需要看到其他的，但你可以理解这个意思。所以我在这里打断一下。为了确保这些是俳句，我们需要做一个额外的步骤，即对这些单词进行分词，然后计算一下，看看我们能否将其分成俳句。如果可以的话，我们就会打印出来，在每行后添加换行符，然后输出它们。
- en: If we can't， then we'll just continue。 The thing that that's going to look like
    is for sentence in sentences。 Again we're going to convert the sentence to lowercase。
    And then we're going to get our list of words。 I'm just going to copy and paste
    the thing to work to here。 Do do do。 Sline right here to get us the words in the
    sentence。
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们不能，那我们就继续。那看起来像是对句子中的每个句子。我们将把句子转换为小写。然后我们将获得我们的单词列表。我只想复制并粘贴到这里。这里的行将获得句子中的单词。
- en: And then I'm going to do a little try except thing here and I'm going to try
    first of all。 to get the syllable counts which I'm going to do the same way before
    pronouncing dot syllable。 count。 Quickphones for the word for W in words。 And
    then I'm going to say line breaks equals partition haiku。 I'm passing in those
    syllable counts。 Now if the length of the line breaks is greater than zero。
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我将做一个小的try except，我将首先尝试获取音节计数，我将用之前的方法进行，使用pronouncing.dot.syllable_count。快速计算每个单词W的音节。然后我将说换行符等于分段俳句。我将传入这些音节计数。现在如果换行符的长度大于零。
- en: then what I want to do is I want， to print out that haiku but I want to print
    it out as an actual haiku。 I'm going to say out equals join together the result
    of printing either the word or the。 word plus a line break。 If I is in the line
    breaks else。 just an empty space between each word for I W in enumerate， words。
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我想要做的是打印出那个俳句，但我想要以实际的俳句形式打印出来。我将说输出等于将打印的结果连接起来，无论是单词还是单词加上换行符。如果I在换行符中，否则就是在每个单词之间留空格，针对每个I
    W在枚举的单词中。
- en: So the line breaks gives us the indices in the array of words where the line
    break should， occur。 So this is just sort of a tricky way of saying like look
    at each word in the line。 If the index of that word that we get from using enumerate
    over here is in that line breaks。 then append a new line to it otherwise don't
    append anything。
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 所以换行符为我们提供了单词数组中应该出现换行符的索引。这只是有点狡猾的方式，意思是看看行中的每个单词。如果我们使用这里的枚举得到的那个单词的索引在换行符中，那么就添加一个新行，否则不添加任何东西。
- en: I forget why I put this try except in here now even though it's in my notes。
    So in sub to index error， I continue。 So if any point in here。 it can't get any
    of this stuff and it's just going to exit。 So I'm going to run this now and we'll
    see what happens。
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 我忘了为什么我在这里放了这个try except，尽管它在我的笔记中。所以在子程序中如果出现索引错误，我将继续。所以在这里的任何时候，如果它无法获取这些内容，它就会退出。所以我现在要运行这个，我们看看会发生什么。
- en: Usually when it happens like this and I'm not sure it's working， I'll do this
    little trick。 where I'm already using I down here。 So I'm going to do current
    sense in enumerate sentences。 And just to print current。 And I could also bring
    in TQDM or something like that but let's just make sure that it。 is in fact coming
    through these lines。 And I'll double check my code while I'm doing this。
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 通常当事情这样发生而我不确定它是否有效时，我会做这个小把戏。我在下面已经使用了I。所以我将做“当前感”来枚举句子。只是打印当前。我也可以引入TQDM之类的，但我们先确保它确实通过这些行。我会在做这个时仔细检查我的代码。
- en: It's a little count， so we're going to do it for words because I feel like it
    should。 have found one already。 Line Breaks is partitioned Iku with solable counts。
    Length of line Breaks is greater than zero。 Yeah， I feel like you definitely should
    have found one by now。 So just I'm going to debug a little bit more here。 Print
    words。 That looks right。
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个小计数，所以我们将对单词进行处理，因为我觉得它应该已经找到一个了。换行符是带有可音节计数的分区Iku。换行符的长度大于零。是的，我觉得你现在绝对应该找到了一个。所以，我将在这里调试一下。打印单词。这看起来不错。
- en: Print solable counts。 That also looks right。 And print line Breaks。 Ah boy。
    all this sometimes happens。 Yeah， that should have gone right there。 So what did
    I do wrong？ Oh。 I forgot to print it。 All right。 So sorry， it's getting close
    to the end of the day here folks。 All right， so here we have our Iku。 This expedition
    has been the favorite dream of my early years。
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 打印可音节计数。这看起来也没错。然后打印换行符。啊，天哪，这一切有时会发生。是的，应该正好在那里。那么我做错了什么？哦。我忘记打印了。好吧，抱歉，今天快到结束了，朋友们。好吧，我们有我们的Iku。这次探险是我早年最喜欢的梦想。
- en: Iku， remember me with affection。 Should you never hear from me again？
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: Iku，带着深情记住我。如果你再也听不到我的消息？
- en: No human being could have passed a happier childhood than myself。 So it's going
    to go through Frankenstein and find all of those。 Iku。 now we could develop this
    a little bit more from a number of different stand points。 One is we threw out
    all of the punctuation and the uppercase and stuff like that when we did。
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 没有任何人能够度过比我更快乐的童年。所以它会通过《弗兰肯斯坦》找到所有那些。我ku。现在我们可以从多个不同的角度稍微展开一下这个。一个是我们在处理时把所有标点和大写字母都抛弃了。
- en: it this way。 We could find a way to bring those back in by keeping track of
    the tokens along with the。 punctuation that followed them and then using that
    to print it out instead。 We could introduce some semantic constraints to the kind
    of Iku that we're looking for because。 right now we're just doing it purely based
    on syllable counts which isn't really how。
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种方式。我们可以通过跟踪与其后面的标点符号一起的令牌找到一种将它们带回的方法，然后使用它来打印出来。我们可以引入一些语义约束，来寻找我们所寻找的Iku，因为现在我们只是根据音节计数纯粹地进行，这其实并不是。
- en: Iku work in Japanese literature。 But this is a good first time。 It kind of helps
    us see this text in a little bit of a different light since we know that。 there
    are all of these Iku hidden inside of it。 I'm going to interrupt that and move
    on to the next example。 So the next thing I want to do is re-rime the sonnets。
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: Iku在日本文学中工作。但这是第一次尝试。这种方式让我们从不同的角度看待这段文字，因为我们知道里面隐藏着所有这些Iku。我将打断这一点，继续下一个示例。接下来我想做的是重新押韵这些十四行诗。
- en: So a sonnet is a particular poetic form in English that has a particular rhyming
    scheme。 William Shakespeare， the playwright also famously wrote a sequence of
    sonnets that are very well。 known。 It's included in the repository a file called
    sonnets。txt that has all of the sonnets that。 Shakespeare wrote in a plain text
    format with all of the formatting and like paratax removed。
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 所以十四行诗是一种特定的英语诗歌形式，具有特定的押韵方案。威廉·莎士比亚，这位剧作家也著名地写了一系列非常知名的十四行诗。它包含在一个名为sonnets.txt的文件中，里面有莎士比亚以纯文本格式写的所有十四行诗，所有格式和旁注都已去除。
- en: So what I'm going to do is I'm going to load in that those sonnets as a bunch
    of lines。 So I'm going to do item for item in open sonnets。txt。 Read。split on
    new line characters if the length of that line is greater than zero。 And now if
    I do like sign lines， let's get the first 14 lines we see the first sonnet。
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 我将把这些十四行诗作为一堆行加载进去。所以我将做“item for item in open sonnets.txt”读取。根据换行符拆分，如果该行的长度大于零。现在如果我像sign
    lines那样做，让我们获取前14行，我们就看到了第一首十四行诗。
- en: from Paris creatures we desire increase that their bipedis rose might ever die。
    So you can see there's a rhyme pattern inside of here where we have an A， A， B，
    B。 So A。 there's a gap between there。 Then we have C， D， C， D。 We have another
    set of rhymes that are interleaved。
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 我们渴望从巴黎的生物中增加，它们的双足生物可能永远不会死。所以你可以看到这里有一个韵律模式，我们有一个A，A，B，B。因此A。之间有一个间隔。然后我们有C，D，C，D。我们有另一组交错的韵。
- en: And then another set of rhymes that are interleaved。 And then a final couplet
    that has a single rhyme。 These all happen to be an iambic pentameter。 All of these
    lines have 10 syllables。 We're not going to worry about syllable count in here。
    But if we were making a program that finds arbitrary sonnets， we would need to
    worry。
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 然后是一组交错的韵，最后有一对单韵。这些全部都是抑扬五音步。所有这些行都有10个音节。我们不会担心音节数。但如果我们要制作一个程序来找到任意的十四行诗，我们就需要担心。
- en: about finding iambic pentameters。 But for now our task is just I want to generate
    new sonnets that follow the rhyme scheme of。 the original sonnets。 We're not going
    to quite get there with this example。 Basically what I wanted to do is sort of
    a simplified version of the problem is just。 find random rhyming couplets inside
    of the sonnets that aren't necessarily from the same， sonnet。
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 关于寻找抑扬五音步的内容。但是现在我们的任务只是想生成遵循原始十四行诗韵律的新十四行诗。我们在这个例子中不会完全达到目标。基本上，我想做的是一种简化版本的问题，就是在十四行诗中找到随机的押韵对，而这些并不一定来自同一首十四行诗。
- en: Just as an example of showing how to use the rhyming functionality from pronouncing
    along。 with the ability for a pencil it to get pronunciation support in the scene
    you're pronouncing。 So if you remember pronouncing has a function called rhyming
    part。 And if you pass in some sequence of phonemes as a string， a quick phone，
    and I'll pass。
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 作为展示如何使用“发音”的押韵功能的示例，同时能够为铅笔提供发音支持。如果你记得，“发音”有一个叫做押韵部分的功能。如果你传入一些音素序列作为字符串，一个快速的电话，我将传递。
- en: in alphabetical。 It returns。 The part of word at the end has to be identical
    for these two word streams。 So if we're drawing with alphabetical， it has to end
    in "edical"。 So our task is to find random rhyming couplets from the sonnets。
    So a quick way to do this would be。 this is sort of like the simplistic way， is
    I'm going。
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 按字母顺序排列。它返回。两个单词流的末尾部分必须完全相同。因此，如果我们以字母顺序绘制，它必须以“edical”结尾。我们的任务是从十四行诗中找到随机的押韵对。所以快速的方法就是。这有点像简化的方式，我正在做的就是。
- en: to pick a random line from the sonnet's random dot choice sonnet lines。 Then
    I'm going to get all of the words in that line， but actually just like the last
    word。 in that line is the only one that's really important。 Well， let's just get
    all of them。 So all of the words in that line is going to be word for word in
    MLTK dot word tokenize。
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 从随机选择的十四行诗中选取一行随机句子。然后我要获取该行中的所有单词，但实际上，只有该行的最后一个单词是最重要的。好吧，让我们获取所有单词。因此，该行中的所有单词将在MLTK中逐字标记。
- en: That picked sonnet line。 If again， that word is not punctuation。 And then the
    rhyming part for that sonnet is going to be the pronouncing rhyming part with。
    the getting the phonemes for that word。 Basically the word we want is all of those
    words。 the very last one in that。 And now I'm just going to print the picked and
    then the picked rhyme。
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 选定的十四行诗行。如果该单词不是标点符号。那么该十四行诗的押韵部分将是发音的押韵部分，获取该单词的音素。基本上，我们想要的单词是所有这些单词中最后一个的。
- en: So this picks a random line and then gets the thing that another line has to
    have at the。 end if it is going to rhyme with that line。 So I picked the line，
    the line。 since my appeal says I did strive to prove for another sonnet， to rhyme
    with this。 it has to end in oov。 So as I mentioned， sort of the naive first approximation
    way of doing this would be to。
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这会选择一行随机句子，然后获取另一行必须在末尾的内容，如果它要与那一行押韵。我选择了这一行，因为我的吸引力说我努力证明为了另一首十四行诗与之押韵，它必须以“oov”结尾。因此，正如我提到的，做这个的简单第一近似方法就是。
- en: say for line in random dot sample sonnet lines and then the length of sonnet
    lines。 This is a way of this is like random dot shuffle except it returns a copy
    of the array that's。 been randomized or sampling from that array but sampling
    as many items as there are in， that array。 I just like this better than using
    random dot shuffle because random dot shuffle modifies。
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每一行，在`random.sample`十四行诗的行中，然后是十四行诗行的长度。这是一种方法，类似于`random.shuffle`，只是它返回一个已经随机化或从那个数组中采样的数组的副本，但采样的项目数量与该数组中的项目数量相同。我更喜欢这种方式，而不是使用`random.shuffle`，因为`random.shuffle`会修改原数组。
- en: the list in place。 We'll skip if the current line is equal to the one that we
    picked then we'll skip it。 Otherwise we're going to get the words out so words
    equals and then our little thing。 for getting words from a line。 If there aren't
    any words in this line that meet our criteria then we'll continue and。 then we're
    going to do the meaty part of this which is if pronouncing the rhyming part。
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 列表保持不变。如果当前行等于我们选择的那一行，我们将跳过它。否则我们将提取单词，所以单词等于然后我们的那个小东西。用于从一行中提取单词。如果这一行中没有符合我们标准的单词，那么我们将继续。接下来我们将进行这一部分的实质内容，即发音的韵脚部分。
- en: of this current line， quick phones word minus one is equal to the rhyme of the
    line we picked。 then we're going to print the picked line and we're going to print
    the line that matched。 and then we're just going to break because I just want
    to find one one mat we could find。 all of the matches but this is one that's going
    to fit words I met here。
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 当前这一行的快速音节单词减去一个等于我们选中的行的韵脚。然后我们将打印选中的行，并打印匹配的行。然后我们就会中断，因为我只想找到一个我们能找到的匹配项。所有的匹配项，但这是一个能够契合我在这里遇到的单词的。
- en: Here we picked the other two slight error and perching fire。 Oh my god。 Why
    didn't that didn't work？
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们选中了另外两行，轻微的错误和**栖息火焰**。哦，我的天。这为什么不工作？
- en: Quick phones rhyming part。 The line picked equals line word rhyming part quick
    phones words minus one。 This shouldn't be picked that should be line。 So now I
    search them through each line and seeing if that line ends in the same rhyming。
    part and these two do this is sort of a trivial case because it ends in the same
    word。 Here's one that's a little bit better。 In love converted from the thing
    it was since why did love I can't allege no cause。
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 快速音节的韵脚部分。选中的行等于行的单词韵脚部分快速音节单词减去一个。这不应该被选中，这应该是行。所以现在我在每一行中查找，看看那一行是否以相同的韵脚部分结尾，这两行确实如此。这是一种琐碎的情况，因为它以相同的单词结尾。这里有一个稍微好一点的。在爱中转变成的事物，它是因为爱我不能说没有原因。
- en: So was cause don't quite rhyme but according to the way that this word was pronounced
    in。 the senior pronouncing dictionary it does。 This is the open tenure of the
    ijealousy。 I need to find another line that ends in LSE。 Let's see if any of them
    do。 They don't so it doesn't there is nothing that rhymes jealousy in this corpus。
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 所以可能因为不太押韵，但根据这个词在高级发音词典中的发音，它确实押韵。这是**嫉妒**的开放韵脚。我需要找到另一个以**LSE**结尾的行。让我们看看是否有任何行符合。没有，所以在这个语料库中没有与嫉妒押韵的东西。
- en: If I'm in that course untainted to allow then do the high office means I teach
    the house。 So now we found two lines that both end in。 Ow。 So there's this solution
    works fine for finding a couple。 A problem with it is that it just descends through
    all of the lines of all of the sonnets。 every time that we want to find a rhyme。
    So this is an ON squared way to solve the problem which isn't ideal。
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我在那个课程中未被污染以允许，然后做高层的工作意味着我教这所房子。所以现在我们找到了两行都以**Ow**结尾。所以这个解决方案在找到几行时工作得很好。它的问题是每次我们想找到韵脚时，它都会遍历所有十四行诗的所有行。因此这是一个**ON²**的解决方案，这并不是理想的。
- en: So you might not notice how that it only takes a little bit of time to do this
    with a small。 corpus like sonnets but ideally we could find a solution that's
    going to scale to millions。 of lines of poetry and not just the handful of them
    that are in the sonnet。 So a better way to do this is I'm going to use the default
    dict object， the default dictionary。
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 所以你可能没有注意到，用小的语料库（比如十四行诗）进行这个操作只需要一点点时间，但理想情况下我们能找到一个能够扩展到数百万行诗歌的解决方案，而不仅仅是那些在十四行诗中的少数行。所以一个更好的方法是我将使用默认字典对象。
- en: object from collections import default dictionary。 And then what I'm going to
    do is I'm going to make a dictionary that has as its values。 other default dictionaries
    with a list as the keys。 And basically what I wanted to do here is I want to build，
    I'm going to call this rhyming。
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 从 collections 导入 default dictionary。然后我将做的是创建一个字典，它的值是其他以列表作为键的默认字典。基本上我想在这里做的是构建，我将称之为押韵。
- en: part two index。 What I want to do is I want to build a data structure that basically
    looks like it has。 every rhyming part like， I don't know， ease。 And then the value
    for that rhyming part is a dictionary that has a word like cheese along。 with
    the indexes of the lines in the sonnet corpus that rhyme with that， with this
    rhyming。 part that have this word of cheese。 What this data structure is going
    to allow me to do is a couple of things。
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 第二部分索引。我想要做的是构建一个基本上看起来有每个押韵部分的数据结构，比如，我不知道，ease。然后这个押韵部分的值是一个字典，里面有像 cheese
    这样的单词，以及与之押韵的莎士比亚作品中的行的索引，这些行的押韵部分都有这个 cheese 这个词。这个数据结构将让我做几件事情。
- en: One is it's going to let me look up a line by its rhyming part instead of having
    to loop。 through all of the lines and find them。 I can just do an O1 look how
    to find that。 By keeping track of which words rhyme with the particular end word，
    I can make sure that。 I don't pick two lines that have the same end。 So when have
    the same word at the end。
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 其一，它将让我通过押韵部分查找行，而不必遍历所有行并找到它们。我只需进行 O1 查找就能找到。通过跟踪与特定结束词押韵的单词，我可以确保不选取两个结尾相同的行。也就是在结尾有相同单词的行。
- en: So I can look up the rhyming part of any random we chose in line。 And then this
    presumably would have like， I don't think there are any keys or fleas in， this
    on it。 But let's just use that as an example。 And then this would be like 10，
    11， 12， 13。 So if I wanted to generate a rhyming couplet where the last word was
    not repeated， I would。
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我可以查找我们在行中随机选择的押韵部分。然后，这可能会有，比如，我认为在这部作品中没有任何键或虫子。但我们就用这个作为例子。然后这将是像 10，11，12，13。如果我想生成一个押韵的对句，其中最后一个单词不重复，我会。
- en: just pick two keys from this interdictionary at random and then pick rhymes
    from those。 That would leave me with two lines that rhyme but don't repeat the
    end word。 So to build this data structure， I'm going to go for I line in enumerate
    sonic lines。 And then grab the words again， W for W in MLTK dot word， tokenize
    the line。
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 随机从这个内部词典中选择两个键，然后从中选择押韵的词。这将让我有两行押韵但不重复最后一个单词。为了构建这个数据结构，我将遍历声学行的每一行。然后再次抓取单词，W
    为 MLTK.dot.word 中的 W，进行行的标记。
- en: And if it's not punctuation。 If we do in fact have some words on this line。
    Another little variation I'm going to do with this is I'm actually going to get
    the last。 couple words。 The phonemes were the last few words because sometimes
    the rhyme of lines will spread across。 more than one word。 I don't know if that's
    the case at any point in this on it。
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这不是标点符号。如果我们确实在这一行有一些单词。我将对这个进行另一个小变体，实际上我将获取最后几个单词。因为有时行的押韵会跨越多个单词。我不知道在这部莎士比亚作品中是否会出现这种情况。
- en: but I just thought it would， be a fun thing to try out here。 So I'm going to
    get the phonemes for each one of these words for。 And like the last three words
    assuming that the rhyming part of a line isn't going to go。 back before the last
    three words of the line。 So this is going to give me the rhyming part that might
    include multiple words。
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 但我只是觉得在这里尝试一下会很有趣。所以我要获取这些单词的音素。假设最后三词的押韵部分不会在这一行的最后三词之前出现。这将给我提供可能包含多个单词的押韵部分。
- en: And then I'll get the actual rhyming part pronouncing dot rhyming part for those
    concatenated last。 few phonemes or the phonemes from the last few words of the
    line。 And then update this rhyming part to index data structure setting dot rhyming
    part for。 the last word in the line， appending the index of the current line。
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我将获取实际的押韵部分，pronouncing.dot.rhyming_part，用于那些连接的最后几个音素或这一行最后几个单词的音素。然后更新这个押韵部分到索引数据结构，设置
    dot.rhyming_part 为这一行的最后一个单词，附加当前行的索引。
- en: So this is taking this part or for the dictionary whose key is the rhyming part。
    I'm adding an item to the list for the key that to use or for the values key is
    the last。 word of this line。 So this is going to take a little while to run here
    at the beginning。 But all of the computation is being done up front in this case。
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这是在处理这个部分，或者说字典的关键是押韵部分。我正在为这个关键添加一个项，值的关键是这一行的最后一个单词。所以在这里运行会花一点时间。但在这种情况下，所有的计算都是在前面完成的。
- en: We're putting in the state of structure that will make all of this up is going
    to look up。 as much faster。 Now we can look at rhyming part two index。 Just the
    keys of this are going to show me all of the rhyming parts in this on it。 So here
    are all of the lines， all of the things that can go at the end of the line that
    indicate。
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在构建一个结构状态，这将使所有这些内容看起来更快。现在我们可以查看押韵部分的第二个索引。关键在于这些内容将向我展示所有押韵的部分。
- en: where they could rhyme。 And we could get like we could poke into this a little
    bit like rhyming part two index。 Let's say erring。 So this is saying line 2115
    ends with swearing and line 2117 ends with bearing。 So this is from the same song
    it almost certainly。 We could look at let's say errs。 Terrs occurs twice in different
    places。 But there's only one rhyme with that。 What's one maybe ends。
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 在他们可以押韵的地方。我们可以稍微探讨一下，比如押韵部分的第二个索引。假设是erring。那么这说明2115行以swearing结尾，而2117行以bearing结尾。所以这几乎肯定来自同一首歌。我们可以看看比如是errs。Terrs在不同地方出现了两次。但只有一个押韵，可能是ends。
- en: A man's and depends again almost certainly from the same song it。 Let's look
    at this is ing。 So all of the lines that run and with ing as the rhyming part
    here we have a bit more variety。 So like spring rhymes with sing rhymes with bring，
    king， wing， thing。 So we have multiple words that can end these lines。 Each one
    of those has multiple lines。
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 一首歌的内容几乎肯定来自同一首歌。让我们看看这个是以ing结尾的。所以所有以ing作为押韵部分的行我们有更多的变化。比如spring与sing，sing与bring，king，wing，thing。我们有多个词可以作为这些行的结尾。每一个都有多个行。
- en: So a little just something that's going to help us later on is we saw when I
    was just。 like poking through and exploring that in some cases the rhyming part
    didn't match up。 with any other line。 Technically with this on it every line should
    have at least one other rhyme but just because。 of the vagaries of the process
    of sounding them out with pronouncing and pencil eight。
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 有一点是以后会对我们有帮助的，我们看到当我只是浏览和探索时，在某些情况下押韵部分并没有与其他行匹配。理论上，每一行应该至少有一个其他的押韵，但是由于发音和拼写过程中的一些不确定性。
- en: sometimes that doesn't end up being okay。 So just to make it so we don't have
    to do a track every time。 What I'm going to do is just filter the dictionary to
    exclude anything that has fewer than two。 possible rhyming words。 So now that
    rhyme map is only going to have and we'll look at the keys here。 It's only going
    to have possible rhymes where there's more than one alternative and we can。
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候这并不会结束得很好。因此，为了让我们不必每次都进行跟踪。我打算过滤字典，以排除任何少于两个可能的押韵词。因此现在押韵地图只会包含键，我们来看一下这些键。它只会包含有多个备选项的可能押韵。
- en: test this out。 This would be other。 So rhyming map other。 Another mother， other
    smother。 We have multiple options for each one of these keys。 So now we can generate
    couplets and this is where we're going to end up here。 I'm not going to go through
    making the ABAB rhyme scheme。
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 测试一下。这将是其他的。押韵地图的其他部分。另一个母亲，其他的压制者。我们为每个关键都有多个选项。所以现在我们可以生成对联，这就是我们最终会到达的地方。我不打算制作ABAB押韵方案。
- en: I'm just going to generate a sequence of couplets and leave doing the ABAB rhyme
    scheme to do。 as an exercise。 The way to do that is I'm going to loop。 So we'll
    do seven so we end up generating 14 lines total， seven couplets。 I'm going to
    get a random rhyming part， random dot choice。 The list of the rhyme map keys。
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 我只是打算生成一系列对联，将制作ABAB押韵方案留作练习。做到这一点的方法是我将循环。所以我们做七次，总共生成14行，七对对联。我将随机选择一个押韵部分，随机选择押韵地图的关键列表。
- en: So this is going to give me a not random show C random choice keys。 This is
    going to give me a random rhyming part and then I'm going to call this A list。
    PList is going to be random dot sample from the keys of the dictionary that this
    points， to。 So the list of rhyme map for the rhyming part that we just selected
    keys。
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这将给我一个不随机显示的随机选择键。这将给我一个随机韵脚部分，然后我将称之为A列表。PList将从指向的字典的键中随机抽样。所以我们刚选择的韵律部分的韵律图的列表。
- en: So that's going to give me the -- and I want two of those because I want to
    get a pair。 This is going to give me the keys to the list， to the dictionary that's
    going to return the。 list of lines， the list of indices of the lines that contain
    potential random rhyming， couplets。 The index of the first line in the couplet
    is going to be random dot choice， the rhyme map。
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这将给我——我想要两个，因为我想要一对。这将给我列表的键，字典将返回。包含潜在随机韵脚的对句的行的索引。对句中第一行的索引将是随机选择，韵律图。
- en: at the rhyming part， at the A list。 This is going to give me again that list
    of indices。 And then the B index is going to be the same thing except working
    with the B and the B。 And then I'm going to print joining with a new line， the
    sonnet lines at that A index。 and sonnet lines at that B index。 So this is like
    a big like de-referencing of this data structure grabbing out all of these。
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 在韵律部分，在A列表。这将再次给我那个索引列表。然后B索引将是相同的，除了处理B和B。然后我将打印出以新行连接的在那个A索引的十四行诗行，以及在那个B索引的十四行诗行。所以这就像是一个大规模的去引用这个数据结构，提取出所有这些。
- en: individual parts。 But hopefully you can see how this -- I'm grabbing first one
    of these dictionaries in。 this line here， two of these dictionaries in this line
    here。 And then here I'm grabbing a random one of these keys。 And then here I'm
    grabbing another random one of these keys -- or， sorry， here I'm getting。
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 单独的部分。但希望你能看到这——我先抓取一个这些字典，在这一行这里，两个这些字典在这一行这里。然后在这里我抓取一个随机的这些键。然后在这里我抓取另一个随机的这些键——抱歉，在这里我得到。
- en: two of these keys at random。 This grabs the dictionary。 And then this grabs
    two of those keys at random， making sure we don't select the same one， twice。
    And then here I'm grabbing a single random line from the two keys that we selected
    at， random。 And then I'm printing them out next to each other。
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 随机选择这两个键。这会抓取字典。然后随机抓取这两个键，确保我们不会选择同一个两次。然后在这里，我从我们随机选择的两个键中抓取一行随机文本。然后我将它们并排打印出来。
- en: And here we have something that looks like what we set out to do。 With eager
    compounds we urge our -- we -- our pallet urge， we sicken to shun sickness when。
    we purge。 Yet in these thoughts， myself almost spising like to the lark at break
    of day arising。 had having and in quest to have extreme。 The basis jewel will
    be well-esteemed。
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们有一些看起来像我们所设想的东西。随着渴望的成分，我们催促我们——我们——的味觉，我们厌恶疾病而选择清除。当我们净化。然而在这些思想中，我几乎像晨曦中升起的云雀一样蔑视。极端追求拥有的基础珠宝将备受推崇。
- en: Why of the ice falsehood has that forged hooks whilst like willing patient？
    I will drink -- or。 sorry， if ice corrupt by over-partial looks。 Whilst like a
    willing patient。 I will drink no bitterness that I will -- no bitterness， that
    I will bitter think。 The other。 as your bounty doth appear， or if they sing to
    Zodol a cheer， to be diseased。
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么冰的虚假性会锻造钩子，而又像愿意的病人一样？我会喝——或者。抱歉，如果冰因过于偏爱而腐坏。就像一个愿意的病人。我不会喝任何苦涩，——任何苦涩，我会苦苦思索。其他的。正如你的慷慨所展现，或者如果他们为佐多尔欢唱，便是疾病。
- en: ear that there was true needing to bitter sauces that I frame my feeding。 So
    her -- we've achieved this goal of inside of Shakespeare's on it's being able
    to find。 random ringing couplets that don't repeat the word in the rhyme。 Now
    with this technique。 hopefully you can take this and apply it in a number of different，
    contexts。
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 听说真的需要苦涩的调味料来框定我的饮食。所以她——我们在莎士比亚的作品中实现了这个目标，就是能够找到不重复韵脚的随机对句。希望你能运用这个技巧，应用在多个不同的上下文中。
- en: One would be to use a much larger corpus。 Another would be to do something like
    Ranjit Botanikar's pentametron where you search through。 another corpus and actually
    find sequences of words that correspond to Iambic pentameter。 and try to match
    those up with the rhymes。 Or you can apply this to， to say， finding a limerick。
    or something like that other forms， of poetry as well。
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 一个方法是使用一个更大的语料库。另一个方法是做一些像Ranjit Botanikar的pentametron那样的事情，通过另一个语料库进行搜索，实际上找到与抑扬五音步相对应的单词序列，并尝试将它们与韵脚匹配。或者你可以将这个应用于，比如说，寻找打油诗，或者其他形式的诗歌。
- en: You can combine this also with the stress's function in pronouncing to pay attention
    to。 stress as well。 So with that， that is the end of the workshop。 I am very happy
    to answer any questions you have about this material or to -- if there's。 some
    application that you have in mind， I can help point you along the way with a little。
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以将这一点与发音中的重音功能结合起来，以便引起注意。重音也是如此。因此，这就是研讨会的结束。我很高兴回答你对这些材料的任何问题，或者如果你有某种应用在脑海中，我可以帮你提供一些指导。
- en: bit of sample code。 Just send me an email。 Hope you enjoyed it。 Thank you and
    goodbye。 。 。 。 [BLANK_AUDIO]。
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 一点示例代码。只需给我发封电子邮件。希望你喜欢这个。谢谢，再见。……[BLANK_AUDIO]。
- en: '![](img/8b020ff93a34aaaec015555fe5d65b80_7.png)'
  id: totrans-451
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8b020ff93a34aaaec015555fe5d65b80_7.png)'
