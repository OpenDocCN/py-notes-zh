- en: P44：Talk James Bennett - A 🐍's guide to Unicode - 程序员百科书 - BV1rW4y1v7YG
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: P44：演讲者詹姆斯·贝内特 - 一条🐍的Unicode指南 - 程序员百科书 - BV1rW4y1v7YG
- en: Hi， I'm James and I'm here today to talk to you about Unicode。
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 嗨，我是詹姆斯，今天我来和你们谈谈Unicode。
- en: '![](img/2a3245dcd9af276985281a539c729f78_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a3245dcd9af276985281a539c729f78_1.png)'
- en: Now I know that word can provoke some reactions in people， so the very first
    thing I want。 to do is remind you of a wise message from a beloved modern philosopher。
    Because Unicode is complex and I'm sure you've heard scary stories about it， but
    it's not。 something that you have to be afraid of and by the end of this talk
    I hope you won't be。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我知道这个词可能会引发一些反应，所以我想做的第一件事就是提醒你一句来自受人喜爱的现代哲学家的智慧信息。因为Unicode是复杂的，我相信你听过关于它的可怕故事，但它并不是你必须害怕的东西。希望在这个演讲结束时，你不会再害怕它。
- en: afraid of it。 Because you're going to understand where Unicode came from。 what
    it is and how it really works， how it gets implemented in computer systems and
    especially programming languages like。 Python and how you can work with it and
    recognize where the complexity in it is found so that。 you can manage that complexity
    and write more effective and more confident code so that you。
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 不必害怕它。因为你将理解Unicode的来源、它是什么以及它如何真正运作，如何在计算机系统中实现，特别是在像Python这样的编程语言中，以及如何使用它并识别其中的复杂性，以便管理这种复杂性，编写更有效、更自信的代码。
- en: don't have to be afraid of Unicode anymore。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 你不再需要害怕Unicode了。
- en: '![](img/2a3245dcd9af276985281a539c729f78_3.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a3245dcd9af276985281a539c729f78_3.png)'
- en: But of course we have to start somewhere， which means starting at the beginning。
    And the history of Unicode really is the history of written text， which is kind
    of complicated。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们得从某个地方开始，这意味着从头开始。Unicode的历史实际上就是书面文本的历史，这很复杂。
- en: '![](img/2a3245dcd9af276985281a539c729f78_5.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a3245dcd9af276985281a539c729f78_5.png)'
- en: Because we're still not sure entirely what that history looks like。 We know
    writing seems to have been invented independently multiple times throughout history。
    and over the thousands of years since then people have come up with almost an
    unbelievable。 number of different ways of writing down their thoughts and words。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们仍然不完全确定那段历史是怎样的。我们知道，书写似乎在历史上多次独立发明。在此后的几千年里，人们想出了几乎难以置信的不同方式来记录他们的思想和语言。
- en: Writing you can think of as a basis for a writing system has probably been used
    at some， point。 There are writing systems that are based on individual sounds
    or syllables or whole words， or ideas。 There are writing systems that are based
    on abstract representations of an idea。 There are writing systems that are based
    on the position of your mouth as you pronounce， a sound。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以把书写视为书写系统的基础，这在某个时刻可能被使用过。有些书写系统基于单个声音、音节、完整单词或思想。有些书写系统基于一个思想的抽象表现形式。有些书写系统基于你发音时口腔的位置。
- en: Really anything you can imagine， probably someone has come up with。 And the
    history of text encompasses all of those things， which can be pretty complicated。
    Now fortunately for this talk we really only need to talk about the last couple
    of centuries。 When we've tried to come up with systems for representing and transmitting
    text electronically。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 任何你能想象的东西，可能有人都想到了。文本的历史涵盖了所有这些内容，这可能相当复杂。幸运的是，对于这个演讲，我们只需要讨论过去几个世纪。当我们尝试设计用于电子表示和传输文本的系统时。
- en: There are older systems for long distance transmission。 There are semaphore
    systems and flag codes and signal fires and many other systems that。 were really
    effective。 But today we're mostly concerned with electronic or electromagnetic
    broadcast over a wire or。 radio waves。 And we've probably all seen some examples
    of early attempts at this。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 还有更古老的远程传输系统。有信号系统、旗帜代码、信号火焰和许多其他有效的系统。但今天我们主要关心的是通过电线或无线电波进行电子或电磁广播。我们可能都见过一些早期尝试的例子。
- en: '![](img/2a3245dcd9af276985281a539c729f78_7.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a3245dcd9af276985281a539c729f78_7.png)'
- en: This is one a lot of people know is Morse code， which was developed for a telegraph
    system。 It's a variable width encoding uses binary alphabet of two characters，
    a dot and a dash。 And there was a whole family of different telegraph codes with
    different principles and based on。 different ideas。 One of the more popular later
    on was ITA。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这是很多人所熟知的摩尔斯电码，专为电报系统开发。它是一种可变宽度编码，使用两个字符的二进制字母，一个点和一个破折号。还有一整套不同原理和不同想法的电报编码。后来比较流行的是ITA。
- en: which is a baudot code named after Emil Baudot， who。 also gives us the baud
    as a unit of transmission rate。 And baudot codes are kind of interesting because
    they introduced this concept of control characters。 If you look at this， it's
    a five bit binary code。 Normally these messages would be recorded by being punched
    as holes in a paper tape。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个以埃米尔·博多命名的波道编码，博道同时也给我们带来了传输速率的波特单位。波道编码很有趣，因为它引入了控制字符的概念。如果你看这个，它是一个五位的二进制代码。通常，这些消息会通过在纸带上打孔记录。
- en: which， sounds like it should only be able to handle 32 characters。 That's two
    to the fifth power。 But here the capacity is over 60 characters because it uses
    a control character to switch。 between two different alphabets of characters。
    These sorts of clever innovations let people do a lot of cool things with the
    telegraph system。 as it evolved and eventually developed into modern computer
    text encoding systems， many。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 听起来它只能处理32个字符。这是二的五次方。但这里的容量超过60个字符，因为它使用控制字符在两种不同字符字母之间切换。这类聪明的创新使人们能在电报系统的发展中做许多酷炫的事情，最终演变为现代计算机文本编码系统。
- en: of which were heavily influenced by these telegraph codes。 This of course is
    the 100 pound gorilla in the room， ASCII， which owes a lot to ITA2。 and the baudot
    family of telegraph codes。 But ASCII really took over the world even though it
    shouldn't have。 The problem with ASCII of course is it's the American standard
    code， which is a problem。
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 其中许多系统受到这些电报编码的影响。当然，这就是房间里的大象ASCII，它在很大程度上得益于ITA2和波道电报编码。但ASCII实际上占据了世界，尽管它不该如此。ASCII的问题在于它是美国标准代码，这确实是个问题。
- en: in a world that contains a lot more countries than America and a lot more languages
    than， English。 which meant that of course， even though ASCII was built into a
    lot of systems。
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个拥有比美国更多国家和更多语言的世界中，这意味着尽管ASCII被内置到许多系统中。
- en: '![](img/2a3245dcd9af276985281a539c729f78_9.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a3245dcd9af276985281a539c729f78_9.png)'
- en: and still is today and a lot of things will assume ASCII。 Lots of different
    people developed text encodings to represent their languages， their dialects。
    their regions， their countries。 There are a huge number of them out there。 This
    is just a subset that I took from a list that I found online。
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如今仍然如此，许多事情会假设使用ASCII。许多人开发了文本编码来表示他们的语言、方言、地区和国家。外面有大量不同的编码。这只是我从网上找到的列表中提取的一个子集。
- en: And of course that brought its own set of problems because how do you work together
    with。 so many different possible encodings？ How do you avoid the kinds of bugs
    and translation and encoding problems that can come up when。 you have this many
    different options and you may not even know which of them are being， used？
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这也带来了自己的一系列问题，因为你如何与如此多不同的编码方式合作？如何避免在有这么多不同选项时出现的错误、翻译和编码问题，且你可能甚至不知道使用了哪种？
- en: Wouldn't it be great if we just had one universal agreed-on solution？
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们只拥有一个普遍认可的解决方案，那该多好啊？
- en: '![](img/2a3245dcd9af276985281a539c729f78_11.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a3245dcd9af276985281a539c729f78_11.png)'
- en: Well， that's what Unicode is supposed to be。 And it's worth pausing for a moment
    to make sure we understand really what Unicode is。
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，这就是Unicode的目的。值得停下来思考一下，确保我们真正理解Unicode是什么。
- en: '![](img/2a3245dcd9af276985281a539c729f78_13.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a3245dcd9af276985281a539c729f78_13.png)'
- en: A lot of single page guides will really make a point of saying Unicode is not
    a character。 set and Unicode is not an encoding。 It's much more productive to
    think of Unicode as a set of databases and specifications and。 rules and properties
    for describing different human writing systems that we know about。 And yes。 some
    of those include ways to encode it into binary text。 Yes。
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 许多单页指南会强调Unicode不是一个字符集，也不是编码。更有效的理解方式是将Unicode视为描述不同人类书写系统的数据库、规范、规则和属性的集合。是的，其中一些包括将其编码为二进制文本的方式。
- en: some of those include sets of characters， but Unicode itself is so much more
    than any。 of those individual components。 And of course that means it's also complex。
    And it really has to be。 If you think about that long list of different encodings，
    Unicode has to try to do the job。 of all of them and handle all of the things
    that they handled。
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一些包括字符集，但 Unicode 本身远远超过任何单个组件。当然，这也意味着它非常复杂。如果你考虑到那长长的不同编码列表，Unicode 必须尽力完成所有这些编码的工作，并处理它们所处理的所有内容。
- en: If any given individual encoding only needed to handle perhaps one languages
    or one dialects。 or one region's particular language and rules for writing， but
    Unicode has to be able to。 handle them all。 There's a lot of complexity that's
    just inherent to that task。 And of course that means it's very different from
    those older single purpose encodings， but。
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果任何给定的单一编码只需要处理一种语言或方言，或一个地区特定语言和书写规则，但 Unicode 必须能够处理所有。这项任务本身就有很多复杂性。当然，这意味着它与那些较早的单一用途编码有很大不同，但。
- en: different doesn't have to be the same thing as scary。 And I hope that's something
    you'll take away from this talk。 Now we need to dive a little bit deeper into
    the terminology just to be able to talk usefully。
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 不同不一定要与可怕划等号。我希望这是你从这次演讲中能带走的一个要点。现在我们需要更深入地探讨一下术语，以便能够进行有用的讨论。
- en: '![](img/2a3245dcd9af276985281a539c729f78_15.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a3245dcd9af276985281a539c729f78_15.png)'
- en: about Unicode。 So let's stop and do a quick glossary check。 Because often we
    fall into very informal terminology。 Like we start talking about characters。 And
    Unicode does have a concept of character， but it's much more of an abstract entity
    than。 in those older encodings and character sets。 The basic atoms of Unicode。
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 Unicode。让我们停下来快速检查一下词汇。因为我们经常陷入非常非正式的术语中。比如我们开始讨论字符。Unicode 确实有字符的概念，但它比旧编码和字符集中的概念更加抽象。Unicode
    的基本单元。
- en: the things that make it up are called code points。 And you might try to think
    of a code point as a character， but we're going to see examples。 of why that's
    risky。 And Unicode itself is organized into planes of code points。 two to the
    16th or 65，536， code points per plane。 Originally there was just one plane。
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 组成它的东西称为代码点。你可以试着将代码点视为字符，但我们将看到一些例子，说明这样做是多么危险。Unicode 本身被组织成代码点平面，每个平面有 2
    的 16 次方或 65,536 个代码点。最初只有一个平面。
- en: Now there are 17 of them。 And code points are much like Unicode's concept of
    a character。 still sort of an abstract， entity。 When we start encoding Unicode
    into a binary format。 we need to translate it into code units， which are the atoms
    of a binary encoding。 And then if we do want to go up a higher level， if we want
    something that's analogous to what。
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在有 17 种。代码点（code points）与 Unicode 的字符概念非常相似，仍然是某种抽象的实体。当我们开始将 Unicode 编码为二进制格式时，我们需要将其转换为代码单元（code
    units），它们是二进制编码的基本单元。如果我们想提升到更高的层次，想要一些类似于什么的东西。
- en: we would call a character， Unicode has the term "graphyme。"。 Sometimes you'll
    also see it described as a grapheme cluster。 And there are a couple different
    variations。 There's legacy grapheme clusters and extended grapheme clusters。 You
    don't really need to know all the differences between those to be able to work
    effectively。
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们称之为字符，Unicode 中有一个术语是“图形单元（graphyme）”。有时你还会看到它被描述为图形单元集（grapheme cluster）。而且还有几种不同的变体，包括遗留图形单元集和扩展图形单元集。你并不需要了解它们之间的所有差异就能有效地工作。
- en: with Unicode in Python。 But a grapheme is， in Unicode's terms。 the smallest
    or the minimally distinctive unit of， writing in a particular system。 A grapheme
    is the smallest thing such that if you change it， you change the meaning of， the
    text。 and there's not a one-to-one correspondence between these and code points，
    as we're about， to see。
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 中使用 Unicode。但图形单元在 Unicode 的术语中是指在特定系统中写作的最小或最小可区分单元。图形单元是这样的最小单位，如果你改变它，就会改变文本的含义。而且这与代码点之间并没有一一对应关系，正如我们即将看到的。
- en: So let's look at some examples of code points。 Here's one that's probably familiar
    to a lot of people。 It's just a Latin capital letter A， as you can see from the
    name。 Its code point is 0041。 Code points are always a number。 By tradition， they're
    expressed in hexadecimal。 And we can see that it has a block and a category and
    some other information。 And in fact。
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 那么让我们看看一些代码点的例子。这是一个许多人可能熟悉的例子。它就是一个拉丁大写字母 A，从名称可以看出。它的代码点是 0041。代码点总是一个数字。根据传统，它们以十六进制表示。我们可以看到它有一个块、一个类别和一些其他信息。事实上。
- en: this is just a subset of the information Unicode has on this code point。 Blocks
    are a way of organizing code points below the level of a plane。 Blocks are contiguous
    sets of code points that are all related。 So for example。 the basic Latin block
    contains the code points for the Latin alphabet， or。
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是Unicode在这个代码点上信息的一个子集。区块是一种组织代码点的方式，低于平面级别。区块是所有相关的代码点的连续集合。例如，基本拉丁区块包含拉丁字母的代码点。
- en: at least the most common parts of it。 It has a lot of overlap with ASCII。 In
    fact。 the first 128 code points in Unicode match the 128 values in ASCII。 We can
    see its category。 It's an uppercase letter。 We can see it has information about
    bi-directionality。 English and most other Western European languages， are written
    left to right。
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 至少是它最常见的部分。它与ASCII有很大的重叠。事实上，Unicode中的前128个代码点与ASCII中的128个值相匹配。我们可以看到它的类别，它是一个大写字母。我们可以看到它有关于双向性的相关信息。英语和大多数其他西欧语言是从左到右书写的。
- en: There's also this combining class property， which we'll get to in just a second。
    Of course。 there's a lot more that you could look up if you went trolling through
    all of。 the information in the Unicode database。 So let's look at something a
    little bit more complicated。 This is code 。0308， which by itself doesn't really
    do anything。 It wants to go with something else。
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 还有这个组合类属性，我们稍后会讨论。当然，如果你去翻阅Unicode数据库中的所有信息，还有很多内容可以查阅。那么让我们看看一些稍微复杂的内容。这是代码0308，单独来看并没有什么作用。它想与其他东西一起使用。
- en: And when it does， it shows up as an accent mark， diuresis， or sometimes you
    might call。 it an umlaut or just dot。 But here we can see， for example。 that combining
    class value suddenly shows up has a value of， 230。 which says when we're rendering
    this and we see this in a sequence of code points。
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 当它出现时，它显示为重音符号、二重音符，或者有时你可能称之为变音符或只是点。但在这里，我们可以看到，例如，组合类值突然显示出230的值，这表示当我们渲染这个并在一系列代码点中看到它时。
- en: it shows up above whatever came before it。 And there are different values for
    combining class to show positioning and how different。 things combine together
    to form a single visible glyph on your screen or when printed。 But notice that
    this means if we want that u with an umlaut above it， we're using multiple。 code
    points to produce what is one character from the human reader's perspective。
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 它显示在之前的内容之上。组合类有不同的值，用于显示定位以及不同事物是如何组合在一起形成单个可见的字形，无论是在屏幕上还是打印时。但请注意，这意味着如果我们想要带有变音符号的u，我们需要使用多个代码点来生成从人类读者的角度来看是一个字符的内容。
- en: So we've already broken that concept of one code point is one character because
    here we。 have a character that uses two code points。 And it actually goes the
    actual complexity shows up in both directions。 For example， here this character
    from the Arabic sections of Unicode is one code point。 but 18 characters。 And
    there are actually several of these in Unicode。
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们已经打破了一个代码点就是一个字符的概念，因为这里我们有一个使用两个代码点的字符。实际上，复杂性在两个方向上都显现出来。例如，这个来自Unicode阿拉伯语部分的字符是一个代码点，但有18个字符。实际上，Unicode中有几个这样的例子。
- en: These are used in Arabic religious type setting where there are certain phrases
    that tend。 to occur quite often and there are ligatures for representing them
    just as a single unit。 when type setting and when printing and displaying。 But
    again。 we see you can't assume one code point is one character and in fact this
    is。
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这些用于阿拉伯宗教排版，其中有些短语相当常见，并且有连字将它们表示为一个单元。在排版、打印和显示时。但再次强调，我们看到你不能假设一个代码点就是一个字符，实际上这是。
- en: one code point that isn't necessarily even one word。 So Unicode yes can be complex
    and yes you need to know that there's a difference between。 code points and characters
    and graphims。 But when you sit down and think about it。 any system that tries
    to handle all of the complexity。
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 一个代码点并不一定是一个单词。因此，Unicode确实可以很复杂，而且你需要知道代码点、字符和图形之间的区别。但是，当你坐下来思考这个问题时，任何试图处理所有复杂性的系统都会面临挑战。
- en: of human writing sooner or later is going to run into something like this and
    is going。 to present this level of complexity to you in some way。 And of course
    it keeps going because this means that often in Unicode there are multiple。 ways
    to write the same thing。 Going back to that you with the umlop above it。
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 人类书写最终迟早会遇到这样的复杂性，并以某种方式向你展示这种复杂性。当然，这种情况还在继续，因为这意味着在Unicode中，通常有多种方式来写同样的东西。回到那个带有变音符号的u。
- en: there are at least two ways you can write， this in Unicode。 Here's the one we
    saw earlier that uses the combining accent character。 There's also a pre composed
    form that does it in one code point。 And this is there for historical reasons。
    A lot of earlier encodings that were single purpose had pre composed characters
    for different。
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: combinations of letters and accent marks。 And so for compatibility Unicode has
    to have them as well so that you can do a lossless conversion。 to and from Unicode
    back to your original encoding。 If you ever want to。 But this means that in Unicode
    we can end up with multiple ways to write the same thing。 And these two sequences
    of code points where the one pre composed point and the decomposed。
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: sequence of two code points are considered equivalent。 And in fact Unicode calls
    them canonically equivalent because it should always be safe。 to swap one of these
    for the other。 You won't change the meaning of your text by doing so。 But it also
    has a concept of compatibility equivalence which is where it may not always。
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: be safe to swap between two different ways of writing the same thing。 So here
    for example we have a code point that represents a composed fraction one half
    and。 a decomposed sequence that writes it out as a one and a two with a splash
    between them。 There are times when it's correct to swap between these there are
    also times when it's， not。
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: And this gives rise to the concept of normalization。 Which is a way that we
    can take different sequences that may represent the same thing。 and find out if
    they do by making them equal after the normalization。 And because Unicode has
    both composed and decomposed forms and has two different types。
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: of equivalents。 There are four different ways to normalize Unicode depending
    on what the result should。 look like and what rules you want to apply。 So you
    can either get a composed or a decomposed form after the normalization。 You can
    use either canonical or compatibility equivalence rules as you're doing this。
    Now we'll get to this a little bit later on but if you're just feeling overwhelmed
    and。
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: want a general recommendation if you ever need to do Unicode normalization yourself。
    it's probably best to pick form NFKC。 That's the one that will make the most trade-offs
    in favor of what you probably want but we'll。 see examples of how different normalization
    forms can be good or bad a little bit later， on。 Speaking of multiple ways of
    writing the same thing though a lot of languages have multiple。
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: different forms for different characters， uppercase and lowercase and in fact
    Unicode has three。 different cases lowercase， uppercase and title case and multiple
    different case mappings。 and ways of transforming characters according to case
    as well as the concept of completely。 uncased characters。 And in fact most code
    points in Unicode were most characters abstract entities that Unicode。
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: handles are uncased because the case mappings won't change them because they're
    coming from。 languages or systems of symbols that just don't have a concept of
    case。 Now you might be wondering well how then do I do things like case insensitive
    comparisons。 especially because Unicode if you dig into it has at least three
    different concepts of。
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: case and ways to find out what case a character is or whether it even is case
    and the answer。 is case folding which Python supports and we'll see examples of
    it in a little bit but I do。 want to call out that Python's documentation says
    something not great。 Python says case folding is like a more aggressive form of
    lowercase and while it's true that。
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: for a lot of Western European languages the result of case folding will look
    lowercase this。 is not a guarantee there are languages where the result of case
    folding will look uppercase。 So don't think of case folding as being uppercasing
    or lower casing it is its own thing but the。 important thing to know about case
    folding is that after you've case folded two strings。
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: if they differed only in case they will be the same after the fold。 And of course
    case can also extend beyond what Unicode really handles。 Unicode handles most
    of these cases for example the Greek Sigma which takes different forms。 depending
    on where it occurs in a word the Turkic languages have both dotted and dotless。
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: forms of the letter I and it's incredibly important to preserve the dot or absence
    of。 the dot when you're doing a case transformation because those effect meaning
    German has this。 character officially it's called the sharp s historically it
    didn't have an uppercase form。 and so it uppercases to SS but this also means
    that case mappings in Unicode aren't transitive。
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: because uppercasing this and then lower casing again won't get you back what
    you started。 with and there's far more complexity in the language of that have
    case that Unicode just。 doesn't handle and tells you you may need to have low-calaware
    rules there are situations。 like for example Dutch where words that begin with
    ij have to title case that as a single。
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: unit rather than as two characters and Unicode simply tells you you need to
    get low-calaware。 rules for the specific language you're going to work with it
    handles some of these but。 nowhere near all the complexity that exists in all
    the languages now finally we need to。 understand since we're going to work with
    computers how we actually get this into a。
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: computer which means how do we get it into a binary form how do we encode it
    and decode。 it going between code points which are numeric values but kind of
    abstract to actual bits。 and bytes and to do that we need a Unicode transformation
    format and there are a lot of。 those I've listed some here the two you'll see
    most often are probably UTF-8 and UTF-16。
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: but it's worth being aware that most of these are variable width they use different
    numbers。 of bytes to encode different code points UTF-8 for example for a code
    point from the。 ASCII range only needs one byte but for other code points may
    need up to four UTF-16 for。 anything in the lowest numbered plane plane zero or
    the basic multilingual plane BMP as。
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: you'll sometimes see it written uses two bytes for anything from higher numbered
    planes uses。 four bytes because originally Unicode had just the one plane and
    it had two to the sixteenth。 code points in it so there was an assumption that
    16 bits ought to be enough for anybody。 right well eventually Unicode added more
    planes and UTF-16 was developed with a scheme that。
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: lets it still handle 16 bit units but sometimes use two of them per code point
    the exact mechanics。 if you want to go look it up are called surrogate pairs and
    basically there is a segment of。 plane zero of Unicode that set aside that will
    never be assigned and UTF-16 transforms。 a code point bigger than 16 bits into
    two code points from that range and then you can。
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: transform them back again to get back the original value and this is how UTF-16
    handles those。 code points that are larger than 16 bits but that also means that
    it too now is a variable。 with encoding and of course we need to consider what
    kind of abstractions we're going to expose。 to a programmer because there are
    different ways we can handle strings in programming languages。
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: they might be sequences of bytes they might be sequences of the encodings code
    units or。 they might be sequences of code points or sequences of graph themes
    and their trade-offs。 involved in all of these one of the important things to
    be aware of though is depending。 on the abstraction your language chose you may
    or may not be able to cause changes in。
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: meaning or even completely invalidate a sequence of code points by cutting into
    it so for example。 in a language like see where typically strings are exposed
    as a sequence of bytes if you。 arbitrarily cut in the middle of that you might
    cut in the middle of a multi byte code unit。 or you might cut in the middle of
    a code point that requires multiple bytes or you might。
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: be cutting at a code point boundary but cutting in the middle of a graph theme
    that's made。 up of multiple code points all of these operations can be unsafe
    and depending on which abstraction。 your language exposes to you you may be at
    risk of different versions of these problems。
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2a3245dcd9af276985281a539c729f78_17.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
- en: now you might be wondering well what does Python do and you might also be wondering。
    well we're twenty minutes into this and you haven't really talked about Python
    I thought。 this was a Python talk well okay let's talk about Python originally
    there was Python 2。
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2a3245dcd9af276985281a539c729f78_19.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
- en: and Python 2's story for Unicode was not that great in Python 2 the string type
    was a sequence。 of bytes there was a separate type called the Unicode that was
    a Unicode string it offered。 access to lots of features of Unicode it could represent
    any code point in Unicode or at least。 sometimes could we'll get to that in a
    minute and you had to know to convert back and forth。
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 而 Python 2 的 Unicode 故事并不好。在 Python 2 中，字符串类型是字节的序列，还有一种称为 Unicode 的单独类型，它是
    Unicode 字符串，提供了对许多 Unicode 特性的访问。它可以表示 Unicode 中的任何代码点，或者至少有时可以，稍后我们会讨论这一点，而你必须知道如何进行相互转换。
- en: between them and you had to know what encodings things came from and we're going
    to and Python。 assumed ASCII by default for its byte strings and even if you told
    it otherwise still a。 lot of third-party modules and other code didn't behave
    all that well when you presented。 them with non-asky byte sequences or even sometimes
    with just Unicode instances and this。
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 你必须知道东西来自什么编码，以及要转到什么地方。Python 默认假设字节字符串为 ASCII，即使你告诉它其他信息，许多第三方模块和其他代码在你提供非
    ASCII 字节序列或有时只是 Unicode 实例时，也并不那么好用。
- en: was generally a mess so now we have Python 3 and there was much rejoicing because
    in Python。 3 there's only one string type and it is a Unicode string type there
    is still a separate。 type for sequences of bytes and you can go back and forth
    between them you can take a。 byte sequence and if you know the encoding you can
    decode it into a string or you can。
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这通常是个麻烦，所以现在我们有了 Python 3，大家都很高兴，因为在 Python 3 中只有一种字符串类型，那就是 Unicode 字符串类型。仍然有一个单独的字节序列类型，你可以在它们之间来回转换。如果你知道编码，可以将字节序列解码为字符串，或者你可以。
- en: take a string and encode it into bytes in a particular encoding but a lot of
    the issues。 that used to exist in Python 2 especially with the sort of interchangeability
    that it had。 for both Unicode and byte strings have been cleaned up except for
    one thing that persisted。 for a few releases into the Python 3 series and it's
    this this is everybody's favorite。
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 取一个字符串并将其编码为特定编码的字节，但在 Python 2 中存在的许多问题，特别是在 Unicode 和字节字符串之间的可互换性问题，已经得到清理，除了一个在
    Python 3 系列中持续了几个版本的问题，这就是每个人的最爱。
- en: emoji the pile of poo and if you fire up a Python interpreter from Python 3。0。1。2
    there's。 a good chance you will see this result and you might be wondering what's
    going on here。 well earlier versions of Python when you compiled the interpreter
    you made a choice as to how。 it would store Unicode internally and effectively
    the choice was between UTF-16 and UTF-32 so。
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 表情符号“便便”，如果你从 Python 3.0.1.2 启动一个 Python 解释器，看到这个结果的机会很大，你可能会想，发生了什么事。早期版本的
    Python 编译解释器时，你需要选择如何在内部存储 Unicode，实际上选择是 UTF-16 和 UTF-32 之间的选择，因此。
- en: either 16-bit or 32-bit storage for Unicode these were called narrow and wide
    builds of。 Python most people used a narrow build and that's where you would see
    this result because。 that code point is too large to fit in a single 16-bit unit
    so an encoding like UTF-16 needs。 to use a surrogate pair for it and split it
    across two replacement code points and Python。
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 16 位或 32 位存储 Unicode，这被称为 Python 的窄和宽构建。大多数人使用窄构建，这就是你会看到这个结果的地方，因为这个代码点太大，无法容纳在一个
    16 位单元中，因此像 UTF-16 这样的编码需要使用代理对来处理，并将其分成两个替代代码点，而 Python。
- en: would expose this to you directly if you iterated over this you would see two
    code points from。 the surrogate range in the basic multilingual plane instead
    of the original code point you。 put in now fortunately that's been fixed Python
    3。3 changed this implemented a spec from pep。 393 which did away with the narrow
    and wide builds of Python if you want to know the details。
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你逐步查看这个，你将直接暴露给你两个来自基本多语言平面的代理范围的代码点，而不是你现在输入的原始代码点。幸运的是，Python 3.3 修复了这个问题，实施了
    PEP 393 的规范，消除了 Python 的窄和宽构建。如果你想知道更多细节。
- en: and how that affected in memory storage and how it affects the capi of Python
    you can go。 look up the pep one other nice takeaway is that it means Python strings
    use a lot less。 memory now on average than they used to but the big thing for
    our purposes is it means。 that a Python string now really is a sequence of code
    points where previously it was a sequence。
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 以及它如何影响内存存储和 Python 的 C API，你可以去查阅 PEP。另一个不错的收获是，这意味着 Python 字符串现在平均使用的内存要比以前少得多，但对我们来说，最重要的是，这意味着
    Python 字符串现在确实是一系列代码点，而之前是一个序列。
- en: of code units and this is actually a test I like to use with different languages
    when。 I try them out is take a string like the pile of poo and ask the language
    how long is this。 if you get an answer of one that means the language is probably
    working with either code。 points or graph themes as its string abstraction if
    you get an answer of more than one then maybe。
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: it's working with code units like Python used to with its 2-byte 16-bit encoding
    on narrow。 builds or maybe even at something more complex like just exposing sequences
    of UTF-8 bytes。 which will give you an even larger answer on some of the emoji
    but it's a good way to。 quickly find out what is a language doing and what abstraction
    is it exposing when it。
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: says it has Unicode support because that's an important thing to know now as
    far as Python。 we now have strings which are sequences of code points which means
    that we can find out。 information about them if we grab something out of a string
    so a string of length one it's。 a single code point if we iterate a string we're
    iterating over code points if we if we。
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: take a slice of a string or index into a string we're getting code points and
    we can actually。 find out what's the numeric value of a code point and we can
    transform it into hexadecimal。 as a tradition for representing Unicode code points
    there's also a module in the standard。 library that's really useful called Unicode
    data and this gives us a lot of access to the。
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: Unicode databases and the information that Unicode provides about its code points
    and。 characters so we can ask questions like what's the name of this code point
    or what category。 is it assigned to what's its bidirectional or combining rendering
    behavior all of which。 can be useful information to find out we also have access
    from that module to Unicode normalization。
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: and we can use any Unicode normalization form we want and so here for example
    we can take。 that pre-composed u with umlaut character and decompose it into the
    two code points sequence。 or we can take that pre-composed one half fraction and
    decompose it using compatibility。 equivalence into that sequence of one slash
    two we also have access in Python to case folding。
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: which is useful gives us access to case insensitive comparison and anytime you
    need to do a case。 insensitive string comparison in Python this is what you should
    be reaching for a lot of。 us probably developed habits from earlier days when
    we weren't working with Unicode of。 upper casing or lower casing and a lot of
    us probably still do that when working with databases。
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: because we may not have a case fold abstraction in our sequel libraries or in
    our database。 but in Python we have that available and that's how we should be
    doing case insensitive comparisons。
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2a3245dcd9af276985281a539c729f78_21.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
- en: of strings so everything is wonderful right obviously well yes in a way Python
    three and。 especially since three point three does a good job of implementing
    Unicode and exposing。 it in a useful way and making it relatively easy for us
    to work with but there are still。 traps and problems that we can fall into one
    of which I'm not normally a fan of absolute。
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2a3245dcd9af276985281a539c729f78_23.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
- en: statements but this is one that I will get pretty absolute on I will call this
    the golden。 rule of working with text in any sort of programming language not
    just Python is to be aware of。 your programs boundaries and do encoding and decoding
    there and only there and when I say。 boundaries I mean things like if your program
    reads and writes files then that's a boundary。
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: when it opens up and reads the contents of a file or writes the contents back
    onto the。 file system if your program talks over a network that's a boundary when
    it sends information。 out over that connection or receives information coming
    in those are the points where you should。 do your encoding and decoding those
    are the points where you should be working with bytes。
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: objects but once you have them encoded or decoded you should be working entirely
    with。 strings internally you should not be passing around bytes objects or dealing
    with encoded。 sequences of bytes at almost any cost because most older approaches
    and most older Python。 code that had trouble making the jump two to three had
    trouble because of this because。
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: of mixing of byte strings and Unicode strings or even just not using Unicode
    strings at all。 in some cases and not thinking about encoding and decoding and
    where they needed to happen。 so this is your golden rule if you take nothing else
    away look for the boundaries of your。 program identify what they are do your encoding
    and decoding there and only there everywhere。
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: else be working with strings be working with real Unicode now there is still
    some difficulty。 every once in a while especially when it comes to working with
    files and especially on certain。 types of Unix operating systems and these problems
    fall into a few different categories there。 are some systems where there is no
    reliable way to ask the system what encoding it uses。
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: for its file system so you know that something like a file name is a sequence
    of bytes but。 you might not have any way of figuring out how to decode that into
    a sequence of Unicode。 code points there are also file systems where technically
    there is not a requirement that。 they be able to decode where a path can simply
    be any arbitrary sequence of bytes you want。
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: and never validly decode in any known encoding and Python has made progress
    over the course。 of the Python 3 release series with getting better at this there
    are some tips and tricks。 and tools and now Python mostly does its best to let
    you treat the file system as UTF-8。 with some tricks to handle potentially invalid
    or just completely undecodable paths actually。
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: what Python does now is similar to what UTF-16 does where when it encounters
    a byte that。 can't possibly decode as a sequence of code points it preserves it
    as is by transforming。 it into a code point from the surrogate pair range and
    that lets it transform back into。 the original byte again when it's time to write
    things on the file system or do other。
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Python现在所做的类似于UTF-16的做法，当它遇到一个无法解码为代码点序列的字节时，它将其原样保留，通过将其转换为代理对范围内的代码点来实现，这样当需要在文件系统上写入内容或进行其他操作时，就可以再次转换回原始字节。
- en: encoding sometimes you can work around this by telling Python what encoding
    your file system。 is using sometimes you just have to hope that it works because
    there are some systems that。 are configured hopelessly but it is a thing that
    has gotten better it is a thing that now。 mostly reliably works even on those
    badly configured systems which is a big leap forward。
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 编码有时可以通过告诉Python你的文件系统使用的编码来规避，有时你只能希望它能正常工作，因为有些系统的配置是绝望的，但这确实有所改善，现在即使在那些配置不良的系统上也基本可靠，这是一个很大的进步。
- en: from where it was in the early days of Python 3 of course there are other problems
    you can。
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 从Python 3早期的状态来看，当然还有其他问题。
- en: '![](img/2a3245dcd9af276985281a539c729f78_25.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a3245dcd9af276985281a539c729f78_25.png)'
- en: run into we've we've definitely seen examples of normalizing different forms
    that can sometimes。 be a destructive operation depending on what language you're
    working with some languages。 really rely on the combining and composing features
    of Unicode this example is Korean。 but it's not the only language that does this
    that initial string is two code points。
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们确实见过规范化不同形式的例子，这有时可能是一种破坏性操作，具体取决于你正在使用的语言。有些语言确实依赖于Unicode的组合和构成特性，这个例子是韩语，但这并不是唯一的这样做的语言。最初的字符串由两个代码点组成。
- en: it's two composed characters effectively each one represents one syllable of
    the text and。 each syllable is made up of three individual characters or three
    individual letters that。 represent the consonants and vowels that go into that
    syllable and performing a decomposing。 normalization can result in that sequence
    of as you see below six different code points。
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这实际上是两个组成字符，每个字符代表文本的一个音节，每个音节由三个单独的字符或三个单独的字母组成，表示构成该音节的辅音和元音。执行去构成的规范化可能会导致如下面所示的六个不同代码点的序列。
- en: representing the constituent parts of those composed characters those single
    syllable representations。 and depending on what system you feed them into they
    may render correctly or they may。 not the terminal application I used to generate
    these examples handled this well and rendered。 both of these strings the same
    way this slide does not so this is something to be aware of。
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 代表这些组成字符的构成部分，那些单音节的表示形式。而且根据你输入的系统，它们可能会正确渲染，也可能不会。我用来生成这些示例的终端应用程序很好地处理了这些，并且以与这个幻灯片相同的方式渲染了这两个字符串，但这个幻灯片没有，所以这是需要注意的事项。
- en: and in general combining and composed forms pop up more often than people expect
    a lot。 of emoji for example are made of combining sequences the country flags
    there is a set。 of code points that are called the regional indicator symbols
    and they provide an alphabet。 that lets you spell out two-letter country codes
    and then those render as the flags of。
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，组合和组成形式出现的频率比人们预期的要高。很多表情符号，例如，由组合序列组成。国家旗帜有一组称为区域指示符符号的代码点，它们提供了一个字母表，可以拼写出两位数的国家代码，然后这些代码渲染成国家的旗帜。
- en: those countries so this is basically the sequence us spelled out in regional
    indicator。 symbol code points if you wanted something like the flag of Canada
    you would spell CA。 if you wanted the flag of France you would spell FR and that's
    how the flag emoji work。 splitting these down the middle could just destroy the
    meaning because you wouldn't know。
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这些国家的顺序基本上是用区域指示符符号代码点拼写的US。如果你想要类似加拿大的国旗，你会拼写CA。如果你想要法国的国旗，你会拼写FR，这就是国旗表情符号的工作原理。将这些中间分开可能会摧毁其含义，因为你将不知道。
- en: how to render it anymore the same thing is true of a lot of emoji for people
    for example。 this is a family of four people but it's seven different code points
    under the hood and a。 lot of the emoji for people are multi-code point sequences
    either composing groups of。 people or composing on modifiers to indicate gender
    or skin tone or other attributes and。
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: again splitting in the middle of them can be destructive it can change the meaning
    or。 completely destroy the meaning of a sequence so we need to turn back to that
    concept we。 saw earlier of the graph theme the minimally distinctive unit of meaning
    and unfortunately。 Python doesn't directly give you a way to work with graph themes
    in strings but you can。
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: still do it using third party libraries so for example this is a third party
    regular。 expression library called regex you can pip install it and it offers
    a lot more support。 for Unicode then Python's standard library regex module does
    including things like filtering。 and matching on Unicode properties and most importantly
    for this case it provides a meta。
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: character for matching Unicode graph theme clusters and this is actually defined
    in one。 of the Unicode specifications it's supposed to be this capital X character
    but it means。 that we can do things now like count the number of graph themes
    in a string or split on graph。 themes or iterate over graph themes rather than
    risking splitting up a graph theme that's。
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: made up of multiple code points but even in the Python standard library there
    is still。 a lot of awareness of Unicode if we go back to for example the regex
    module in the Python。 standard library most of us have probably written code like
    this where we're saying oh。 okay I need to match something that you know looks
    like a year so it's a sequence of four。
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: digits and it's going to be something like 2020 well it turns out Unicode has
    a much。 broader concept of digit than what speakers of English and Western European
    languages。 do so that second string for example pulls digit characters from four
    different blocks。 and four different languages that are represented in Unicode
    but it still matches because according。
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: to Unicode properties they are all digits and this is an important thing to
    be aware of。 when you're working with Python in Python 3 where everything is Unicode
    and things are。 mostly Unicode aware that you need to be explicit as the Zen of
    Python says explicit。 is better than implicit but you need to make sure you understand
    what some of these things。
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: mean like this digit medic character or the other regex medic characters and
    if what you。 really wanted was only to match digits 0 through 9 from the Latin
    character set you can say。 that but you do have to be explicit about it。 There
    can also be difficulty with things。 like performing string comparisons and working
    with different strings that potentially write。
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: the same thing different ways and here it can be difficult to give any single
    answer because。 the answer is usually context sensitive it depends on what you're
    doing。 So for example。 here this is a fairly simple algorithm but it comes from
    one of the Unicode technical。 reports on security and this is for comparing things
    that might be used as identifiers things。
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 同样的事情以不同的方式，这里很难给出单一答案，因为答案通常是上下文敏感的，这取决于你正在做什么。例如，这里有一个相对简单的算法，但它来源于Unicode技术报告中的安全性，这用于比较可能用作标识符的事物。
- en: like maybe variable names in a programming language or usernames in an account
    system。 and this gives you a way to compare them in a case insensitive way and
    figure out which。 ones should be considered equivalent and which ones should not。
    There are other ways to normalize。 and prepare strings for comparison and for
    use and it really does depend on your use case。
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 例如编程语言中的变量名或帐户系统中的用户名，这为你提供了一种无视大小写地比较它们的方法，并找出哪些应该被视为等价，哪些不应该。还有其他方法来规范化并准备字符串进行比较和使用，确实取决于你的用例。
- en: Python supports quite a few of them for example if you are working with domain
    names which can。 be internationalized now there are modules in the standard library
    that support this the。 encoding codeings。idna module the puny code codec let you
    work with these and transform。 internationalized domain names into an ASCII compatible
    form that's safe to transmit through。
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: Python支持相当多的功能，例如，如果你在处理可以国际化的域名，现在标准库中有支持这个的模块，编码代码的idna模块和punycode编解码器让你可以处理这些，并将国际化域名转换为安全的ASCII兼容形式以便传输。
- en: a lot of systems that maybe aren't aware of internationalized domain names。
    There are。 also even trickier things that you can get by digging into third-party
    modules。 For example。 this is something that comes and goes where people will
    try to fool you by writing out。 a domain name or maybe an email address or a username
    or some other identifier using a。
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 很多系统可能不太了解国际化域名。还有更棘手的事情，可以通过深入挖掘第三方模块获取。例如，这种情况时有发生，人们会试图通过使用多个脚本的代码点来愚弄你，写出域名、电子邮件地址、用户名或其他标识符。
- en: mix of scripts where some of the characters look like each other but aren't
    actually the。 same and Unicode actually includes a database for this called the
    visually confusing characters。 file and there's a third-party module that you
    can go download that has this wonderful。 function and it called is dangerous。
    I love that name that tells you when a string contains。
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这涉及到混合脚本，其中一些字符看起来相似但实际上并不相同，而Unicode实际上包含一个称为视觉混淆字符文件的数据库，还有一个第三方模块可以下载，具有这个奇妙的功能，它被称为is
    dangerous。我喜欢这个名字，它能告诉你字符串中是否包含。
- en: code points from multiple scripts and some of them appear in that visually confusing。
    characters file some of them are confusable characters so you can notice when
    somebody's。 trying to do something dangerous and that module also includes a lot
    of other information that。 you can access so you can ask it to show you a list
    of what are the confusable characters。
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一些出现在视觉混淆字符文件中，一些是可混淆字符，所以你可以注意到有人试图做一些危险的事情，而该模块还包含大量其他信息，你可以请求它展示可混淆字符的列表。
- en: what was it that set this off what were the script properties that were being
    used in。 this string that were being mixed together and there's really a whole
    wide world of things。
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 是什么引发了这个问题，这个字符串中混合使用的脚本属性是什么，这里实际上有很多内容。
- en: '![](img/2a3245dcd9af276985281a539c729f78_27.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a3245dcd9af276985281a539c729f78_27.png)'
- en: out there but hopefully at this point you've got a handle on the core ideas
    of what goes。 into Unicode what it is why it's complex and where that complexity
    comes from so you can。 start thinking about that complexity in a productive way
    start anticipating where you。 may need to do extra work where you may need to
    worry about something and how you can write。
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 外面的内容，但希望此时你已经掌握了Unicode的核心理念，它是什么、为什么复杂以及这种复杂性来源于哪里，这样你就可以开始以富有成效的方式思考这种复杂性，开始预见何时可能需要额外的工作，何时可能需要担忧，以及如何编写。
- en: better more effective code and feel more confident about how you're using Unicode
    and of course。
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 更好、更有效的代码让你对如何使用Unicode更有信心，当然。
- en: '![](img/2a3245dcd9af276985281a539c729f78_29.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a3245dcd9af276985281a539c729f78_29.png)'
- en: if you have any questions unfortunately this is an online presentation because
    PyCon had。 to be canceled this year but I'm happy to have people reach out and
    ask me questions。 I also keep a blog where I regularly rant about all sorts of
    things including Unicode。 which has its own category there and finally I want
    to take a minute to just thank the。
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有任何问题，不幸的是这是一场在线演讲，因为今年的PyCon不得不取消，但我很高兴有人能联系我并问我问题。我还保持一个博客，定期吐槽各种事情，包括Unicode，那里有自己独立的分类，最后我想花一点时间感谢。
- en: PyCon organizers and the PSF because they were really put in an impossible situation
    this。 year and as sad as it is that the in-person version of PyCon 2020 had to
    be canceled it。 really is incredible the way that they reacted and responded and
    were able to put together。 this online track of talks as quickly as they did and
    as successfully as they did so if you're。
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: PyCon的组织者和PSF，因为他们今年面临了一个不可能的局面。尽管2020年PyCon的线下版本被取消是令人悲伤的，但他们反应和应对的方式，以及能够如此迅速而成功地组织这条在线讲座的方式，真的令人难以置信，所以如果你正在。
- en: watching this please be thankful for the PSF for the PyCon organizers and for
    all the。 work they put in to putting this online and pulling off a remote PyCon
    2020 on such short。 notice and under the worst possible conditions。 In the meantime
    stay safe hopefully I will see you at a PyCon in person sometime in the。 future。
    Thank you。
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 观看这个的人，请感谢PSF、PyCon的组织者以及他们为在线举办2020年远程PyCon所付出的努力，这一切都是在如此短的时间和最糟糕的条件下完成的。与此同时，保持安全，希望将来能在某个PyCon上见到你。谢谢。
- en: '![](img/2a3245dcd9af276985281a539c729f78_31.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a3245dcd9af276985281a539c729f78_31.png)'
- en: so much for watching。 for watching。 the PSF for watching。 the PSF for watching。
    [BLANK_AUDIO]。
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢观看。感谢观看。感谢PSF的观看。感谢PSF的观看。[空白音频]。
- en: '![](img/2a3245dcd9af276985281a539c729f78_33.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a3245dcd9af276985281a539c729f78_33.png)'
